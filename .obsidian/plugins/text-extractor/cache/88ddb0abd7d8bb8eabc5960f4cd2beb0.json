{"path":"Git Ignore/Matthew Barnes Notes/Distributed Systems & Networks Notes.pdf","text":"Computer Science / Software Engineering Notes Network Distributed Systems & Networks Matthew Barnes Netwo rkin g (Kirk) 5 Physical + Link layer 5 Functions 5 Acknowledgements 7 Frames 9 Ethernet CSMA/CD 10 WiFi CSMA/CA 10 Ethernet LANs 11 Ethernet theory 11 ARP 12 Building Ethernet LANs 13 Spanning tree protocol 13 VLANs 15 Ethernet frame priority 16 Internet/Network layer 16 Internet Protocol (IP) 17 Subnets 21 Calculating subnets 23 ICMP 25 IP routing protocols 25 Aggregating prefixes 26 Interior routing protocols 27 Distance Vector 27 Link state 28 Exterior routing protocols 29 Transport layer 30 UDP 30 TCP 31 TCP or UDP? 35 Sockets 36 DNS 37 Application layer 40 Telnet 40 Email 41 SMTP 41 IMAP 42 HTTP 42 Computer Science / Software Engineering Notes Network HTTP/2 43 QUIC 43 CoAP 44 RTSP 44 SMB 44 NFS 45 P2P 45 IPv6 45 IPv6 Features 46 Why use v6? 47 IPv6 headers 47 IPv6 with routers and privacy 48 Deploying IPv6 48 IPv6 security 49 Other IPv6 stuff 49 Network security 50 DNS Security 50 Firewalls 51 Intrusion Detection Systems 52 Port / Physical Security 52 DDoS 53 Wi-Fi (In)Security 54 D istributed Systems Imp lemen tatio n s (Tim) 55 Distributed Systems Models 55 Physical models 55 Architectural models 55 Mapping entities to infrastructure 56 Architectural patterns 56 Fundamental models:Interaction, Failure and Security 57 Distributed Object Systems 59 Distributed OOP 59 Remote Interfaces 60 Server Deployment 60 Dynamic Code Loading 60 Many Clients! 61 The Monitor 61 The Observer Pattern 62 RMI Limitations 62 Data Serialisation 62 Serialising Java Objects 62 Mobile code üì± 63 Computer Science / Software Engineering Notes Network Pass by reference or value? 63 Programming language independence 64 JSON 65 GSON 65 Linked Data & Semantics 65 Loose Coupling 66 Space & Time Uncoupling 66 Group Communication 67 Publish & Subscribe 68 Message Queues & IoT 69 RabbitMQ 70 Distributed Transactions 71 Distributed Data 71 Lost Updates & Inconsistent Retrievals 71 Dirty Reads & Premature Writes 73 Distributed Commit Protocols 74 Two-Phase Commit 75 2PC Failure Handling 75 Increasing Concurrency & Deadlocks 76 D istributed Systems Theo ry (C o rin a) 77 Time in Distributed Systems 77 Clock synchronisation 77 Logical clocks 78 Distributed Mutual Exclusion 82 Failure detectors 82 Distributed Mutual Exclusion 82 Leader Election 91 Asynchronous systems 92 Synchronous systems 96 Reliable and Ordered Multicast 98 Basic multicast 99 Reliable multicast 99 Ordered multicast 100 Consensus 103 Synchronous 104 Asynchronous 105 Consistency models 106 Strong consistency 107 Sequential consistency 107 Causal consistency 109 Eventual consistency 109 Computer Science / Software Engineering Notes Network Strong eventual consistency 110 Other stuff (Leo n ardo ) 110 Data Replication and Scalability 110 Data Replication 110 Primary-backup 110 CAP theorem 112 Scalability 115 Highly Available Distributed Data Stores (Amazon Dynamo) 116 Replication 117 Consistency 118 Fault tolerance 123 Why is Amazon Dynamo AP? 123 Scalability 124 Consistent Distributed Data Stores (Google BigTable) 125 Data model 125 Architecture 126 Tablets 129 SSTables 130 Why is Google BigTable CP? 132 Online Distributed Processing 132 Use cases 132 Requirements 133 Apache Storm 133 Data model 133 Architecture 134 Replication 135 Stream grouping 136 Fault tolerance 137 Batch Distributed Processing 139 Implementation #1:Google MapReduce 139 Implementation #2:Apache Hadoop 140 TL;D R 142 Kirk‚Äôs stuff 143 Tim‚Äôs stuff 150 Corina‚Äôs stuff 154 Leonardo‚Äôs stuff 158 Computer Science / Software Engineering Notes Network Networking (Kirk) Physical + Link layer Functions - There are three reference models for networking protocols: OSI mo del TC P/IP mo del Tan en baum‚Äôs bo o k Application Application Application Presentation Transport Transport Session Internet Network Transport Link Data Link Network Physical Data Link Physical - Here is a sentence to remember the OSI layers, from bottom up:Please D o Not Throw Salami Pizza A way üçï‚ùåüóë - Tanenbaum‚Äôs book is just the TCP/IP model, but they changed Internet to Network and Hardware to Physical. - Each layer adds its own header, and it becomes part of the payload for the layer below it: - There‚Äôs different types of medium for the physical layer: - Coaxial cable - Twisted pair Computer Science / Software Engineering Notes Network - Power line - Fibre optic - Wireless (laser, sound, ultrasonic, pulses, radar) - Bits are transmitted using encoding schemes. Transmission is based on something varying over time, like voltage or frequency, with synchronisation. - What does the link layer actually do? - Transmits frames over physical media - Detects and handles transmission errors - The link layer doesn‚Äôt care about what the packet says. The link layer only cares about getting the packet from A to B. - Packet:a unit of data in the Network layer (our payload) - Frame:a unit of data in the Link layer (what the link layer actually sends) - A frame contains a packet and wraps a header and a trailer around the packet. - Data frames vary based on the physical layer, for example there are Ethernet frames and Fibre Channel frames. - The partitions of a frame are usually fixed in size (except for the payload), making it far easier to tell where the data actually is. - Frames are transmitted through hop by hop transmission over a packet-switched network. - Too jargon-y for you? - Ho p by ho p tran smissio n :where data is transported through intermediate nodes to its destination. - Packet-switched n etwo rk:A network where packets dynamically find their own way to a destination without a set path (look at the pretty animation from wikipedia) Computer Science / Software Engineering Notes Network - Because of these properties, framing can allow senders to send packets through a shared medium, like you see above (all the intermediate nodes are available to all the coloured packets/frames). - You also need to know where the frame starts and the frame ends. - In flow control, we may need to regulate how fast we send data. We don‚Äôt want to swamp a slow receiver with tons of packets! - We can either: - send messages from the receiver to the sender saying ‚Äúwait, let me process this data first‚Äù and alternatively, ‚Äúalright, now send more data‚Äù a.k.a. feedback-based flo w co n tro l - make the communication rate-based so the speed is agreed between both parties (rarely used in such a low layer) a.k.a. rate-based flow control Acknowledgements - There are three main link layer models: - Connectionless, no acknowledgements - Used for low error rate networks (networks where packets rarely get lost, like Ethernet) - C o n n ectio n less:no signalling path is established in advance. - No ackn o wledgemen ts:Frames are sent, and may or may not be received by the destination. - Acknowledged, connectionless service - A ckn o wledged:frames are sent, and the recipient notifies the sender when they‚Äôve received a frame through an acknowledge (A C K) signal. - This is used when connections need the assurance of delivery, but can‚Äôt afford the overhead of connection management. - Acknowledged, connection-oriented service - Acknowledgement signals are sent, and a connection is formally established before communications occur. Computer Science / Software Engineering Notes Network - This is used for long delay, unreliable connections, for example with satellites. - It‚Äôs computationally expensive, but it‚Äôs secure. - How do we handle ACK signals and errors? - We use ARQs! - A RQ (auto matic rep eat-req uest):an error-control mechanism that uses ACKs and timeouts to ensure reliable communications with an unreliable recipient. - Basically, ARQs are different ways of handling ACKs and when they screw up. - There are three kinds: A RQ p ro to co l n ame Exp lan atio n (not in the slides, so it might not be examinable, but if you wanna play it safe then read this anyway) Stop-and-wait The sender sends the first frame, then the recipient sends an ACK signal for that frame. The sender sends the second frame, then the recipient sends an ACK signal for that frame. This keeps on going until all the frames have been sent. Go-back-N The sender sends frames #1 to #N to the recipient, in order, over and over again, even if an ACK signal doesn‚Äôt exist. The recipient throws away duplicate frames and frames that aren‚Äôt in the right order. The recipient sends an ACK signal containing the lowest number frame it had missed, let‚Äôs say #M where 1 ‚â§ M < N. The sender gets the ACK signal, and now sends frames #M to #(M + N - 1) to the recipient. This keeps on going until all frames are collected. Protocols like these are called sliding window protocols. Examp le: Alice is sending frames 1, 2, 3, 4 and 5. Bob gets frames 1, 2, 3 and 5, but misses 4. Bob sends an ACK signal to Alice with the number ‚Äò4‚Äô. Alice receives this ACK signal, and is now sending frames 4, 5, 6, 7 and 8. Now Bob has frames 1, 2, 3, 4, 5, 6, 7 and 8. Bob sends an ACK signal with the number ‚Äò9‚Äô. Alice receives this ACK signal again, and is now sending frames 9, Computer Science / Software Engineering Notes Network 10, 11, 12 and 13. Selective-repeat Go-back-N may send duplicate frames, which is inefficient on the bandwidth. Selective-repeat aims to fix this. The sender sends frames #1 to #N. The receiver can either: - Send an ACK signal to move onto the next set of frames - Send a NAK signal to request a specific frame If the sender gets an ACK signal with number M, then it‚Äôll start sending frames #M to #(M + N - 1). If the sender gets a NAK signal with number M, then it‚Äôll send only the frame #M to the recipient. Examp le: Alice sends frames 1 and 2 to Bob. Bob gets frames 1 and 2, and sends an ACK signal with number 3 to Alice. Alice gets this ACK signal and sends frames 3 and 4 to Bob. Bob misses 3, but gets 4. Bob sends a NAK signal with number 3 to Alice. Alice gets this NAK signal, and sends frame #3 to Bob. Bob gets frame 3 and sends an ACK signal with number 5 to Alice. Alice gets this ACK signal and now sends frames 5 and 6 to Bob. - How do we detect errors in communication? - There are a few ways we can do this: - Parity bit:a bit that‚Äôs either 1 or 0 depending on whether the number of 1‚Äôs is even or odd - C RC (C yclic Redun dan cy C heck):a type of checksum based on polynomial division. The checksum is stored in a field of the frame, and is calculated and compared by the sender and the recipient. - Checksums may happen on other layers too. IPv4 has a checksum, but IPv6 doesn‚Äôt. Frames - In frames, how do you know where frames start and where frames end? - There‚Äôs many ways to do it. One way is to use a FLAG byte value to mark the start and the end. Computer Science / Software Engineering Notes Network - If a FLAG byte appears in the payload, escape it with an ESCAPE byte (similar to escape characters \\ n , \\ b , \\ \\ ... in C, C++, Java etc.) Ethernet CSMA/CD - Ethernet was the most commonly used link layer standard throughout the 90‚Äôs, and continues to be today. - Originally, it all ran through shared media. In other words, it was all one wire and everyone had to share. There came twisted pair with hubs/repeaters to help, but it didn‚Äôt solve the problem. - In the end, switches were used (they‚Äôre like hubs, but a little smarter). There is one device per switch port, and since it‚Äôs fully duplex, there‚Äôs no contention. - On a shared medium, how is media contention handled? - Originally, Ethernet used C arrier Sense Multiple A ccess with C ollision D etection, or C SMA /C D . - It works by checking if the media is busy. If it is, then wait. If it isn‚Äôt, then it sends its signals across it. - If a collision occurs (two devices try to use the media at the same time), they both stop and pick a delay before trying to talk again. - Ethernet doesn‚Äôt really use this anymore because switches are fully duplex, so there‚Äôs no contention. WiFi CSMA/CA - WiFi is the wireless alternative to Ethernet. It works in the 2.4GHz or 5GHz range. The 2.4GHz range has 14 channels (13 in Europe). WiFi has evolved over the years. - With WiFi, devices are associated with a wireless access point (AP). Devices can select from one of many service set identifiers (SSIDs). - WiFi is technically a shared medium, so there can be contention in a busy area. Therefore, you need a collision avoidance scheme. - WiFi can‚Äôt send and receive at the same time, so WiFi uses a slightly different approach called C SMA /C ollision A voidance (C SMA /C A ). - It‚Äôs like CSMA/CD, but instead of listening to the medium, it waits for an acknowledgement from the AP to determine if the frame was sent. - In other words, instead of dealing with collisions, it avoids them. - It‚Äôs very similar to the stop-and-wait ARQ protocol. - Optionally, Req uest to Sen d / C lear to Sen d (RTS/C TS) could be used to improve performance, where a sender sends an RTS message to ask if it can send frames, and can only send frames after it receives a CTS message from the receiver (basically, send an RTS and expect a CTS). - /CA is used in wireless connections as it is very difficult to determine if a collision has occurred over a wireless network. Computer Science / Software Engineering Notes Network Ethernet LANs Ethernet theory - Ethernet is used on campus networks and on home networks. - An Ethernet frame includes (remember, this is the link layer): - 48-bit source MAC address - 48-bit target MAC address - Optional VLAN ID and frame priority - At max, the frame is usually around 1500 bytes. If it gets any bigger, it‚Äôll be broken down into smaller frames. - MA C (Media A ccess C o n tro l) address:a unique ID for network interface controllers (NICs) at the link layer. - It‚Äôs around 48 bits long, but can be extended to 64 bits. - They need to be unique, so MAC addresses are split up into: - 24 bits for vendor allocations (tells you what vendor this hardware is from) - Last 24 bits assigned by the vendor - Ethernet networks are built with each device (also called hosts) connected to a concentrator device (usually a switch). - Desktops usually have 1 Gbit/s Ethernet, but the servers are on 10 Gbit/s Ethernet. - There are different kinds of concentrator devices: - Hubs and repeaters: - Really old! - They just take frames and forward them on to all the devices available - They just extend Ethernet range - All hosts see all packets, which is a big no-no for security. - Bridges and switches: - Receives frames and forwards them to the host that needs them - Has ‚Äòsmart‚Äôforwarding (they learn which host needs what packet) - Hosts only see the packets sent to them, which is good for security. - Switches are smart, because: - they can perform CRC (Cyclic Redundancy Checks) before forwarding Computer Science / Software Engineering Notes Network - it learns the addresses of the hosts using a MAC table, so they only send packets to the hosts that need them - can support more advanced features, like VLAN or QoS - How do switches learn which frames go to which host? - Switches match up source MAC addresses to switch ports. - So if a frame with source MAC address 6F-72-61-6F-72-61 is picked up by port number 2, the switch will remember that. The next time a frame with that source MAC address comes up, the switch will send it to port number 2. - There is a time-out for pairings like that (~ 60 seconds). - If there is no entry in the table the switch has to send the package to all ports. ARP - To send a frame to a host, you need its network layer address (IP address) and its link layer address (MAC address). - We can get the IP address from DNS, but how do we get the MAC address from an IP address? - We use ARP! - A RP (A ddress Reso lutio n Pro to co l):a protocol that allows a host to get the MAC address associated with a given IP address. - ARP uses a link layer broadcast message (a message sent to everyone). - The broadcast message asks ‚ÄúWho has this IP address‚Äù? - All the hosts see this message, and the one with that IP address goes ‚ÄúIt‚Äôs me! My IP address is so.me.th.ing and my MAC address is wh:at:ev:er‚Äù - The sender gets this information and can now send the frame. - This information is usually cached for around 60 seconds. - In an ARP message, you have: - Sender MAC address - Sender IP address - Target MAC address (zero-padded when we don‚Äôt know what it is) - Target IP address - There are 4 kinds of messages: - Unicast:from one sender to one receiver. Purely one-to-one. - Broadcast:sent to everyone. To broadcast a message, make the MAC address FF:FF:FF:FF:FF:FF. - Multicast:sent to anyone who is interested. - Anycast:sent to the nearest receiver;doesn‚Äôt matter who, as long as it gets to someone. Computer Science / Software Engineering Notes Network - Nuances of ARP: - Hosts can spoof and steal frames from other hosts - Low power devices may ‚Äòsleep‚Äôand not respond to ARP messages - You can send a ‚Äògratuitous ARP‚Äô, which is just making sure your information is up to date. - A RP p ro be:a use of ARP to make sure no two hosts have the same IP Building Ethernet LANs - LANs can‚Äôt be too big, or else we‚Äôll have problems with range and volume of messages (when broadcasting). - Therefore LANs must be kept at a reasonable size, for example in a campus, there‚Äôs typically one LAN per floor, or per building. - When we create an Ethernet LAN with a switch, hosts can talk to each other directly using their MAC addresses. - They‚Äôll also allocate ‚Äúlocal‚Äù IP addresses to each host, for example 192.168.0.0 up to 192.168.255.255, as part of an IP address p lan . - To connect two LANs together, we need to use an IP router, which forwards IP packets between LANs (remember, routers do not work with the link layer, only the network layer). - Routers can tell other routers the reachability of the IP address ranges it serves, so the network can learn where to forward IP packets. - Therefore, if a host was sending a packet from one LAN to a host on another LAN, it will send the packet to its ‚Äòdefault‚ÄôIP router. - IP routers act as network layer gateways between individual link layer Ethernet LANs. - A localised network layer LAN behind a router is called an IP subn et. - A home network is usually a single IP subnet and Ethernet LAN. - In multi-story buildings, they typically use copper twisted pair cabling. - Ethernet networks may be deployed using: - Data riser:vertically aligned switch/server rooms - Flood wiring per floor:have faceplates from switch room - Ethernet switch stacks:one switch port per faceplate - A building may have one LAN, if a router connects the whole building, or there could be one LAN per floor. - In homes, you typically have an ADSL router with multiple Ethernet ports and 802.11 WiFi. It‚Äôs just one LAN, with no internal routing. Pretty basic. Spanning tree protocol - A bridge lo o p occurs in a network when there are two ways to reach the same node. Computer Science / Software Engineering Notes Network - They‚Äôre bad news because they can cause bro adcast radiatio n , which is where there‚Äôs so much traffic on the network cabling that it severely harms the performance of the network. No bridge lo o p B ridge lo o p - Why is this so bad? - Let‚Äôs say the workstation wants to send a frame to the file server. The switches will pass the frame onto the neighbouring nodes, right? After all, no frame has been sent before, there‚Äôs no way the switches would know which frames to send where. - The workstation‚Äôs frame could end up back at switch 1 through the path 1 -> 2 -> 3 -> 1 or 1 -> 3 -> 2 -> 1. This loop is wasteful and clogs up the medium. - The file server could also end up with two of the same frame. - It‚Äôs pretty clear that loops are bad. But they could also be good, because what would happen if switch 3 dies? We could still use the switch 2 path to get to the file server. Whereas, on the left, if switch 1 dies, that‚Äôs it. No more talking to the file server. - Introducing the sp an n in g tree p ro to co l! - The spanning tree protocol maps out a set of paths from the source to the target in a ‚Äútree‚Äù structure. It plucks out the least cost path, and disables all the other switches that are not on that path. Computer Science / Software Engineering Notes Network - The source can then send the packet, and no loops will occur. - However, if a switch on that path fails, the protocol will pick the next best path, and re-enable and disable the appropriate switches to follow that path instead. - Therefore, we get the best of both worlds:no broadcast radiation, and if any switches fail, we‚Äôre fine. - Want an example? - So we want to get from the workstation to the file server. There‚Äôs two (sensible) ways of doing this: - Normally, we‚Äôd pick the smallest, but they‚Äôre both the same length, so let‚Äôs go with the switch 3 path. - So now, switch 2 is disabled. The workstation sends the frame. - Oh no! A rat chewed on the cabling of switch 3 and made it explode! What are we going to do?! - The protocol will now pick the switch 2 path. So now, switch 2 is enabled, switch 3 is ‚Äúdisabled‚Äù, and the frame is re-sent through the switch 2 path. - It reaches the file server successfully! VLANs - A VLAN, or a Virtual LAN, are broadcast domains that are partitioned and isolated. - A VLAN can consist of multiple hosts, all of different LANs, but they are made to think that they are all connected to the same wire. - Ethernet frames include an optional VLAN identifier. It‚Äôs 12-bits, so there are 4096 different VLAN IDs. - Because it‚Äôs completely logical and not physical, it‚Äôs quite flexible. Computer Science / Software Engineering Notes Network - Here, workstations 1, 3 and 5 think they‚Äôre all on the same LAN, but really it‚Äôs a VLAN. - This is useful to group together staff that aren‚Äôt physically in the same LAN, for example, workstations 1, 3 and 5 might all be in the marketing department. Ethernet frame priority - How important is a frame? - VoIP is pretty important, because you want to know what the other person is saying as they‚Äôre saying it. - HTTP might not be as important, because it‚Äôs a document;you don‚Äôt need it right away. - There are three bits in the 802.1Q tag that determines priority, from 1 to 7. - This only affects prioritisation at switches, not end-to-end. Internet/Network layer - What does the network layer actually do? - The network layer is responsible for establishing a network between computers so that they can send things to each other. - In more detail, the network layer is responsible for: - Internetworking: - Connecting networks together to form an ‚Äúinternetwork‚Äù, or ‚ÄúInternet‚Äù - Each network is served by a router - Transmitting: Computer Science / Software Engineering Notes Network - Packets the data by adding an IP header - Processes and routes IP datagrams (data units across the network) - Fragmenting packets that are too big - Receiving: - Error checking - Reassembling fragments if needed Internet Protocol (IP) - IP (or In tern et Pro to co l) is the main protocol used in the network layer. - The properties of IP are: - Packet-switched, connectionless: - IP packets are routed towards destination at each router on the path - C o n n ectio n less:packets find their own way to the destination, it doesn‚Äôt have to rely on a fixed path from A to B - Unreliable: - No guarantee that any IP datagram will be received - B est-effo rt delivery:there is a variable bit rate and latency and packet loss depending on the current traffic load. Basically, the routers try their best but won‚Äôt guarantee perfect performance - Routing: - Sending a packet is only based on destination IP address - Routers maintain routing tables to make routing decisions - Globally unique, delegated addresses: - Devices must be globally unique + addressable to send traffic to them - Private address space, which are not globally routed, may be used (because that‚Äôs the whole point, since we ran out of IP addresses) - There are 5 main protocols for the network layer: - IPv4 - IPv6 - ICMP - used for diagnostics and control - ICMPv6 - IPSEC - used for security - Sto re-an d-fo rward packet switching is a technique where data is sent to an intermediary node and then passed on to either another intermediary node or the destination node. - In this context, routers store the packet and determine where to forward them. Computer Science / Software Engineering Notes Network - IP is a bit unreliable, because routers forward packets on a ‚Äòbest effort‚Äôbasis. - Packets may get dropped because of congestion. The transport layer (next layer above) may handle retransmissions: - With TCP, retransmissions are handled - With UDP, the application layer has to handle retransmission - Quality of Service may help by prioritising certain traffic. - In IPv4, segments of data are taken from the transport layer and an IP header is attached to the end of it. - This creates an IP datagram. - An IP header has the following fields: - Source IP address - Destination IP address - IHL - header length (can vary) - Identification field and fragment offset - Time to live (how long should this packet stay switching before we give up) - IP header checksum Computer Science / Software Engineering Notes Network - MTU (or Maximum Tran smissio n Un it) is the size of the largest data unit that can be communicated in a single network layer transaction. - If we‚Äôre sending a packet of 2000 bytes to a router, and the MTU is 1500 bytes, then the packet has to be fragmented. - Fragmentation happens in the network layer. - We should try to avoid fragmentation, because it adds overhead and security issues. - Now, a bit of history of IPv4! - People used IPv4 since the 1970‚Äôs - It uses 32-bit addresses, written as ‚Äòdotted quads‚Äô, like 152.78.64.100. - The IPv4 address space is partitioned into 5 different classes, where 3 classes are used for networks of different sizes, 1 class is used for multicast groups and 1 class is reserved: Class Prefix range Prefix length # of networks # addresses per network Examples A 0.0.0.0 to 127.0.0.0 8 bits 128 networks ~16 million addresses 20.xx.xx.xx 102.xx.xx.xx B 128.0.0.0 to 191.255.0.0. 16 bits ~16,000 networks ~65,000 addresses 152.78.xx.xx 160.125.xx.xx C 192.0.0.0 to 223.255.255.0 24 bits ~2 million networks 256 addresses 196.50.40.xx 202.155.4.xx D 224.0.0.0 to 239.255.255.255 n/a n/a n/a n/a (used for multicast groups) E 240.0.0.0 to 255.255.255.255 n/a n/a n/a n/a (reserved) - Here is a graphical visualisation of the partitioning of the IPv4 address space: Class A Class B Class C Class D Class E - Basically, if an IPv4 address is within a certain class, it must follow two rules: 1. The first 8 bits must be within a certain range 2. It must have a fixed prefix - For example, if an IP is within class B, the first 8 bits must be between 128 and 191, and the first two bytes must be fixed. Computer Science / Software Engineering Notes Network - Additionally, an IP range of 152.xx.xx.xx cannot be within class A because the first byte lies outside of A‚Äôs range;it would be B, but the second byte would be part of the fixed prefix too, so you should write something like 152.78.xx.xx. - This is generally very inefficient, e.g. there are not many networks that require a Class A IP address and thus 16 million different addresses, which means that a lot of space is wasted. Even 65,000 addresses in class B are too many for most networks. - Since 1995, RIR (Regional Internet Registry) allowed variable length prefixes, meaning that network addresses were no longer assigned strictly based on the ABC class scheme - This change reduced address consumption rate, but we still ran out of addresses back in 2011. - Due to the fact that there are still not enough IPv4 addresses for all hosts world-wide, private IP addresses were introduced - More precisely, there exist ranges in the IPv4 address space that are used as private IP addresses - What does private IP address mean? It basically means that this is an IP address that is not globally unique and thus cannot be reached from outside the network. - In other words, private IP addresses may be used many many times in different networks world-wide - An example for the use of a private IP address is your home network - There exist three different private IP networks with the following address ranges: A ddress ran ge Number o f addresses Subn et mask 10.0.0.0 - 10.255.255.255 16,777,216 8 bits mask 172.16.0.0 - 172.31.255.255 1,048,576 12 bits mask 192.168.0.0 - 192.168.255.255 65,536 16 bits mask - For example, your home network may use 192.168.0.0 - You can further divide the private address space into subnets as you wish (more on subnets later), so you could have 192.168.0.0/24, allowing for 255 ip host addresses - There must be a mechanism to translate your private IP address to a public ip address, which is called NAT (see below) - We can maximise the use of address space: - D HC P (or D yn amic Ho st C o n figuratio n Pro to co l) requires IP addresses to be leased out for small time periods, preventing inactive hosts from hogging valuable address space Computer Science / Software Engineering Notes Network - NA T (or Netwo rk A ddress Tran slatio n ) allows you to use one IPv4 address to refer to an entire private network, so each device on your network doesn‚Äôt need their own unique IPv4 address - C lassless In ter-D o main Ro utin g:allows use of any prefix length, not just /8, /16 or /24 Subnets - Remember that a subn et is a localised network behind a router (its default gateway). - The full name is ‚Äúsubnetwork‚Äù. - There are various addresses concerning IP subnets, like: - Subnet network address: - The first IP in the range - e.g. 152.78.70.0 - Subnet prefix length - How big is the prefix of the range of IPs - e.g. 24 bits, so 152.78.70.(0 to 255) is written 152.78.70.0/24 - Subnet mask (or network mask or netmask) - The fixed prefix bits for all hosts in the subnet - e.g. 255.255.255.0 - In full:11111111 11111111 11111111 00000000 - Conveys the same information as the prefix length - Subnet IP broadcast address - The IP address to use when you want to broadcast to the whole network - The last IP in the range - e.g. 152.78.70.255 - Here‚Äôs a picture of all possible subnet masks you can use in IPv4: Computer Science / Software Engineering Notes Network - So you have a subnet and a bunch of addresses you can use... - ... but not all of them can be used for hosts. - Three are reserved for: - The subnet network address (e.g. 152.78.70.0) - The subnet broadcast address (e.g. 152.78.70.255) - The address of the router, also called gateway (any other address within the subnet range, but conventionally either 152.78.70.1 or 152.78.70.254) - How do you determine a subnet (network) address? - Take the IP address and subnet mask (derived from the prefix length), and binary AND them to get the subnet network address. Computer Science / Software Engineering Notes Network - How do you determine a subnet broadcast address? - Take the IP address and wildcard mask, that is the inverted binary subnet mask, and binary OR them to get the subnet broadcast address - Determining the broadcast address for a device with IP address 172.16.17.30 and subnet mask 255.255.240.0 (/20), which is the wildcard mask 0.0.15.255: 1 7 2 . 1 6 . 1 7 . 3 0 1 0 1 0 1 1 0 0 . 0 0 0 1 0 0 0 0 . 0 0 0 1 0 0 0 1 . 0 0 0 1 1 1 1 0 0 . 0 . 1 5 . 2 5 5 0 0 0 0 0 0 0 0 . 0 0 0 0 0 0 0 0 . 0 0 0 0 1 1 1 1 . 1 1 1 1 1 1 1 1 B r o a d c a s t = 1 0 1 0 1 1 0 0 . 0 0 0 1 0 0 0 0 . 0 0 0 1 1 1 1 1 . 1 1 1 1 1 1 1 1 = 1 7 2 . 1 6 . 3 1 . 2 5 5 - ARP can also be used to find the Ethernet (MAC) address of the default router (gateway) of the network (if the destination IP is not in the same subnet). - This is why being able to use the subnet mask to determine the subnet address is important. - What happens if you screw up the subnet mask (e.g. if the network admin misconfigured the value on the DHCP server)? - If it‚Äôs too short (it is /23 when it should be /24) - Host may think a remote host is local, so it‚Äôll use ARP locally - It won‚Äôt get a response - If it‚Äôs too long (it is /25 when it should be /24) - Host may think a local host is remote, so it‚Äôll send it to the router - The router may end up redirecting the packet Calculating subnets - Here is a concrete example of how to calculate subnets - you could find a question like this in the exam: - You have been tasked with assigning IPv4 address ranges to six subnets in a new building and specifying the routing tables. You have been allocated 152.78.64.0/22 to carry out this task. How would you allocate this block of addresses to best use the Computer Science / Software Engineering Notes Network available space to cater for ‚Ä¶? In your answer you should include the network address, the broadcast address and prefix length of each subnet! - A computing lab with 260 computers - First of all, let‚Äôs determine the subnet size we need. We want to find the smallest power of two that exceeds the host count by at least three. Why three? Because one is the network address, one is the broadcast address and one is reserved for the gateway (default router). Why the smallest? Because we do not want to waste any addresses by making our subnet too large. - In this case, it is 9 because 2^9 = 512 and 512 - 3 >= 260. - So for this subnet, we will need the last 9 bits for the hosts, thus the first 32 - 9 = 23 bits are used for the network and stay fixed (Why did I use 32? Well, the whole IP address has 32 bits). Our subnet will be a /23 subnet. - Next, determine the network address for this subnet. The network address is always the lowest address. Since this is the first subnet, we are going to start with 152.78.64.0, which is given in the question. - Finally, we need to determine the broadcast address. Our network address is 152.78.64.0 and our subnet mask is /23. The broadcast address is always the highest address. Therefore we need to copy the first 23 bits and leave them unchanged, and take the last 9 bits and set them to 1. - After you do this you will get 152.78.65.255, which is our broadcast address. - So all in all our subnet is 152.78.64.0/23 with the broadcast address 152.78.65.255 - An electronics lab subnet with 200 computers - Again, we will determine the subnet size first. This time it is 8, because 2^8 = 256 and 256 - 3 >= 200. Therefore our subnet will be a 32 - 8 ‚Üí /24 subnet - To determine the network address, take the broadcast address of the last subnet and add 1. Why 1? Because we don‚Äôt want to leave any gaps and thus waste addresses in our allocation. 152.78.65.255 + 1 ‚Üí 152.78.66.0 (by doing this, we ensure that this subnet begins immediately after the last one ends) A tten tio n :This only works if the current subnet is of the same size or smaller than the last one. Otherwise, you might need to leave a gap. You can check if you need to leave a gap by checking whether the network address is the lowest one in the range. If it isn‚Äôt, you must leave a gap and skip to the next possible network address. - To determine the broadcast address, take the first 24 bits of the network address and set the last 8 bits to 1. Luckily, the first 24 bits are exactly the first 3 groups. Now we get 152.78.66.255. - All in all, our subnet is 152.78.66.0/24 with the broadcast address 152.78.66.255. - An office subnet with 110 computers - Subnet size:2^7 = 128, 128 - 3 >= 110 ‚Üí /25 - Network address:152.78.66.255 + 1 ‚Üí 152.78.67.0/25 - Broadcast address:152.78.67.127 - Also, an alternative way to calculate the broadcast address if you already have the network address is to just add the subnet size - 1 to the network address. In this case the subnet size is 128 addresses, so we will add 127. Take 152.78.67.0 + 127 ‚Üí Computer Science / Software Engineering Notes Network 152.78.67.127 and you are done. A tten tio n :this only works if you add to the network address, the other procedure works with every address within the network! This technique is especially helpful if the subnet size is 8 or smaller. - A server subnet with 60 servers - Subnet size:2^6 = 64, 64 - 3 >= 60 ‚Üí /26 - Network address:152.78.67.127 + 1 ‚Üí 152.78.67.128/26 - Broadcast address:152.78.67.128 + 63 ‚Üí 152.78.67.191 - A DMZ subnet with 25 servers - Subnet size:2^5 = 32, 32 - 3 >= 25 ‚Üí /27 - Network address:152.78.67.191 + 1 ‚Üí 152.78.67.192/27 - Broadcast address:152.78.67.192 + 31 ‚Üí 152.78.67.223 - An infrastructure subnet with 17 devices - Subnet size:2^5 = 32, 32 - 3 >= 17 ‚Üí /27 - Network address:152.78.67.223 + 1 ‚Üí 152.78.67.224/27 - Broadcast address:152.78.67.224 + 31 ‚Üí 152.78.67.255 - We are done. As a last cross-check we can verify whether our allocation fits within the range we were initially given. Wait, you don‚Äôt need to scroll up, it was 152.78.64.0/22. - Let‚Äôs determine the broadcast address. Be careful, because it might be the case that the address given is not the network address (i.e. the lowest address) of this range, so you may not be able to just use the trick I previously used and add 1023 to this address! - To determine the network address, take the first 22 bits and leave them unchanged. Set the remaining 10 bits to 0. You will get 152.78.64.0, so as it turns out, the address given was indeed the network address (which is the lowest address). - To determine the broadcast address, either set the last 10 bits to 1 or just add 1023 to the network address. You will get 152.78.67.255, which is exactly the broadcast address of our last subnet. - So to conclude, our allocation fits perfectly in the range that we were initially given. ICMP - IC MP (or In tern et C o n tro l Message Pro to co l) is a supporting protocol for sending status messages between hosts instead of actual data. - If you ping a host, that‚Äôs ICMP. - ICMP can be used to send error messages or other operational information. - ICMP can also be used for routers to tell other routers about themselves to fill out their routing tables, called ro uter advertisemen t. IP routing protocols - When a host sends a packet, it will send it: Computer Science / Software Engineering Notes Network - directly to the destination, if it‚Äôs on the same local subnet - to the router, if the destination is not on the local subnet - Hosts have no idea what goes on outside their subnet;they just send to the router and let that take care of the rest. - The router will participate in a site routing protocol, and the site routes to the Internet using a policy-rich routing protocol called B o rder Gateway Pro to co l (B GP). - To determine whether to deliver locally or forward to a router, a host maintains a small routing table, with a list of known networks and how to reach them (can be built from information learnt by DHCP or IPv6 RAs) - The table includes a local subnet in which the host resides, and a ‚Äòdefault‚Äôroute to send a packet if the destination is not in the routing table (the ‚Äòdefault‚Äôroute is usually to the router / default gateway) - But when a packet gets to the router, what do we do then? - The router needs to try to forward the packet to the destination‚Äôs router. - This is where we use routing protocols! - So, how do we solve this problem? - Static routing: - We configure the routes manually. - It works, but if the topology changes or network faults occur, we have problems - Dynamic routing: - We use routing protocols to establish a route on-the-fly, such as: - Ro utin g In fo rmatio n Pro to co l (RIP) - distance vector algorithm - Op en Sho rtest Path First (OSPF) - link state algorithm - IS-IS - link state algorithm Aggregating prefixes - You‚Äôd think all routers would need to have access to all other routers on the Internet to communicate, right? - No need;aggregated prefixes exist! - Instead of routing to 152.78.70.0/24 exactly, you can route to 152.78.0.0/16, and through there the packet can find its way into the smaller subnets, like 152.78.240.0/20, 152.78.255.128/25, and any subnet with address 152.78.??.??/x where x is greater than 16. - Let‚Äôs look at an example: Computer Science / Software Engineering Notes Network - Here, R1 serves 152.78.2.0/24 and R7 serves 152.78.64.0/23. - Instead of sending directly to R1, we can send our packet to the border router, which serves 152.78.0.0/16, which makes it an ‚Äúumbrella‚Äù router for all addresses 152.78.0.0 to 152.78.255.255. Interior routing protocols - Routing is all about routers maintaining routing tables and looking up destination addresses to know where to send off the packet to. - The routing table is, fundamentally, a table with destination IP prefixes and the interface or next hop to use. - So how do routers fill in their routing tables? Routing protocols! They allow routers to build or exchange routing information. Distance Vector - With the distance-vector routing protocol, we determine the best route from one router to the next by distance, the distance being the number of routers (or hops) from the source to the destination. - It does this by only talking to the directly neighbouring routers in a site, and uses an algorithm such as the Bellman-Ford algorithm to get the shortest distance. - An application of this would be the Ro utin g In fo rmatio n Pro to co l (RIP). - RIP is just an application of the distance-vector protocol, but with a few extra conditions. - Each router maintains a RIP routing table, storing: - Destination network - Cost (hop count);0 if network is directly connected - Next hop to use for best path Computer Science / Software Engineering Notes Network - If a router receives an update with a lower cost path to a destination network, it updates its entry for that destination - If a router receives a higher cost path later for the same destination from the same neighbour, the higher value is used because topologies can change and the lower cost route might not be valid anymore - This is all great, but RIP isn‚Äôt perfect: - Updates are only sent every 30 seconds, so things take time. Plus, updates aren‚Äôt acknowledged (UDP) so there could be message loss - Metrics are simple hop count values. What if you wanted to weight certain links? Plus, the maximum value is 15. A value of 16 means unreachable. - Routers don‚Äôt have knowledge of network topology, so this can lead to the ‚Äòcount to infinity‚Äôproblem (basically, a loop) Link state - With the link-state routing protocol, we talk to all routers and establish full knowledge of the site - Routers flood information messages describing their connected neighbours around the entire site - An application of this would be IS-IS (Intermediate System to Intermediate System) or OSPF (Open Shortest Path First). - The steps are as follows: 1. Discover neighbours 2. Determine cost metric to each neighbour 3. Construct link-state information packet 4. Flood this message to all site routers in the same area 5. Use messages to build topology, and then compute shortest paths for prefixes served by any given router - The cost is usually based on bandwidth/delay Computer Science / Software Engineering Notes Network - The structure of a link state packet is as follows: - Source ID to uniquely identify the node - Sequence to allow receiver to determine if message is a new one to process and flood, or one to discard (sender increments sequence number with each message) - Age (decremented once per second, prevents old messages persisting in the network) - All messages are acknowledged to senders - Because we know the whole topology, we don‚Äôt need to use Bellman-Ford or anything. We can just use Dijkstra‚Äôs, which is faster. Exterior routing protocols - A uto n o mo us system (A S):a network or a collection of networks that are all managed and supervised by a single entity or organisation, typically an ISP (Internet Service Provider). - An interior routing protocol is for exchanging routing information between gateways (routers) within an autonomous system. - In contrast, exterior routing protocols are for exchanging routing information between autonomous systems. - The de facto exterior routing protocol is B o rder Gateway Pro to co l (B GP). - In BGP, each ISP has a unique AS Number (ASN), assigned by RIRs (Regional Internet Registry) -they‚Äôre 32 bits long - It‚Äôs like distance-vector, but BGP includes many improvements and also incorporates the AS path associated with using a given route, the costs of the paths and many other richer attributes. - In BGP: 1. BGP neighbours, called BGP peers, are identified and create TCP sessions over port 179 2. They send their whole routing tables to each other, and send incremental updates when something changes 3. Then, the routers advertise routes they know to their neighbours, containing network prefix, prefix length, AS path, next hop etc. 4. Neighbours can then use their knowledge of ASNs to choose whether to use that route or not - Here is an example: Computer Science / Software Engineering Notes Network - F needs to get to D, but how? To get to D, F will have to go through one of its neighbours. But which neighbour should F choose? - To choose, F asks all its neighbours how they would get to D. F will then pick the neighbour with the shortest distance. - F will obviously not pick I or E, because their paths contain F itself. - F will likely pick either B or G, making the path from F to D either FBCD or FGCD. Transport layer - The transport layer handles how the information is going to be transported from the source to the destination. - There are two protocols that the transport layer can use:UDP and TCP UDP - User D atagram Pro to co l (or UD P) is a connectionless protocol on a ‚Äòfire and forget‚Äô basis. - Packets are sent to their destination with no acknowledgements. They just sort of throw packets towards the destination and hope for the best. - The properties of UDP are: - Connectionless: - No need to set up a connection with the recipient - Application layer has to retransmit, if required: - If the recipient doesn‚Äôt get the data, the application layer is responsible for resending - UDP applications use a constant bit rate: - No need to control the bit rate as the packets all come in at once anyway - The application should adapt if necessary - Low overhead: - No connection management is used, so we use less bandwidth Computer Science / Software Engineering Notes Network - The UDP header is simpler than TCP‚Äôs header - The checksum is optional - If buffers are full, packets may be dropped. The application can detect this and tell the server. TCP - Tran smissio n C o n tro l Pro to co l (or TC P) is a connection oriented protocol. - It includes acknowledgements and retransmissions. - TCP provides performance and reliability on an otherwise unreliable IP service, at the expense of an overhead. - The properties of TCP are: - Provides connection management: - A connection is established and managed - Provides flow control: - Slows down / speeds up when needed - Uses that capacity but tries also to avoid congestion: - Backs off when there‚Äôs packet loss (indicator of congestion) - Retransmission: - Sends segments again if they were unacknowledged - Receiver reassembles segments in the correct order - TCP headers are padded so that they‚Äôre a multiple of 32 bits. - Seq and Ack numbers used to track sequential packets, with SYN bit: Computer Science / Software Engineering Notes Network - TCP connection establishment uses a three-way handshake of: - SYN: ‚ÄúCan I talk to you please?‚Äù - SYN-ACK: ‚ÄúYou may talk to me.‚Äù - ACK: ‚ÄúWe are now talking.‚Äù - Each side uses a sequence number, so both parties have a common understanding of the position in the data stream - The sender must detect lost packets either: - by retransmission timeout: - Estimate when ACK is expected - by cumulative acknowledgement (DupAcks): - A type of acknowledgement that acknowledges all past data chunks - TCP uses a sliding window protocol, like go-back-N or selective-repeat back in the link layer, to perform flow control. Computer Science / Software Engineering Notes Network - Basically, the window is the same size as the recipient‚Äôs buffer space. That way, the sender can‚Äôt send any more than the recipient can handle. - Once the recipient says that it can handle more, the window is slid and further packets will be sent. - The sender sends a segment with a sequence number and starts a timer. - The receiver replies with an acknowledgment number showing the next sequence number it expects and its available buffer/window size. - If the receiver doesn‚Äôt send anything by the time the timer goes off, the sender resends. - If the receiver says the window size is 0, the sender may send a 1-byte probe to ask for the window size again. - Here is an example, with dialogue to show you what‚Äôs going on: - LEFT:‚ÄúThis is packet 0 (#1), it‚Äôs 2K in size‚Äù - RIGHT:‚ÄúNice;I want packet 2048 (#2), and I have 2048 bytes of space left‚Äù - LEFT:‚ÄúHere‚Äôs packet 2048 (#2), it‚Äôs 2K in size‚Äù - RIGHT:‚ÄúGreat;I would want packet 4096 (#3) now, but I‚Äôm full (I have 0 bytes of space)‚Äù - RIGHT:‚ÄúOK, I want packet 4096 (#3) now, and I have 2048 bytes of space‚Äù - LEFT:‚ÄúAlright, here‚Äôs packet 4096 (#3), it‚Äôs 1K in size‚Äù Computer Science / Software Engineering Notes Network - If the connection started to get congested, how does TCP control this? - TCP actually has two windows:a ‚Äúrecipient buffer‚Äù window and a congestion window. - The recipient buffer window is defined just above;it‚Äôs how much the receiver can take in before it gets full. - The congestion window does its best to prevent congestion in the connection (too much data flying through means more packet loss) - A congestion window starts off small, and grows if everything is going alright. It resets if there is a timeout. - The window size doubles each time, until a threshold is reached, at which point it‚Äôll increase linearly, called C o n gestio n A vo idan ce. - After a timeout, the threshold decreases a bit. - So which window do we use;the recipient buffer window or the congestion window? - We use whichever one is smallest. - Here is a graph showing the size of the window changing with each transmission: Computer Science / Software Engineering Notes Network TCP or UDP? - Streaming services and voice over IP use UDP because it‚Äôs immediate and has limited buffering. - Web services like HTTP and SMTP use TCP because having a structured connection is more important. - DNS uses UDP because the overhead for TCP would be too much for processing 100 to 1000 requests per second. - Here are the differences between TCP and UDP: TC P UD P C o n n ectio n Connection oriented Connectionless:‚Äúfire and forget‚Äù Reliability Handles ACK & retransmissions Application needs to handle ACK & retransmissions if needed D ata Order Guaranteed that it arrives and in the correct order No guarantee that data is received in the order sent Header 20-bytes minimum 8-bytes Go o d fo r Applications that need high reliability Applications that need fast and efficient transmission Examp le p ro to co ls HTTP(S), FTP, SMTP, Telnet, SSH DHCP, TFTP, SNMP, RIP, RTP, COAP - Here is a graphic showing the layers and what protocols they use: Computer Science / Software Engineering Notes Network Sockets - A socket is created when a sender and a receiver act as communication endpoints. - A socket has an IP address and a port number, for example 152.78.70.1 port 80 - The socket and bind protocol uniquely identify the application‚Äôs subsequent data transmission. - When multiple clients talk to one server, there is usually one thread per client endpoint. - There is a sockets API, called the Berkeley sockets API. Servers mainly use SOCKET and BIND, whereas clients tend to use SOCKET and CONNECT: Computer Science / Software Engineering Notes Network DNS - First of all, what is a DNS? - The D o main Name System (or D NS) is a naming system for pairing up domain names to IP addresses. - For example, when you search up ‚Äúgoogle.com‚Äù, you‚Äôre actually talking to an IP, such as ‚Äú216.58.213.110‚Äù, and the DNS translates ‚Äúgoogle.com‚Äù to that IP for you. - DNS names are delegated through the Top Level Domain (TLD) registrars - For example, with soton.ac.uk: - first the ‚Äú.uk‚Äù bit is delegated by Nominet - then the ‚Äú.ac.uk‚Äù bit is through Jisc - then finally, the whole thing ‚Äú.soton.ac.uk‚Äù comes down to the University of Southampton - It allows sites and organisations to maintain authority over their registered domains. - The most common DNS lookup is host name to IP. - The DNS returns an A record for IPv4 or AAAA record for IPv6 when queried for a specific host/domain name. - This means clients need to know the IP addresses of local DNS servers (resolvers) so they can actually send the queries. - A D NS reso lver is a server that acts as a DNS server that resolves queries and sends an answer back. - Client hosts are configured to use one or more local DNS resolvers. They‚Äôre usually provided via DHCP. - Clients can use APIs to do DNS lookups. You can even do it via a CLI tool. - Packets sent to DNS resolvers are usually UDP packets, but they can use TCP. - They use UDP because it‚Äôs connectionless and quick. - The results of queries can be cached. - Here is a list of DNS record types: Computer Science / Software Engineering Notes Network - Campuses will run their own DNS servers, so they can: - act as resolvers for internally sourced DNS queries - act as servers for external queries against internal names - Some DNS infrastructures also may provide a ‚Äòsplit DNS‚Äôview, which is where separate DNS servers are provided for internal and external networks as a means of security and privacy management. - If DNS servers are local, then how does a client talk to a server from across the world? - We leverage the hierarchical delegation structure! What? That doesn‚Äôt make sense? - Basically, we have a set of ‚Äúroot‚Äù DNS servers that can point us to other DNS servers that know about different URL suffixes. - For example, if we were looking for ‚Äúwww.google.co.uk‚Äù, the root DNS could point us to another DNS server and say ‚Äúgo to them, they know all about URLs ending in uk‚Äù - Then that DNS server could point us to another DNS server and say ‚Äúgo to them, they know all about URLs ending in co.uk‚Äù - ... and so on until we reach a DNS that knows the IP address for www.google.co.uk. - Mapping one DNS to another DNS is known as D NS glue. - So in other words, to get your IP from your host name, your browser goes on one big adventure, going from DNS to DNS, looking for the IP. Computer Science / Software Engineering Notes Network - This can also be cached, so we don‚Äôt hit DNS servers heavily. - DNS resolvers are critical to Internet infrastructure. - Because of this, people like to attack them. - Therefore, we need to make them resilient and strong. - Root servers are the ‚Äòanchor‚Äôfor recursive DNS‚Äô. - If someone managed to shut down all the root servers, they could shut down the Internet. - There are 13 highly available clusters of root servers. There are about 1000 servers in total used in these clusters, and a server is picked in a cluster via anycast. - This makes DNS servers more distributed and allows clients to use the most local server, improving performance. - It also helps spread the load, and mitigate DoS attacks. - IP an ycast is where the same IP is configured in many locations, and your network picks the closest one to connect to. - This is especially applied to DNS servers, as picking the closest DNS server means you get better performance. - It also means you don‚Äôt have to reconfigure your network when you‚Äôre in a different place;because of anycast, your network just picks the closest DNS server anyway. - Fast flux D NS is a technique where the association between an IP address and a domain name is changed very frequently. - This is used in some peer-to-peer systems, but it can also be used by botnets (the bad guys) to avoid detection and make takedown harder (so they don‚Äôt get caught by the good guys) - Public D NS servers are open public servers. They also answer queries for domains, recursively. An example is the Google public DNS server. - Why use them? - Speed improvements - Reliability - Parental controls Computer Science / Software Engineering Notes Network - Phishing protection - Security - Access geoblocked content - Bypass web censorship - However, you don‚Äôt know who‚Äôs logging your queries (and with a company like Google, can you really trust them?) Application layer - The application layer provides higher level services. - In the TCP/IP layer, it‚Äôs just called ‚ÄúApplication‚Äù, but in the OSI Model layers, the application layer is split up into ‚ÄúApplication‚Äù, ‚ÄúPresentation‚Äù and ‚ÄúSession‚Äù. Telnet - Teln et:Simple unencrypted terminal emulation protocol - In other words, it provides a bidirectional text-based communication service using your terminal, like a Unix / DOS chatroom! - It was big in the 90‚Äôs, but nobody really uses it anymore because 1. It‚Äôs old and computer normies non-techies don‚Äôt like using terminals 2. It doesn‚Äôt even have security, it‚Äôs unencrypted - Today, it‚Äôs mainly used as a plot device in films (like Die Hard 4) and watching the original Star Wars in ASCII (the server is t o w e l . b l i n k e n l i g h t s . n l ) . Computer Science / Software Engineering Notes Network Email - There are two main protocols for emailing:SMTP and IMAP. SMTP - SMTP (Simp le Mail Tran sfer Pro to co l):a protocol used to send emails. - It uses TCP to connect to a mail server and uses the commands MAIL, RCPT and DATA. - Authentication is an extension;you don‚Äôt need it, but you should have it by now. Original emails didn‚Äôt have it. - You can use SMTP quite easily in modern languages, like Python and PHP. - How does SMTP work? Well, if you‚Äôve been reading my notes, you know I prefer to go in detail about stuff like this (within reason). Computer Science / Software Engineering Notes Network - If this illustration isn‚Äôt enough, here‚Äôs some dialogue, where Alice is the sender and Bob is the receiver: 1. A lice:‚ÄúHey, do you want to start a TCP connection?‚Äù 2. B o b:‚ÄúYes. Let‚Äôs talk in TCP.‚Äù (220 message) 3. A lice:‚ÄúAlright, let‚Äôs begin. Hello! Tell me what you can do.‚Äù (EHLO extended hello message) 4. B o b:‚ÄúOK. Here‚Äôs what I can do:(a list of things Bob can do)‚Äù (250 message with list of supported SMTP extensions) 5. A lice and B ob start performing mail transactions (you don‚Äôt need to know these) 6. A lice:‚ÄúI‚Äôm done with you. Let‚Äôs stop talking.‚Äù 7. B o b:‚ÄúOK. Goodbye.‚Äù Bob stops listening to Alice (221 message, Bob closes transmission channel) 8. A lice receives B ob‚Äôs goodbye and also stops listening to B ob. IMAP - IMA P (In tern et Message A ccess Pro to co l):a protocol used to retrieve emails. - It was designed in 1986 and listens on port 142 (993 for the secure version) - It keeps a TCP connection open to send requests or receive notifications. HTTP - HTTP (Hyp erText Tran sfer Pro to co l):a text-based protocol that uses TCP and uses port 80. - There are two steps to using HTTP: - Send a request (e.g. GET /something/page.html HTTP/1.1) - Receive a response message (e.g. HTTP/1.1 200 OK) Computer Science / Software Engineering Notes Network - A typical response might contain things such as: - Version of HTTP - HTTP status code - Date - Content type (text, html, xml etc.) - Server type - The main types of HTTP requests are: - GET - simply retrieve data - HEAD - like GET but no data is sent back - POST - send data to server, usually to create records - PUT - send data to server, usually to edit existing records - DELETE - send data to server, usually to delete a record - You can tell the variety of a status code by the left-most digit: - 1xx -> Information - 2xx -> Success (e.g. 200 ok) - 3xx -> Redirection (e.g. 301 moved) - 4xx -> Client error (e.g. 403 forbidden, 404 not found) - 5xx -> Server error (e.g. 500 internal error) - You can send HTTP requests using the w g e t or c u r l commands in Linux. HTTP/2 - The first major revision to HTTP, published in 2015 - The header is now compressed as binary using HPACK, a header compression algorithm. However, now, the whole packet is binary, not just the header. - It also has Server Push, which means resources are sent to the client before they even ask for them. No, it doesn‚Äôt use King Crimson and erases time, instead it goes like this: - Let‚Äôs say you requested i n d e x . h t m l , and that page uses s t y l e s . c s s and s c r i p t . j s . Normally, you‚Äôd request for i n d e x . h t m l , receive that, find out you need s t y l e s . c s s and s c r i p t . j s , and do separate requests for those assets, too. - With Server Push in HTTP/2, the server already knows that you‚Äôll need s t y l e s . c s s and s c r i p t . j s , so it prepares those responses in advance before your browser even has the chance to parse i n d e x . h t m l . - It can also multiplex multiple requests over a single TCP connection. QUIC - QUIC (Quick UD P In tern et C o n n ectio n s):A UDP protocol to make the web faster, and possibly replace TCP. - It‚Äôs pushed by Google, and it still establishes some ‚Äústate‚Äù/sessions and encryption. - It‚Äôs experimental, which is why you‚Äôve probably not heard of it. Computer Science / Software Engineering Notes Network - HTTP/3 will be based on QUIC instead of TCP. CoAP - C o A P (C o n strain ed A p p licatio n Pro to co l):provides HTTP-like protocol for simple devices - It has a minimal overhead, perfect for small devices. - Binary encoding for GET / PUT / etc. - It has a simple discovery mechanism and a simple subscribe method - It‚Äôs used in things like Ikea smart lighting. RTSP - RTSP (Real Time Streamin g Pro to co l):a protocol used for streaming video / audio - It‚Äôs used by YouTube and Flash players (R.I.P.). - Video frames are packetized so that losses do not corrupt the whole stream. - It has a URL scheme with arguments, similar to HTTP GET. - Real-time transport protocol (RTP) delivers the media (typically with UDP). SMB - SMB (Server Message B lo ck):a file-sharing protocol from Microsoft that can use either TCP with port 445 or UDP. - It provides authentication, file locking etc. - It‚Äôs provided in Samba within Linux. Computer Science / Software Engineering Notes Network NFS - NFS (Netwo rk File System):a file-sharing protocol mainly used in Unix / Linux. - It‚Äôs common between servers and can cope with very large files and file numbers. P2P - P2P (Peer-to -p eer):instead of using a server-client model, every device has the same priority and shares data with each other. - It distributes the content efficiently across everyone, instead of having one master device rule all. - BitTorrent uses this for files (as you probably know). IPv6 - Why do we need IPv6? - We‚Äôre running out of IPv4 addresses! - The organisations handing out IP addresses (called RIRs) have no unallocated address blocks. - It started off with alpha support in 1996, but drafts for the IPv6 standard was established in 1998. - In the bizarre summer of 1999, IPng Tunnelbroker started, which ‚Äútunnelled‚Äù v4 to v6. - They started putting them in servers at 2004, but major PC operating systems didn‚Äôt start supporting them until 2011. - Now, people are starting to use it more, for instance in 2016 Sky has 80% IPv6 coverage. - It became an internet standard in July 2017. Computer Science / Software Engineering Notes Network IPv6 Features - So what can v6 do? - It has a 128-bit address, as opposed to the 32-bit v4 address, so there‚Äôs 3 . 4 * 1 0 3 8 IPv6 addresses. - If we gave each grain of sand on Earth a global address, we‚Äôd only take up 0.000000000000000002%, or of the total number of addresses we have.2 * 1 0 ‚àí 1 8 % - To put it in perspective further, if we had a copy of Earth for every grain of sand that exists on this Earth, and we gave global addresses to all the grains of sand on every copy of Earth, we‚Äôd still have addresses left over! Basically, that‚Äôs a lot of addresses. - IPv6 addresses are usually written in colon-separated hex format, to keep it shorter. - Leading 0‚Äôs are also omitted, and a single set of repeated 0 blocks can be replaced with ‚Äú::‚Äù. - e.g. address 2 0 0 1 : 0 6 3 0 : 0 0 d 0 : f 1 0 2 : 0 0 0 0 : 0 0 0 0 : 0 0 0 0 : 0 0 2 2 - can be shortened to 2 0 0 1 : 6 3 0 : d 0 : f 1 0 2 : 0 : 0 : 0 : 2 2 - which can be shortened to 2 0 0 1 : 6 3 0 : d 0 : f 1 0 2 : : 2 2 - Remember that you can only do this once, or else there will be confusion over where the zeros are! Source - Some other features include: - Subnets are represented in CIDR notation (like v4, e.g. 2 0 0 1 : 6 3 0 : d 0 : f 1 0 2 : : / 6 4 ) - Not as easy to remember as v4 because it‚Äôs longer, but you shouldn‚Äôt care - Multicast is an inherent part of v6, and used in subnets instead of broadcast - v4 and v6 can co-exist in dual-stack deployments - Just like how v4 had preset addresses, v6 has address scopes dedicated to certain tasks: - : : 1 / 1 2 8 - lo o p back - : : / 1 2 8 - un sp ecified (equivalent to 0.0.0.0) - f e 8 0 : : / 1 0 - Lin k-lo cal address (used only on local link) - f c 0 0 : : / 7 - Un iq ue Lo cal A ddress (ULA , used within a site) - 2 0 0 0 : : / 3 - Glo bal Un icast - f f 0 0 : : / 8 - Multicast - Hosts usually have multiple v6 addresses! - There are conventions, too: - / 1 2 7 can be used for inter-router links - Smallest subnet is a / 6 4 (which still allows 18 quintillion addresses) - Home / small business users should be given a / 5 6 - A ‚Äúsite‚Äù is usually given / 4 8 - Minimum v6 allocation from RIR is / 3 2 - Any subnet larger than /64 can be used Computer Science / Software Engineering Notes Network - We know that v4 addresses are running out, but are there any technical benefits to v6?- No more NAT - More ‚Äúplug-and-play‚Äù than v4 (require less setting up as Stateless auto configuration (SLA A C ) works) - Streamlined header, so more efficient routing and packet processing - Fragmentation occurs at sender, so less strain on routers Why use v6? - If v4 works for now, why swap to v6 early? - You should get familiar with v6 before it becomes mandatory - You can secure v6 and still use v4 - Support for new applications - Enables innovation / teaching / research - To be fair, those last two are only for companies. IPv6 headers - IPv6 headers are a fixed 40 bytes, which is bigger than IPv4, but simpler. - It uses extension headers rather than options, and has 8 fields: - Versio n :represents the version of the Internet Protocol i.e. 0110 - So urce A ddress:the address of the originator of the packet - D estin atio n A ddress:the address of the recipient of the packet - Traffic class:indicates class/priority of the packet - Flo w label:a ‚Äúhint‚Äù for routers that keeps packets on the same path - Paylo ad len gth:size of the payload + extension headers - Next header:indicates the type of the next header - Ho p limit:equivalent to the ‚Äútime to live‚Äù field from v4 - Extension headers carry optional Internet Layer information, and sits after the v6 header but before the transport layer header in the packet. - It‚Äôs equivalent to the options field in v4 - Fragmentation is an extension header - Extension headers can be daisy chained, but must be in order - Each extension header has a ‚Äúnext header‚Äù field, hence the daisy chaining - Each extension header is a multiple of 8 bytes Computer Science / Software Engineering Notes Network IPv6 with routers and privacy - The way v6 handles neighbour discovery replaces ARP and ICMP Router Discovery. - There are five ICMPv6 packet types: - Ro uter so licitatio n :host requests router information - Ro uter advertisemen t:tells other routers about itself - Neighbo ur so licitatio n :equivalent to ARP ‚Äúwho has __‚Äù - Neighbo ur advertisemen t:equivalent to ARP reply - Redirect:router informing host of a better first-hop (in other words, a router correcting a host of a more efficient path) - When a host sees or solicits a Router Advertisement (RA): - The RA message carries the v6 network prefix (/64) to use - The RA source address implies the default router address - DNS server information can be in the RA - Prefix information is sent by multicast: - Periodically (usually every 600 seconds) - On request (in response to a Router Solicitation) - IPv6 can also automatically configure basic network settings without a DHCPv6 server, using something called StateLess A ddress A uto C o n figuratio n (SLA A C ). - A host using SLAAC builds it‚Äôs address from: - A 64-bit prefix from a Router Advertisement - A 64-bit host part generated from the MAC address - It‚Äôs a security issue to embed your MAC address in your global address, because the host part stays the same across networks, meaning it‚Äôs easier for people to track you. - A privacy extension of RFC 2941 adds a random 64-bit host part, used for outgoing connections, to mitigate this issue. - There‚Äôs an alternate method too in RFC 7217 that does not use a MAC address, and it mitigates many of the security / privacy issues of before. Deploying IPv6 - The Internet is mostly v4. How do we get all the benefits of v6? - One approach is:‚Äúwhy not both?‚Äù. It‚Äôs called ‚Äúdual stack‚Äù. - We might also have v4-only systems or v6-only systems that need to talk to each other. - A dual stack system runs both v4 and v6 on the same equipment. - You may need to rewrite/update applications and pick when to use v6 or v4 (typically, it‚Äôs use v6 if available) - You still require a v4 address space, because you use v4, and you need to secure both protocols (e.g. firewall). - How do you translate from v4 to v6 and vice versa? Computer Science / Software Engineering Notes Network - You could: - Rewrite the header information - Use Application Layer Gateways (ALGs) - NA T64:a Nintendo 64 game using NAT to convert single IPv4 address to IPv6 network - D NS64:‚Äúfabricates‚Äù AAAA record for non-IPv6 sites that points to an IPv6/IPv4 translator - There‚Äôs also a variety of tunnelling technologies to use: - 6in 4 - encapsulates v6 packets in v4 packets - Teredo - encapsulates v6 into UDP v4 - D S-Lite (no, not the console) - encapsulates v4 packets in v6 packets - VPNs work too - What‚Äôs the best? Like Totally Spies, there is no best;some are suited to certain scenarios. - We‚Äôre still going to use v4 for a long time, but the focus at the moment is dual-stack. v6-only is growing, though. - Everyone‚Äôs using v6 now! Youtube, Dropbox, LinkedIn, Wikipedia, major ISPs... - Home routers lack v6 support because people in general (normies) don‚Äôt want to learn something new, and network administrators lack the desire to understand v6. IPv6 security - IPSEC encryption is baked into v6. - There‚Äôs tonnes of addresses (as you know), so scanning is less feasible. - Transition mechanisms (like tunneling and Teredo) can bypass network security mechanisms. - v6 implementations still have flaws that are undiscovered (e.g. Windows is susceptible to Router A dvertisement flooding) - v6 hosts can pick their own address. - To track which devices are used where, we can poll switches and routers for MAC table and ARP table information. Other IPv6 stuff - Don‚Äôt be an uninformed IPv6 normie! Know your stuff with this FAQ: - Q:We don‚Äôt need IPv6, with CGNAT and address recovery, we have a lot more addresses. - A :Those can only get you so far until you come crawling back to IPv6. - Q:IPv6 replaces IPv4 - A :Wrong. They will co-exist for years to come. - Q:IPv6 is more complicated than IPv4 - A :The concepts are similar or simpler. You‚Äôre just lazy. - Q:IPv6 is less secure because there‚Äôs no NAT - A :NAT isn‚Äôt a security mechanism and v6 has firewalling/ACLs. Computer Science / Software Engineering Notes Network - Q:IPv6 probably won‚Äôt be in the exam, so I won‚Äôt revise it - A :Fool! It‚Äôs Sod‚Äôs Law that the one thing you don‚Äôt revise on will be on the exam. I know it‚Äôs boring, but please read all the sections. - As long as you know these answers, you can now become ‚Äúthat guy‚Äù by preaching to everyone about how IPv6 is the best thing ever and that you‚Äôre better than everyone still using IPv4! - So, summary pls? - IPv6 good, IPv4 bad Network security - Security is very important, as you know. - You can never be 100% secure! - The human element is often the weakest link in a system, hence why things like phishing are so harmful. - Anyone can be an attacker, and they can have any motive, so stay sharp and read this section to pass the exam be more aware of cyber attacks! DNS Security - DNS can be exploited to break something! - A D NS amp lificatio n attack is an attack where: 1. The attacker sends tons of messages to a DNS with the victim‚Äôs source IP 2. The DNS spams the victim with DNS response messages 3. The victim is overloaded with DNS messages and dies (not really, but you get the picture) - So how do we trust DNS responses? - It‚Äôs not signed or encrypted, and messages can be spoofed, so no, we can‚Äôt trust DNS responses. - There was even a campaign called DNSpionage which used this. - OK, so DNS is insecure, but what information could it possibly leak? - Well, your connection to a server may be encrypted, so what you‚Äôre doing is safe. But since DNS is insecure, where you‚Äôre doing it isn‚Äôt safe. - This means third parties know where you‚Äôre doing stuff, and that‚Äôs usually all they need to know to get your usage patterns. - So, that‚Äôs it? Privacy is dead and we‚Äôre all going to die? - Not quite:D NSSEC addresses DNS insecurity and was developed 10 years ago, and is still being worked on to this day. - It allows responses to be signed, but that makes them bigger and more complex to manage. Still, it‚Äôs worth it. - Lots of people deploy it (like Jisc for .ac.uk and Nominet for .uk), but some haven‚Äôt yet (like iSolutions for .soton.ac.uk). Computer Science / Software Engineering Notes Network - There‚Äôs other things too, like blocking non-local look-ups, or ignoring certain kinds of requests. Firewalls - NAT is NOT a security mechanism!!! >:0 (I mean, I don‚Äôt remember anyone saying it was, but oh well) - A firewall is a network device that sits at the edge of a network and operates at the Network layer. - It acts as a packet filter, and blocks packets that do not fit a set of rules. - Stateless firewalls, or firewalls that work simply by testing predicates on packets, are limited (e.g. to allow all packets on port 80 would mean an attacker can attack on that port). - Sod that;in this day and age, you want a stateful firewall! - These firewalls keep track of connections, and map packets to connections. - There are rules for related and established packets, e.g. allow outbound port 80 packets but disallow incoming port 80 packets unless it‚Äôs in relation to an existing connection, which makes sense;a server doesn‚Äôt just randomly give you a web page! - A common set of rules for home networks is: - Deny all inbound rules unless related / established - Allow all outbound - You can have even more powerful firewalls that act on the application layer. - These firewalls actually snoop around your packets, checking if they look like what they‚Äôre supposed to. - For example, look at these two packets: Packet #1 o n p o rt 80 Packet #2 o n p o rt 80 < ! D O C T Y P E h t m l > < h t m l > < h e a d > < t i t l e > J o J o h o m e p a g e < / t i t l e > < / h e a d > < b o d y > < h 1 > J o s e p h J o e s t a r < / h 1 > < p > B e s t J o J o < / p > < p > m a y b e j o s u k e t o o < / p > < / b o d y > < / h t m l > < ! D O C T Y P E h t m l > / / i ‚Äô m a r e a l p a c k e t i p r o m i s e r e m o v e _ f o l d e r ( s y s t e m 3 2 ) Computer Science / Software Engineering Notes Network - Packet #1 looks like an actual HTML document, whereas packet #2 looks shifty and suspicious. An application layer firewall might be able to spot the difference. - However, this won‚Äôt work in all cases, especially when packets are encrypted, as SSH might look like HTTP. - At home, everything is packaged into one platform: - a router - DNS resolver - DHCP server - NAT implementation - network switch & wireless access point - At workplaces, you might have a firewall device on its own, or embedded in the router. Intrusion Detection Systems - Someone may get into your network, or an actual user might do something stupid in your network. - How do you prevent this? Use NID S (Netwo rk In trusio n D etectio n System)! - NIDS sniffs around in your network, looking for suspicious activity. - The detection may be signature based, or anomaly-based. - Some NIDS implementations might only be able to notify you, but some may be able to take action and prevent intrusion. Port / Physical Security - If someone physically breaches a network, that‚Äôs a lot harder to protect against. - Fortunately, we have NA C (Netwo rk A ccess C o n tro l) mechanisms! - The simplest of which is to filter MAC addresses. However, it‚Äôs easy to circumvent and it has an administration overhead. - A better solution is 802.1x (creative name). - It uses Exten sible A uthen ticatio n Pro to co l (EA P) to authenticate clients. - It has three parties: 1. A supplicant (client) 2. An Authenticator (switch or access point) 3. An Authentication Server (e.g. LDAP using RADIUS) - It blocks the client until they authenticate themselves. - NACs can also have other features, like anti-virus - However, NAC doesn‚Äôt stop parties from sniffing traffic. Therefore, we need IPSEC (IP Security), which is encryption at the Network Layer. - There‚Äôs also VPNs (Virtual Private Netwo rk), that simulates a direct connection between devices. - It allows you to use internal services from the outside, and uses encryption. Computer Science / Software Engineering Notes Network - There are two kinds: - Site-to -Site VPN:connects two different networks together, e.g. a branch office to head office - Remo te-access VPN:where individual clients connect to a VPN server e.g. Globalprotect - These notes are brought to you by ExpressVPN! - Basically, if you didn‚Äôt know, a VPN is a service that encrypts your Internet data and gives you additional security! - It also works on phones and other devices! - You open the program, single tap, and it‚Äôs on! - I use ExpressVPN because privacy is important, keeps my information anonymous and safe from third parties. - Also, it has a 30-day money back guarantee and 30% off the first month when you use the code ‚ÄúNOTESNETWORK‚Äù. - Take back your Internet privacy today by clicking on the link: expressvpn.com/notesnetwork - And now, on with the notes! WARNING:It‚Äôs a joke DDoS - A DDoS (D istributed D en ial o f Service attack), or any DoS attack, is an attack that targets a system and puts them out of service to cause disruptions. - This can be done by consuming: - Network bandwidth - CPU cycles - Server state capacity - Other system resources - DoS attacks aren‚Äôt the focus;they‚Äôre usually used to distract others from the real threat, like: - Deploying malware - Stealing data - Single source attacks (DoS) are effective, but multiple source attacks (DDoS) can be more effective, as it deprives the target of more bandwidth, and it‚Äôs harder to stop as there‚Äôs lots of sources. - One example of a DDoS attack is the TCP SYN flood. - How it works is: 1. Attacker connects with target 2. Attacker sends ‚ÄúSYN‚Äù 3. Target sends ‚ÄúSYN ACK‚Äù, and is now expecting an ACK back 4. Attacker never sends ACK back Computer Science / Software Engineering Notes Network - Normally, that wouldn‚Äôt be so bad for one client, but what if thousands of attackers did that at the same time? - It consumes state on the server and it doesn‚Äôt take much bandwidth to do;just lots of systems. - There are programs that can be used to perform a DDoS attack, like: - Low Orbit Ion Cannon (LOIC) - High Orbit Ion Cannon (HOIC) - There‚Äôs also a unique kind of DDoS called SlowLORIS, and is explained in detail here. - There‚Äôs also IPv6 RA flood, where you flood a target with IPv6 RA multicasts. - It makes targets join dud networks. - It‚Äôs mainly a problem with Windows, Mac OS and Linux aren‚Äôt really affected as much. - What are we going to do to prevent this? - There‚Äôs no clear way to prevent this, but there‚Äôs ways to mitigate it: - A n ycast/co n ten t delivery n etwo rks:spread the load across lots of networks/systems - Resp o n sive n etwo rk team:block attacks as they occur and redistribute services across different connections - Go o d relatio n ship s with up stream p ro viders:get them to help blocking attack traffic - DDoS is easy to attack with, but hard to defend against. Wi-Fi (In)Security - Obviously, wireless networks are less secure than wired ones. - All clients have access to all traffic in a wireless network. - It‚Äôs clear that wireless networks require some kind of encryption. - One of the old wireless encryption methods is WEP (Wired Eq uivalen t Privacy). - It uses a 40-bit or 104-bit key and 24-bit IV, and uses the RC4 stream cypher - It was proved insecure in the early 2000‚Äôs, so don‚Äôt use it anymore! - The FBI proved that WEP is crackable in 3 minutes. Computer Science / Software Engineering Notes Network - So they made a better one:WPA and WPA/2. - WPA (WiFi Pro tected A ccess I) is more of a fix for WEP and used Temp o ral Key In tegrity Pro to co l (TKIP) - WPA /2 (WiFi Pro tected A ccess II) is more complex than its predecessor and more secure, and uses a 128-bit AES (encryption standard). - WPA -Perso n al:uses pre-shared keys - WPA -En terp rise:uses 802.1x authentication (for that extra pinch of security) - WPA are not without their weaknesses though! - If you have a crap password, like ‚Äúpassword‚Äù (who even uses that anymore) then you‚Äôre far more likely to get hacked, even using WPA. - If the generation of keys are weak, they can be ‚Äúguessed‚Äù from the SSID e.g. old BT routers could have their keys guessed from a spreadsheet Distributed Systems Implementations (Tim) Distributed Systems Models Physical models - There are really only 4 physical models: - Early 80‚Äôs:up to 100 nodes connected by LAN - In tern et-scale (90‚Äôs):large nodes connected by Internet;nodes are static, not embedded and autonomous - C o n temp o rary:hundreds of nodes, and nodes can change location. Can be embedded - Emergin g:systems of systems Architectural models - Types of communication paradigms: - In ter-p ro cess communication:low-level communication e.g. Java sockets - Remo te invocation:two-way communication, sending and receiving - In direct communication:one-to-many communication using groups, message queues, distributed shared memory systems etc. - Two main architectural models: - C lien t-server architecture:there‚Äôs one central ‚Äúserver‚Äù node, and lots of other ‚Äúclient‚Äù nodes that query a server with resources. Servers can also be used as clients. - Peer-to -p eer architecture:all processes share similar roles, and data is distributed amongst peers. Used in software like Gnutella or BitTorrent. Computer Science / Software Engineering Notes Network Mapping entities to infrastructure - It‚Äôs not good enough to just have a cool network with lots of techy features. - Your system must be fit for purpose and be mapped to the infrastructure it manages. - For example, a logistics network could be mapped to road, rail, etc. infrastructure - How do we tailor our networks to fit into a mapping to infrastructure? - There are three strategies we can apply: - Use of multiple servers - several servers implement a service and distribute resources and services to increase performance - Proxies and caches - make web proxies store often used data to make it more quickly accessible - Mobile code - send code to the recipient, so they can run the code locally, which improves performance (but can also be a security threat) Architectural patterns - There are several architectural patterns that networks can follow: - Layering - A vertical organisation of services into layers, with each service making use of the service below it (similar to OSI model or TCP/IP model) - Two-tier and three-tier architectures - Splits the system into different logic categories - For two-tier it‚Äôs view and model-controller - For three-tier it‚Äôs view, controller and model Computer Science / Software Engineering Notes Network - Thin clients - Moves complexity away from the end-user and do all the hard computational stuff on the server. - Popular with Software-as-a-service (SAAS) in cloud computing - The point is that the client only has a handful of features (mainly a UI hooked up to some web requests) and the server does all the work - The opposite is called a thick client - Proxies - Web proxies offer the same interface as the server they‚Äôre trying to mirror - Supports location transparency when doing RMI (remote method invocation) Fundamental models:Interaction, Failure and Security - The three fundamental models include: - Interaction - Models how the participants interact with each other - There are two flavours: - Synchronous:we specify bounds about things like: - the time to execute each process step - the time to transmit a message over a channel - the drift of the local clock from real time Computer Science / Software Engineering Notes Network - A synchronous:we don‚Äôt care about stuff like that;messages can happen as and when - Often, distributed systems are asynchronous, which are harder to work with than synchronous because they need to handle actions in any order. - However, some problems can only be solved in synchrony (e.g. multimedia data stream) - Failure - Describes the types of failures that can happen, and what we can do to mitigate them - We categorise the types of failures: - Omission - failed to perform the action - A rbitrary (B yzantine) - performed the wrong action / lies - Timing - performed at the wrong time (only in synchronous systems) - We can mask failures either by: - Hiding - do something to rectify the failure (think of it like a try-catch) - C onversion - convert the failure to another kind of failure, so we can handle it (e.g. a corrupted message would initially be captured as an arbitrary failure, but we can convert it to omission once we realise it‚Äôs corrupted) - To ensure reliable one-to-one communication, you need: - Validity - every message is eventually delivered - Integrity - received message is identical to the one sent, and every message is only sent once - Security - Ensures security in both processes and communication - To ensure security, we need to model threats, more specifically a ‚Äúman - in - the - mirror middle‚Äù - There are threats to both processes and communication: - Threats to processes:how can you trust the source of the message? An attacker can use a false identity when sending a request to the server (like a DNS amplification attack). You can‚Äôt tell. - Threats to communication channel:attackers can copy, alter or inject messages - But by using secure channels, we can kill two birds with one stone and patch these problems! - A secure channel uses existing encryption and authentication technologies (like SSL and TLS). - Every process knows the identity of every other process (via Trusted Third Party) and can check access rights before performing operations, so no man-in-the-middle can meddle. - It ensures privacy and integrity of data, and timestamps are used to prevent replaying or reordering messages. Computer Science / Software Engineering Notes Network - You also need to protect objects encapsulated by a distributed application. - This is called access co n tro l. Usually, access rights are associated with each principal (a user associated with an object, either the one requesting it or the one who owns it) - For example, XACML policies are enforced at the server based on the identity of the client. - Encryption and access control are great, but they don‚Äôt address DoS attacks. - Also, how do we deal with mobile code? How do we trust it? - Digitally signed code? - Run it in a sandbox? - I don‚Äôt know. I just write the notes. Distributed Object Systems Distributed OOP - There‚Äôs a thing called RMI (Remo te Metho d In vo catio n ). - Basically, you call methods on remote objects, as if they are local. - It‚Äôs crap and it‚Äôs not used anymore. But you still need to learn it to pass the exam see the advantages of other more modern approaches :) - The server sets up a bunch of remote objects and make their references accessible. - The client obtains remote references and invokes methods. - Java.rmi package gives programs API to perform these kinds of RMI operations. - Remote references are passed by parameters - Clients have proxies, or ‚Äústubs‚Äù, that allows clients to communicate with the server. Computer Science / Software Engineering Notes Network - Java objects are instantiated from a compiled class, so RMI has to load classes from remote sites. It needs serialization and transmission of class specifications. - There are two fundamental concepts of RMI: - Remote object reference - so the client can talk to the server - Remote object interface - so the client knows what to do with the remote object Remote Interfaces - There is an interface called Remote. - If an interface extends Remote, it can become a remote interface. - The methods in a remote interface can be accessed remotely. - Any object can be a remote object if it implements a remote interface. - A stub is a proxy for a remote object. - The stub implements the same methods as on the remote interface. - RMI middleware consists of: - Stub - Dispatcher (uses Java reflection, it invokes the remote method) - A remote implementation should: - Implement a remote interface - Require an appropriate constructor - Must provide behaviour on all methods on remote interface (obviously, you need to do that in Java anyway) Server Deployment - To deploy an RMI server, you need to run the server itself, an d you need a registry. - What‚Äôs a registry? It‚Äôs a separate instance of the JVM that maps URLs to remote references. - Yes, you need two Java instances to run an RMI server. - You can bind URLs using the b i n d method, as well as u n b i n d and r e b i n d . Dynamic Code Loading - How do you trust the code that‚Äôs coming to your computer? - You need two things: - Security Manager - enforces rules, or policies - Security policy - the actual rules to abide by - A security manager, in Java, is stored via a singleton pattern (sort of). - You can set one up with S y s t e m . s e t S e c u r i t y M a n a g e r and access it with S y s t e m . g e t S e c u r i t y M a n a g e r . - So then how do you set up security policies? Computer Science / Software Engineering Notes Network - You can use S y s t e m . s e t P r o p e r t y , or via the -D switch when initialising the JVM. - You also need a policy file, to store your policies. - The format looks a little like this: g r a n t { p e r m i s s i o n j a v a . n e t . S o c k e t P e r m i s s i o n \" * : 1 0 2 4 - 6 5 5 3 5 \" , \" c o n n e c t , a c c e p t , r e s o l v e \" ; p e r m i s s i o n j a v a . n e t . S o c k e t P e r m i s s i o n \" * : 8 0 \" , \" c o n n e c t \" ; } ; Many Clients! - How does RMI manage multiple clients running the same methods? - It opens up a new thread for each request! - But then we‚Äôve got lots of threads acting on the same resources. If you‚Äôve read the PLC notes, you know that this is a recipe for race conditions. - But in case you haven‚Äôt started PLC yet, a race condition is when two or more threads try to manipulate a shared resource at the same time. - So then, what do we do to stop race conditions from screwing things up? - We use a schedule! So that thread activities can be controlled. - Basically, we only want one thread trying to access a critical region (some mutable shared resource) at a time. This is called ato micity. - Also, when other threads try to access an occupied critical region, it‚Äôll wait for the ‚Äúlock‚Äù. This is called guaran teein g mutual exclusio n . - In Java, there exists an implementation of the monitor concept. - A mo n ito r is a barrier securing a shared resource with a lock. - When a thread accesses a shared resource, it gets the lock. - When more threads try to access the shared resource, it has to wait in queue until the lock is released. The Monitor - Don‚Äôt worry! There‚Äôs not some weird class you have to use to use monitors. - You‚Äôve actually been using monitors this whole time:it‚Äôs from the s y n c h r o n i z e d keyword. - It can declare critical regions of methods or objects. - When a thread tries to access code encapsulated with a synchronized block, it needs a lock of that object (or class, if it‚Äôs a static method). - For more information, read the PLC notes. PLC does a great job of covering concurrency! Computer Science / Software Engineering Notes Network The Observer Pattern - There‚Äôs also an observer pattern used for concurrent threads: - w a i t ( ) - the thread stops and waits to be notified - n o t i f y ( ) - wakes up a random thread - n o t i f y A l l ( ) - wakes up all threads - This is more useful for scenarios such as the producer consumer problem. - Again, this is explained further in the PLC notes, so for more information, please check those. RMI Limitations - Despite how amazing RMI is, it has disadvantages. - For example, it assumes both the client and server run in a JVM. - It doesn‚Äôt work if either server or client are not written in Java. For example, it can‚Äôt work with legacy code in COBOL, servers written in Python or C (good luck to you if you write servers in C ) or a web application written in JavaScript. - You can use JNI (Java Native Interface) in some cases, but it‚Äôs a pain to work with (even more than RMI) and doesn‚Äôt always work. - It makes remote calls look like local calls, i.e. it assumes that the network is always reliable. Obviously, that‚Äôs not the case and it‚Äôs a pain to handle network problems with RMI. - All in all, RMI is a tightly coupled system. We don‚Äôt want tight coupling though, as we want to build servers and clients which are independent of each other, i.e. don‚Äôt restrict or affect each other. - So yeah, it‚Äôs clear:RMI sucks. Well, it‚Äôs not that it sucks;it‚Äôs outdated technology. Nowadays, we have things like REST APIs, which pretty much run the entire Internet. Data Serialisation Serialising Java Objects - In RMI, we send objects over networks, like parameters and stuff. - How do we do that? - The object needs to implement the Serializable interface! - If an object implements the Serializable interface, the compiler generates bytecode to handle serialization/deserialization. - The same version of the class must be known on both sides. - Objects are passed through networks using O b j e c t I n p u t S t r e a m s and O b j e c t O u t p u t S t r e a m s, with the methods r e a d O b j e c t and w r i t e O b j e c t . - You also need a version UID, because that‚Äôs important in sending objects over a network. Computer Science / Software Engineering Notes Network Mobile code üì± - We can use serialisation to create mobile code: - Client sends a message object to a server that contains behaviour - Server calls a method on the received object to execute the behaviour - The message object can then either be sent back to the client or visit the next server. - To do this, you can define an interface for tasks, called Task: p u b l i c i n t e r f a c e T a s k e x t e n d s S e r i a l i z a b l e { p u b l i c O b j e c t e x e c u t e ( ) ; } - Then, you can create tasks that implement Task and send those to a server. - For example, you could make a LetterCount task, which has a string as a property, and the e x e c u t e implementation could count the number of characters in the string and return the result. - If the client sent that to the server, the server could run e x e c u t e and do something with the result (e.g. send it back to the client). - This is one way to send mobile code in Java, although it‚Äôs a bit hacky because the server must already be aware of the code in the first place;code isn‚Äôt actually being ‚Äútransmitted‚Äù. - However, if you store a T a s k as a property in some E x e c I m p l class and send that, you could send code that isn‚Äôt preprogrammed into the server. Pass by reference or value? - With serialisation, we‚Äôre passing a copy of the object. - However, with RMI, you can pass a reference of an object, using the Remote interface! - Let‚Äôs use an example with Banks and Accounts. - The Bank implementation passes references to remote account objects. - Both the client and the server have copies of the same Account object reference. - We can go further and use callbacks. - With callbacks, we pass a callback object reference (from client to server). Computer Science / Software Engineering Notes Network - Basically, a client sends the server a request and some callback object. - Then, once the server has done performing the request, it uses the callback object, so the client can react to what the server has done. - With RMI, the client‚Äôs calling thread waits until the remote method returns. - Callback allows decoupling between client and server. Programming language independence - Don‚Äôt like the way Java is serialising your objects? - What was that? You wanted your Java programs and your C programs and your FORTRAN programs and your COBOL programs to talk to each other through a language-independent format? - No worries! Just override the w r i t e O b j e c t and r e a d O b j e c t methods and you can define your own language-independent format! import java .io. Serializable ; import java .io. ObjectOutputStream ; import java .io. ObjectInputStream ; public class MyClass implements Serializable { private static final long serialVersionUID = 2L ; private void writeObject ( ObjectOutputStream out ) throws IOException { // Custom solution } private void readObject ( ObjectInputStream in ) throws IOException , ClassNotFoundException { // Custom solution } } - But that‚Äôs effort! You want to use a standard because you‚Äôre lazy and don‚Äôt want to define your own format yourself you‚Äôd also like to support other programs, and using a well-defined standard makes everything easier. - So what should the standard have? - Syntax:What is the structure of the byte stream? - Semantics:What do the symbols mean? Computer Science / Software Engineering Notes Network JSON - JSON (JavaScrip t Object No tatio n ):a language-independent syntax for exchanging structured data - There are three main components: - Value:a number, a string, a boolean, an array, an object or null - Array:a list of values [ ] - Object:a mapping from keys (written as strings) to values { } - For example, here is a JSON document expressing an auction structure, containing items with IDs, names and stock: { ‚Äú a u c t i o n ‚Äù : ‚Äú N o t e s N e t w o r k A u c t i o n ‚Äù ‚Äú i t e m s ‚Äù : [ { ‚Äú I D ‚Äù : ‚Äú 0 2 3 4 6 9 2 3 4 ‚Äù , ‚Äú n a m e ‚Äù : ‚Äú R e d S t o n e o f A j a ‚Äù , ‚Äú s t o c k ‚Äù : 1 } , { ‚Äú I D ‚Äù : ‚Äú F E 4 0 5 3 6 ‚Äù ‚Äú n a m e ‚Äù : ‚Äú S t r i n g ‚Äù ‚Äú s t o c k ‚Äù : 5 8 } , { ‚Äú I D ‚Äù : ‚Äú 2 9 6 3 6 0 ‚Äù ‚Äú n a m e ‚Äù : ‚Äú T i m e S t o p H a t ‚Äù ‚Äú s t o c k ‚Äù : 3 } , ] } - JSON documents should be underpinned by schema (semantics, or set rules) which can be defined by a ‚Äú$ s c h e m a ‚Äù or/and ‚Äú$ i d ‚Äù property. GSON - GSON is a JSON helper API made by Google. - Basically, it lets you use JSON in Java. - It has reflection-based functionality, which allows it to convert Serializable objects into JSON and back again. - If you wanna check out more, look at the repo:https://github.com/google/gson Linked Data & Semantics - There‚Äôs a method of encoding linked data to JSON called JSON-LD. - It‚Äôs a W3C recommendation (standard) to use this. Computer Science / Software Engineering Notes Network - It uses a common schema with defined relations, most of which can be found here: https://schema.org/ (such as s a m e A s , i s - a , r e q u i r e s , a t t a c h e d T o etc.) - We can also use this to describe policies for distributed systems, not just with access control, but for behaviour control, too. - The International Labour Organisation reported fatalities in low/middle income countries due to workplace accidents and illnesses. This was because equipment didn‚Äôt comply with OHS policies. - So they used W3C SSN Ontology for sensor descriptions and a framework called OWL-POLAR for semantical policy representation, and now it‚Äôs being used in coal mining. - Also, if we can describe things, rules, policies, we can describe networks, too. That‚Äôs called software-defined networking, and we‚Äôve already seen a bit of that already (with virtual LAN). Loose Coupling Space & Time Uncoupling - If senders and recipients don‚Äôt have to be directly connected to each other, we are deco up lin g with sp ace. - If sending and receiving messages can happen at any time anyone is available, we are deco up lin g with time. - This can make one-to-many communication easier. - Here are the effects of coupling: Time co up led Time un co up led Sp ace co up led Message is directed specifically towards receiver. Receiver must be present when the message is sent. Example:sockets, remote invocation Message is directed specifically towards receiver. Receiver doesn‚Äôt have to be present when the message is sent. Example:snail mail (normal mail), email Sp ace un co up led Sender doesn‚Äôt know exactly who they‚Äôre sending to. Receiver must be present when the message is sent. Example:IP multicast Sender doesn‚Äôt know exactly who they‚Äôre sending to. Receiver doesn‚Äôt have to be present when the message is sent. Computer Science / Software Engineering Notes Network Example:publish & subscribe with message queues Group Communication - A sender sends a message to a group - All the recipients of that group receive the message - Participants may leave / join the group - A single multicast operation is used for sending the message - Usually implemented with IP multicast The frowning person won‚Äôt receive the message as they aren‚Äôt available, hence why this is space-uncoupled-time-coupled. - You can think of this as a space uncoupled time coupled network (assuming there aren‚Äôt any message queues). - You can use this to send information to a large number of clients, or in a collaborative application. - It‚Äôs also handy for different kinds of groups, such as closed groups (where only members can send messages) or open groups (where any process can send messages). - There are two kinds of group communication: - Synchronous group communication:the messages are sent out in real-time, and bounds must be set on communication delays, process scheduling delays and faulty components. - Asynchronous group communication:messages are sent via datagram (UDP), so they may get lost, so systems are characterised by communication uncertainty. We should set bounds of timeout delays and assume timely communication most of the time. Computer Science / Software Engineering Notes Network - When implementing, we need to ensure: - Reliability:message received is identical to the one sent (integrity), every message is eventually delivered (validity) and if a message is delivered to one member, it‚Äôs delivered to all (agreement). - Ordering:sender order is preserved (FIFO), and can either have: - Causal ordering:just make sure if message m2 is sent in response to m1, m2 is received by all members after m1. - Total ordering:all messages are sent in the same order, regardless of causality. - Remember that we also need some kind of management, so we can create/delete groups, add/remove participants, detect failures and notify members of membership changes. Publish & Subscribe - Publish and subscribe is the most widely used form of indirect communication. - Also known as distributed event-based systems - Basically, publishers p ublish events to an event service, and subscribers express interest (or subscribe) in particular events. - It‚Äôs like a special kind of group communication, also making this space-uncoupled-time-coupled (assuming that the system doesn‚Äôt store any events). - These kinds of systems deliver event notifications. - Publishers can also publish messages by topic, and subscribers may want to subscribe to a set of topics. - If a subscriber is not running, events may be stored and queued until it rejoins. - When events are queued, the system becomes time-uncoupled since it will store them until a subscriber comes back online - You‚Äôve seen lots of these before, like: - Subscribing to a channel on YouTube (except you actually get told when they upload) - Financial information systems (like the stock market) - Cloud-based workflows - Cooperative working systems - An example of an infrastructure that uses pub & sub is Google Cloud Pub / Sub (creative name). - It supports many-to-many communication, and it has hetero gen eity, which means it supports different components written by different developers. - The types of subscription models are: - C han n el-based:subscribers subscribe to a channel, so they receive all events - To p ic-based:subscribers subscribe to a set of topics, so they only receive messages sent to those topics Computer Science / Software Engineering Notes Network - C o n ten t-based:subscribers filter messages based on queries, and only receive those. - The types of implementation models are: - C en tralised:A single publisher sends messages to multiple subscribers via point-to-point messages (it lacks resilience and scalability) - D istributed:A network of publishers work together (also called federated) - Peer-to -p eer:Some fully peer-to-peer implementations are possible Message Queues & IoT - That‚Äôs great, but we still don‚Äôt have full decoupling (unless we store events);how do we decouple time, too? Do we need a time-based stand, like Killer Queen or King Crimson? - No, using message queues are enough. - Traditionally, message queues are point-to-point services. - Senders (or producers) place messages into queues, and receivers (or consumers) take messages from the queues. - This way, producers and consumers can have different lifetimes, decoupling time. It‚Äôs also suitable for enterprise applications. - What protocol uses message queues like this? - There‚Äôs one called MQTT (Message Queue Telemetry Tran sp o rt), and it‚Äôs very light-weight! Perfect for embedded systems, edge computing and Internet of Things. - Why not just use HTTP? Well, HTTP is better for requesting information. Plus, it‚Äôs not event-oriented and it can be more bulky than MQTT. - However, the way MQTT defines its namespaces is similar to HTTP, as it uses a hierarchical system. - The sub-topics are separated with ‚Äú/‚Äù, and it gets more specific as you specify more topics. - For example, some device could publish to: - < t o w n > / < p o s t c o d e > / < h o u s e > / a l a r m - < t o w n > / < p o s t c o d e > / < h o u s e > / t e m p e r a t u r e - < t o w n > / < p o s t c o d e > / < h o u s e > / e n e r g y U s e - ... and subscribe to: - < t o w n > / < p o s t c o d e > / < h o u s e > / t h e r m o s t a t / s e t T e m p - Subscribers can also use wildcards: - Single-level wildcards ‚Äú+‚Äù selects every topic at that hierarchy - Multi-level wildcards ‚Äú#‚Äù selects every topic path - For example: - S o u t h a m p t o n / + / + / e n e r g y U s e - subscribe to energy use for all homes in Southampton - S o u t h a m p t o n / S O 1 7 1 B J / # - subscribe to all queues for all homes in SO17 1BJ Computer Science / Software Engineering Notes Network - It‚Äôs also cheaper to maintain a MQTT connection than a HTTPS connection, as it requires less power: - A subscription can either be: - Durable:messages are stored until next time subscriber connects - Non-durable:messages remain as long as subscriber is connected - Publishers can also make publications ‚Äúretained‚Äù. - This means that ‚Äúlast known good‚Äù messages are sent to new subscribers. - MQTT is really small;the smallest packet size is 2 bytes! It‚Äôs compressed into bit-wise headers and variable length fields. - It has asynchronous bidirectional pushing, so no polling. - It supports always-connected and sometimes-connected models - It‚Äôs aware of sessions, and usually operates over TCP. - Plus, the sender and receiver can agree on a quality of service (QoS) based on a 2-bit integer: - 0 - messages are delivered at most once - 1 - messages are delivered but may be duplicated - 2 - messages are delivered once and only once - Because MQTT is so minimalistic, it‚Äôs perfect for devices with limited resources, like game controllers or small battery powered devices. - Implementations of MQTT are available for C and Java, but one of the most popular is one called RabbitMQ. RabbitMQ - RabbitMQ is a multi-protocol implementation that is polyglot (supports multiple languages). - It supports: Computer Science / Software Engineering Notes Network - A MQP (A dvan ced Message Queuin g Pro to co l) - message-oriented pub/sub queueing protocol with reliability and security - MQTT (Message Queue Telemetry Tran sp o rt) - pub/sub based protocol designed to be minimalistic for small code footprints - STOMP (Simp le Text-Orien ted Messagin g Pro to co l) - similar to HTTP and has commands such as CONNECT, SEND, SUBSCRIBE, UNSUBSCRIBE - Since it is polyglot, it supports many languages, for example, you could write the producer in Java and the consumer in Python. - It also supports different communication patterns, such as pub/sub, topic-based routing and RPC (Remote procedure call). Distributed Transactions Distributed Data - When you distribute data, it needs to follow the ACID rules: - A to micity:either a transaction happens or not at all - C o n sisten cy:a transaction takes the system from one consistent state to another - Iso latio n :effects of a transaction are not visible until it‚Äôs fully complete - D urability:effects of a transaction are persistent (resistance to failures) - To put this into context, we need: - objects to be recoverable - clients to signal the start/end of a transaction - commitment processes to guarantee all operations are permanently recorded - the protocol to ensure aborted transactions leave no visible effects - We need some kind of C o o r d i n a t o r to uphold these rules... Lost Updates & Inconsistent Retrievals - Here are two kinds of problems we could face: - Lo st up dates - This is where an update is lost by transaction U because transaction T overrides it: Tran sactio n T Tran sactio n U b a l = a . g e t B a l a n c e ( ) ; $ 2 0 0 b a l = a . g e t B a l a n c e ( ) ; $ 2 0 0 a . s e t B a l a n c e ( b a l * 1 . 1 ) ; $ 2 2 0 c o m m i t Computer Science / Software Engineering Notes Network a . s e t B a l a n c e ( b a l - $ 1 0 0 ) ; $ 1 0 0 c o m m i t - As you can see, the final value is supposed to be $120, but because T accessed the value before U changed it, it sets the balance to $100 instead. The update of U was lost! - In co n sisten t retrievals - This is where a transaction U doesn‚Äôt get the right value from a retrieval because they‚Äôre trying to access before transaction T is finished: Tran sactio n T Tran sactio n U a . w i t h d r a w ( $ 1 0 0 ) ; $ 1 0 0 t o t a l = a . g e t B a l a n c e ( ) ; $ 1 0 0 t o t a l + = b . g e t B a l a n c e ( ) ; $ 4 0 0 b . d e p o s i t ( $ 1 0 0 ) ; $ 4 0 0 c o m m i t c o m m i t - The problem here is that when U gets the balance of account B, it shouldn‚Äôt be $400, it should be $500, because T wanted to deposit $100 into B. - So how do we fix this? - Serial eq uivalen ce! - What is that? That means to ensure serially-equivalent interleaving, as if the transactions happen one after the other. - This prevents lost updates and inconsistent retrievals. - So how can we serialise them? - Two ways: - Locking:transaction must acquire a lock on an object before they act on it. Other transactions must wait for the lock, but can share a read lock. This could lead to deadlock. - Optimistic concurrency control:perform the transaction anyway, and if we have a conflict at the commit stage, then abort. It‚Äôs similar to CAS (compare-and-set) in PLC. - But what if we want to abort transactions? Then we‚Äôll have new problems! Computer Science / Software Engineering Notes Network Dirty Reads & Premature Writes - Here are two problems we could face with aborting: - D irty reads - This happens when transaction U happens after transaction T, but then transaction T wants to abort after U has already committed, which makes U‚Äôs read ‚Äúdirty‚Äù (because it‚Äôs not accurate anymore): Tran sactio n T Tran sactio n U b a l = a . g e t B a l a n c e ( ) ; $ 2 0 0 a . s e t B a l a n c e ( b a l * 1 . 1 ) ; $ 2 2 0 b a l = a . g e t B a l a n c e ( ) ; $ 2 2 0 a . s e t B a l a n c e ( b a l + 2 0 ) ; $ 2 4 0 c o m m i t a b o r t - As you can see, T aborts after U is finished. That means U‚Äôs read of account A‚Äôs balance is now dirty. - We need recoverability, and to avoid cascading aborts by delaying reads until other transactions commit or abort. - Premature writes - This happens when a write happens just before a transaction aborts and rolls back a data value: Tran sactio n T Tran sactio n U $ 2 0 0 a . s e t B a l a n c e ( $ 2 5 0 ) ; $ 2 5 0 a . s e t B a l a n c e ( $ 2 2 0 ) ; $ 2 2 0 c o m m i t a b o r t - If T is aborting, A‚Äôs balance should be $220, right? - What if the implementation of an abort is to roll back the previous balance? - Then the result would be $200! Not good! Computer Science / Software Engineering Notes Network - To fix this, we can delay writes until earlier transactions that update the same objects have committed / aborted. - Remember that communication is not fully reliable;it can crash, or links may temporarily fail. - Some transactions may be affected by this. What will we do? How will we recover? You think Bart Simpson from the slides will care if your transactions are fully committed? Probably not. Distributed Commit Protocols - So we need atomicity - all or nothing - We need durability - account for failures - We need locks on all data objects involved - Hmmm... how about a distributed commit approach? - Who‚Äôs going to coordinate? Use a leader election protocol! - Shall we commit or abort? Use a consensus protocol! (more info in Corina‚Äôs bit) - Basically, a coordinator asks a bunch of participants if they want to commit. - They all commit if everyone else says they‚Äôre ready to commit. This is called Sin gle Phase C o mmit. - The coordinator keeps asking until everyone acknowledges. - But how long do we wait, and what happens if some participants fail? Computer Science / Software Engineering Notes Network Two-Phase Commit - Two-phase commit is a voting scheme to reach a consensus on whether to commit or abort. - It preserves atomicity, because if one operation is aborted the entire transaction is aborted. - This scheme requires a reliable message delivery. - The servers can all abort their own operations if the coordinator can detect it. - It‚Äôs split into two phases: 1. Voting - The coordinator sends instructions to all participants and asks them if they can commit. - For all participants, they execute the instructions and if they can commit, they respond with YES and save state to local storage. If they can‚Äôt commit, they respond with NO and abort local operations and release locks. 2. Completion - The coordinator collects all the votes (including its own). - If all the votes are yes, the coordinator sends a doCommit message to all participants, and all participants send back a haveCommitted message. - If even a single vote is no, the coordinator sends a doAbort message to all participants, and everyone aborts. 2PC Failure Handling - That‚Äôs great, but how does it handle failure? Computer Science / Software Engineering Notes Network - If a participant crashes after voting yes, the participant saves its state to local storage and uses that to reinstate an equivalent participant. Then, it will call getDecision on the coordinator and will use that decision to either commit or abort. - If a coordinator crashes in phase 2 (completion), 2PC can become a blo ckin g p ro to co l. - Participants can‚Äôt use getDecision, because the coordinator is gone. What are they going to do? - They need to elect a new coordinator using a leader election protocol! The new coordinator issues an abort message. - Recovery can take time (obviously). Increasing Concurrency & Deadlocks - How do we increase concurrency in our system? - Objects can have multiple locks! - This is called Two Versio n Lo ckin g. - Here‚Äôs the basic principles:every object has three locks:read, write and commit. If you have a respective lock on that object, you can perform that action. - Threads can share locks too, for example multiple threads can share the read lock on an object. - However, some locks are unobtainable while other locks are already set. - For example, if the write lock has already been set, another thread needs to wait to also obtain the write lock. - The full table is here: Lo ck req uested Lo ck already set Read Write Commit None OK OK OK Read OK OK WAIT Write OK WAIT Commit WAIT WAIT - Following the table, if the ‚Äúread‚Äù lock is already set, it‚Äôs alright to share the read lock or take the write lock (if the write lock isn‚Äôt already taken). - If multiple locks are taken, the strongest (bottom-most) lock takes precedence on the table. - As you can see, while an object is being committed to, no-one can do anything with it until after it is finished. - However, it is possible to have many readers and a single writer, since setting the write lock doesn‚Äôt stop threads from reading the object. Computer Science / Software Engineering Notes Network - The advantage of this is that read operations are only delayed during commits. - However, read operations on one transaction can delay commitment on others (since all reading and writing needs to stop during commitment). - There‚Äôs still one problem though:deadlocks! - We still have the overhead of checking and maintaining deadlocks. - We can break them using timeouts or probes. Distributed Systems Theory (Corina) Time in Distributed Systems Clock synchronisation - Distributed systems need to sync up! - If they don‚Äôt, messages could arrive out of order. Sometimes that can be disastrous! - In practice, this is mostly used in things like banking or e-commerce. - There‚Äôs no way to be fully synchronised, but there are two methods of synchronisation: - Extern al synchronisation:all processes are synced up to some external clock, like UTC - In tern al synchronisation:processes use some kind of sync protocol to sync up their local clocks with each other. They agree on a common time, but not necessarily a standard (like UTC) - To achieve internal synchronisation between two processes, process A sends its time to process B in a message. Then, B sets its own time to ,ùë° ùë° + ùëöùëéùë•+ ùëöùëñùëõ 2 where max is the maximum time needed to transmit a message, and min is the minimum time needed to transmit a message. - Basically, your time is the other process‚Äôtime plus the average time to transmit a message. - In asynchronous systems, max isn‚Äôt known! - But what if you wanted to have internal synchronisation with multiple processes? - You can use the B erkeley algo rithm! - It works like this: - One machine is chosen as the master. - The master then periodically polls everyone‚Äôs clock values. - The master then estimates local times based on round trip times, and then averages (fault-tolerant average that disregards faulty clocks) out the values (including the master‚Äôs own time) - The master then sends the amount by which processes need to adjust their individual times (not the new clock value!) Computer Science / Software Engineering Notes Network - For external synchronisation, you can use C ristian ‚Äôs algo rithm. - The way that works is as follows: - There is a process and a time server. - The process requests for the time, , from the time server.ùëá - The time server responds to the process with the time, .ùëá - The process then sets its own time to , where is theùëá + ùëá ùëüùëúùë¢ùëõùëë 2 ùëá ùëüùëúùë¢ùëõùëë time taken by the request and reply. - Why add that bit at the end? Well, by the time the time server responds with T, T is no longer the time anymore, because of the time spent waiting for the message to get to us. That‚Äôs why we estimate how long that message took, and we add it to the time we receive. - Admittedly, this assumes the time to request and receive are distributed evenly. - There‚Äôs another synchronisation method called Netwo rk Time Pro to co l (NTP). - NTP allows clients to be accurately synchronised to UTC. - It works in a hierarchy system, with: - primary servers (at the top) directly connected to time source (e.g. radio clocks) - secondary servers which synchronise with primary ones - tertiary servers which synchronise with secondary ones - etc. - The time is synchronised down the hierarchy using multicast, or Cristian‚Äôs algorithm. - A client is somewhere in this hierarchy, and the lower they are in the hierarchy, the less accurate the time they‚Äôre synced with is. Logical clocks - Some distributed algorithms only care about the ordering of events. That‚Äôs where we use logical clocks. - Logical clocks use even t causality to obtain partial ordering of events. Computer Science / Software Engineering Notes Network - Alright, so how do we get causal ordering with logical clocks? - First, we define a relation , where and are events:ùëé ‚Üí ùëè ùëé ùëè - If and are events in the same process and a occurs before b, thenùëé ùëè ùëé ‚Üí ùëè - If is the event of sending a message and is the event of receiving theùëé ùëè message, then ùëé ‚Üí ùëè - Transitivity rule:if and thenùëé ‚Üí ùëè ùëè ‚Üí ùëê ùëé ‚Üí ùëê - This relation is called the ‚Äúhappened-before‚Äù relation (a happened before b) - We assume that holds, even if it doesn‚Äôt make much senseùëé ‚Üí ùëé - Messages and are concurrent if neither nor . That‚Äôs written as .ùëé ùëè ùëé ‚Üí ùëè ùëè ‚Üí ùëé ùëé || ùëè - Here‚Äôs an example: - is true because and happen in the same process, and happens before .ùëé ‚Üí ùëè ùëé ùëè ùëé ùëè - is true because is a send event and is that respective receive event.ùëè ‚Üí ùëê ùëè ùëê - is true because of the transitivity laws.ùëé ‚Üí ùëê - is also true because and are both false (you can‚Äôt derive them).ùëé || ùëí ùëé ‚Üí ùëí ùëí ‚Üí ùëé - There are other causalities too, like , , and .ùëê ‚Üí ùëë ùëí ‚Üí ùëì ùëë ‚Üí ùëì ùëé ‚Üí ùëì - We can capture this concept numerically, with Lamp o rt‚Äôs Lo gical C lo cks. - Basically, each process keeps their own logical clock, starting at 0. - When a process sends or executes an event, it increments its logical clock and timestamps it, so the recipient can see the timestamp. - When a process receives an event, it checks if the timestamp received is bigger than its own clock. If it is, it first sets its own clock to the timestamp and then carries on with the same procedure described above. - This may be a little hard to visualise at first, so let‚Äôs use an example: - Below, I give an explanation to all the timestamps of the events: - a - process 1‚Äôs first message, so it has a timestamp of 1 Computer Science / Software Engineering Notes Network - b - process 1 has already executed event a, so the clock of process 1 was incremented by 1, to make it 2. When process 1 executes b, it‚Äôll be timestamped with 2, because that‚Äôs process 1‚Äôs clock value at that moment. - c - process 2‚Äôs clock is 1, but the timestamp of the message is 2. The message‚Äôs timestamp is bigger, so process 2 will increment and use that one for c. Incrementing 2 gives 3, so the timestamp of c is 3. - d - process 2‚Äôs new clock is now 3, because of event c. The clock will be incremented and used to timestamp d, so d‚Äôs timestamp will be 4. - e - process 3‚Äôs clock is still 1, and has no events yet. So process 3‚Äôs first event, e, will have a timestamp of 1. - f - process 3‚Äôs clock is 2 after event e, and the timestamp of the message from d is 4. The message‚Äôs timestamp is clearly bigger, so that will be incremented to 5 and used for the timestamp of f. - To refer to the timestamp of an event, use .ùêø( ùëé) - impliesùëé ‚Üí ùëè ùêø( ùëé) ‚â§ ùêø( ùëè) - ... but does not imply , because could be concurrent to ( )ùêø( ùëé) ‚â§ ùêø( ùëè) ùëé ‚Üí ùëè ùëé ùëè ùëé || ùëè - In the example, a and e have identical timestamps. How do we differentiate them? - We use To tally Spies Ordered Lo gical C lo cks! - All we have to do is add the process ID to the event timestamp. - So instead of something like 1 for event a (in the example above), it would instead be (1, 1), or (3, 2) for c, or (5, 3) for f. - is true if:( ùëáùëñ, ùëñ) < ( ùëáùëó, ùëó) - ùëá ùëñ < ùëá ùëó - or andùëá ùëñ = ùëá ùëó ùëñ < ùëó - For example, under total order in the above example, a < e because (1, 1) < (1, 3). - What if we wanted that implies rule to be true?ùêø( ùëé) ‚â§ ùêø( ùëè) ùëé ‚Üí ùëè - With vecto r clo cks, that can be arranged! - Instead of an integer being stored as a clock, a vector is stored instead. - Instead of incrementing an integer value, the process increments its own field in the vector. - It works almost the same as normal logical clocks, except we‚Äôre using vectors instead, and each process has their own field in the vectors. - Upon receiving a message, it updates all the fields of it‚Äôs own clock with the newly received clock if it‚Äôs bigger than the one we already have (more formally, for all j)ùëâ ùëñ[ ùëó] = ùëöùëéùë•( ùëâ ùëñ[ ùëó] , ùë°[ ùëó] ) - When we compare vectors: - iff for allùëâ = ùëâ' ùëâ[ ùëñ] = ùëâ'[ ùëñ] ùëñ - iff for allùëâ ‚â§ ùëâ' ùëâ[ ùëñ] ‚â§ ùëâ'[ ùëñ] ùëñ - iff andùëâ < ùëâ' ùëâ ‚â§ ùëâ' ùëâ ‚â† ùëâ' Computer Science / Software Engineering Notes Network - It‚Äôll be easier to show an example again: - Below, I give an explanation to all the timestamps of the events: - a - process 1‚Äôs vector clock is empty, (0, 0, 0), so process 1‚Äôs slot (the first slot) is incremented to (1, 0, 0) and is used to timestamp a. - b - process 1 increments their first slot again to get (2, 0, 0) and uses that to timestamp b. - c - upon receiving the message from b, it updates all the slots in its own local clock with the slots in event b‚Äôs clock (only if it‚Äôs bigger than what we already have). Process 2‚Äôs clock is currently (0, 0, 0) and event b‚Äôs clock is (2, 0, 0), so the first slot will be updated with ‚Äò2‚Äôin process 2‚Äôs local clock. Now, process 2 increments its own slot (the second slot) to (2, 1, 0) to use for event c. - d - process 2 increments their own slot again to get (2, 2, 0) and uses it for event d - e - process 3‚Äôs vector clock is still empty, at (0, 0, 0). It increments its own slot (the third slot) to (0, 0, 1) and uses that for event e. - f - process 3 updates its own clock, (0, 0, 1), with the new clock from event d, (2, 2, 0). The first two slots are clearly bigger, so process 3‚Äôs clock is updated to (2, 2, 1). Process 3 then increments its slot to (2, 2, 2) to use for event f. - With vector clocks, we can not only see the number of events a process has timestamped, but we can see how many events another process has executed that affected some other process. - What‚Äôs also good about vector clocks is that implies .ùëâ( ùëé) ‚â§ ùëâ( ùëè) ùëé ‚Üí ùëè - Why? If , that means all the slots in event a‚Äôs clock is smaller than orùëâ( ùëé) ‚â§ ùëâ( ùëè) equal to every slot in event b‚Äôs clock, and slots can only go up (they can‚Äôt be decremented), so a has to have gone before b. - If , then events a and b are the same events, just different names. We‚Äôveùëâ( ùëé) = ùëâ( ùëè) already established that , so this is trivial.ùëé ‚Üí ùëé - The disadvantage to using this over Lamport timestamps is that storage and message payload is proportional to N (the number of processes), so it‚Äôd be inefficient to use this unless we have to. Computer Science / Software Engineering Notes Network Distributed Mutual Exclusion Failure detectors - Failure detectors detect failure (wowee, now that‚Äôs what I call info) - There are two kinds of failure detectors: - Unreliable:returns either unsuspected or suspected hints (can only suspect if a process is no longer alive via an ‚Äúalive‚Äù message not being received back) - Reliable:returns either unsuspected or failure (if it sends ‚Äòfailure‚Äô, it knows for sure a process is down) Distributed Mutual Exclusion - You have some distributed critical region, and all the online processes wanna grab it and mess with it at the same time. Big no-no. You want them to take it in turns. - You want to do it with message passing. - We need to make some assumptions: - There are N processes - Network is reliable but asynchronous - Processes don‚Äôt fail - Processes spend finite time in critical section (they don‚Äôt hang while in critical section) - There are also some properties of mutual exclusion algorithms/protocols: - Correctness: - Safety:at most one process is in critical section - Liveness:requests to enter / exit eventually succeed - Fairness:access to critical section happens in happened-before order, so if action 1 is requested before action 2, then action 1 should go first and then action 2. - Performance: - Minimise number of messages sent in entry / exit operations - Minimise client delay (entering / exiting critical section) - Minimise synchronisation delay (time between one process exiting and another entering critical section) - So what kinds of algorithms are there? - Firstly, there‚Äôs the Central Server Algorithm. - It‚Äôs based on one server and many clients. Simple enough. - The server has a token, and clients can REQUEST for the token or RELEASE the token. - If a client requests for a token and it‚Äôs taken, they‚Äôre added to a queue to wait for the token. - It‚Äôs basically the whole lock concurrency ordeal, but in a distributed setting. Computer Science / Software Engineering Notes Network - It has safety, because if the token belongs to a process, other processes can‚Äôt have it - It has liveness, because all requests are handled by a server, and all request messages are eventually answered once they‚Äôre at the front of the queue - It does not have fairness because there are no timestamps -- it‚Äôs an asynchronous system. For example, say that request #1 request #2. Request #2 could come‚Üí earlier than request #1 and process #2 could get the token, when in reality it should‚Äôve been process #1. See this slide for more detail. - This has good performance, but there is a single point of failure and the server acts as a bottleneck. That‚Äôs bad! But we can find a way around this... - Next we have the Ring-based Algorithm! - It‚Äôs essentially the same as the server based one, except without a server and it‚Äôs a ring. - Tokens aren‚Äôt explicitly sent to one process;it‚Äôs passed around a ring. - For example, when process 2 is finished with the token, it‚Äôll pass it to process 3, who will pass it to process 4 and so on. - It has safety, because again, only the process with a token has access to the critical region. - It has liveness, because eventually everyone will get the token. - It does not have fairness, because the order of processes in the ring topology might not be the order in which we want the processes to act on the shared data. - We no longer have the bottleneck, but this‚Äôll really weigh us down on bandwidth, as the token might have to travel quite far just to get to a process that needs it. Computer Science / Software Engineering Notes Network - Why not use an algorithm using multicast and logical clocks? - There‚Äôs one called Ricart an d A grawala‚Äôs A lgo rithm which uses these in a very interesting way. - In this algorithm, messages have totally-ordered timestamps. Don‚Äôt think too hard about it;it just means that processes can tell when messages were sent. - When a process wants to access a critical region, it sends a REQUEST multicast message to all the participants. - When a process receives a REQUEST message, it can do one of two things: - If this process is already in the critical region, or if this process also wants to access the critical region but this process wanted to access it before the sender, then the sender of the request message is put in a queue - If the sender wanted to access the critical region before this process, then it will send a simple REPLY message to the sender. That‚Äôs all;no extra info in the message or anything. It‚Äôs sort of like a ‚Äúsure, you can use the critical region as far as I care‚Äù - When a process gets REPLY messages from all other participants, it gets access to the critical region. - Confusing? Let me show you an example: Image Exp lan atio n We have three processes and the critical region. The blue process requests access to the critical region from all other processes. Computer Science / Software Engineering Notes Network Both the green and yellow processes don‚Äôt care about the critical region, so they both immediately reply to the blue process. The blue process, having received replies from all other participants, can now use the critical region. Yellow wants to use the critical region now, so they send out requests to everyone. Computer Science / Software Engineering Notes Network Blue adds yellow to their queue, because blue is currently using the critical region. Green doesn‚Äôt care about the critical region, so green replies to yellow. Now green also wants to use the critical region. They send out requests to everyone. Blue is using the critical region, so green is added to the queue. Yellow came first (it knows because of the totally-ordered timestamps), so yellow adds green to its queue. Blue is now done with the critical region and sends a reply to yellow, because yellow was at the head of the queue. It will also send a response to green, because they‚Äôre next on the queue. Computer Science / Software Engineering Notes Network Yellow just got responses from everyone! That means yellow can now use the critical region. Yellow is now done with the critical region, and sends a response to green. Green now has all the responses, and can now use the critical region. - This has safety because a process doesn‚Äôt reply if they are in the critical region. - This has liveness because the total ordering of the timestamps ensures each request will eventually get all replies, and because each participant spends finite time in critical section. - This has fairness because with the timestamps, whoever requests first will go first, and whoever requests after will go second and so on. - The performance is good because the token isn‚Äôt circulating. - Wow, this is, like, the perfect algorithm! - But what if I told you that we don‚Äôt even need all those replies from all those participants? - We can also use Maekawa‚Äôs Vo tin g algo rithm! (No, I don‚Äôt mean Maekawa from iDOLM@STER) - The whole gimmick of Maekawa is that we use groups instead of individual processes. - There‚Äôs one group for each process, and all the groups overlap each other, and each process needs to be in either 2 groups or more (if there are any less, then there‚Äôs no overlapping) Computer Science / Software Engineering Notes Network - As for the size of these groups, an optimal amount would be (where N is the‚âà ùëÅ number of processes). In practice, this makes the groups non-trivial to construct, so we use a simpler method which has group sizes of :‚âà 2 * ùëÅ - Construct groups by first arranging the processes in a matrix, then work out the group for each process by taking the union of the row and column that it‚Äôs in. For example, these are the groups for A and B respectively in a situation with 9 processes. - - This ensures that every pair of groups overlap. - The algorithm works like this: - For each process there is a groupùëù ùëñ ùëâ ùëñ - For to access the critical region:ùëù ùëñ - It must not already be voting for someone else - It sends REQUEST messages to all processes in its group, ùëâ ùëñ - It waits for VOTE responses from all processes in its group - For receiving a REQUEST from :ùëù ùëñ ùëù ùëó - If is already in the critical region, or if they‚Äôve already voted forùëù ùëñ someone else, then put in the queue.ùëù ùëó - Otherwise, send a VOTE message to .ùëù ùëó - For to exit the critical region:ùëù ùëñ - It sends RELEASE messages to all processes in its group, ùëâ ùëñ - For receiving a RELEASE from :ùëù ùëñ ùëù ùëó - If there is a request in the queue, take the first process out of that queue and send them a VOTE. - Otherwise, simply remember that we have no votes for anyone. - What? Still confusing? Let me illustrate it for you: Image Exp lan atio n We have participants A, B and C. The groups are: A‚Äôs group:A, B B‚Äôs group:B, C C‚Äôs group:C, A Computer Science / Software Engineering Notes Network A wants the critical region, so it multicasts a REQUEST message to it‚Äôs group (B). B isn‚Äôt in the region, and it hasn‚Äôt voted for anyone else, so it‚Äôll vote for A. Because A has received all votes from its group, it gets access to the critical region. Now C wants to access the critical region! It sends a REQUEST to its group (A). Computer Science / Software Engineering Notes Network However, A is already using the critical region, so it puts C in the queue. A has now finished, and will send a RELEASE message to its group (B). B will now cancel the vote with A. A looks at the queue and sees that C tried to access the critical region. A will now vote for C. C, now having all the votes in its group, now has access to the critical region. - So, how good is this one? - This has safety because a process needs all votes to enter the critical region, and other processes can‚Äôt vote for someone else if they‚Äôve already voted for someone in a critical region. - This does not have liveness because deadlocks can occur. - This does not have fairness because there are no timestamps;processes can‚Äôt tell which requests should be served first (only via queue). - The performance isn‚Äôt even that much better than Ricart and Agrawala. Computer Science / Software Engineering Notes Network - So why does this have deadlock? - Because we can create a chain of reply waiting! - In the example above, if everyone wanted to use the critical region, we could have this as a deadlock: - A is waiting for B‚Äôs reply - B is waiting for C‚Äôs reply - C is waiting for A‚Äôs reply - To solve this, we could incorporate timestamps into the requests to give order to the requests. - All of these algorithms are great, but they don‚Äôt tolerate message loss. - When processes crash, what happens? - The ring-based algorithm just stops working altogether - Some crashes are tolerated by central server and Maekawa - Ricart and Agrawala can be adapted to tolerate process crashes, assuming a reliable failure detector is available Leader Election - Why use election algorithms? - Sometimes we want to elect a coordinator amongst a bunch of participants. - Everyone has to agree on one, so how do we do it? Election algorithms! - We need some assumptions first though: - There are N processes with unique, totally ordered identifiers - Process with the largest ID must win election (for these examples, this condition will be different in practice) - Messages are eventually delivered (no failed packets) - Each process can call only one election (unless coordinator fails) - Multiple concurrent elections can be called by different processes - Participant:process engaged in an election - Each participant has a variable initiallyùëù ùëñ ùëíùëôùëíùëêùë°ùëíùëë ùëñ = ‚ä• - Wait! One more thing! How do we determine correctness and performance, like in the distributed mutual exclusion algorithms? - Correctness: - Safety:a participant‚Äôs elected vote is either nothing or P where P is the‚ä• non-crashed process with the largest identifier - Liveness:all processes participate and eventually set their elected vote to something other than nothing or they crash‚ä• - Performance: - Minimise total number of messages sent - Minimise turnaround time (number of serialised message transmissions in a single run) Computer Science / Software Engineering Notes Network Asynchronous systems - With asynchronous systems, we use a ring-based algorithm. - In this, all processes are gathered around in a ring. - A process sends messages to the process next to it in the ring. - This can only work with no process failures! - This one‚Äôs actually quite simple. Here‚Äôs how it goes: - Initially, every process marks itself as a non-participant. - Any process can call an election by: - Marking itself as a participant - Places its ID in an ELECTION message - Sends that message to its neighbour - For receiving an ELECTION message: - If message ID > our ID, forward the message and mark ourselves as a participant, if we‚Äôre a non-participant. - If message ID < our ID: - If non participant, replace ID with our ID, forward message, mark ourselves as participant - If participant, stop forwarding (should only happen when doing multiple elections) - If message ID = our ID, then we‚Äôve found our coordinator. Set our elected variable to our ID, and send an ELECTED message with our ID to our neighbour. Set ourselves as a non-participant. - For receiving an ELECTED message: - If message ID != our ID, set our elected variable to the message ID and pass it along. Set ourselves as a non-participant. - If message ID = our ID, stop forwarding (because we know we‚Äôve hit full circle). - To make this work, lots of processes should instigate elections, but this example will show you just one so you understand the algorithm (it is worst-case): Image D escrip tio n We have processes 2, 6, 7 and 3 in a ring. 3 decides to start an election and creates an ELECTION message with 3 in it. It passes it to its neighbour. Red = non-participating Green = participating Computer Science / Software Engineering Notes Network 6 receives the message and sees that its ID is bigger than the one in the message. It puts its ID in there, sets itself as participating, and sends the message to its neighbour. 2 receives the message. 2 is smaller than 6, so it just forwards the message and marks itself as a participant. 7 receives the message. 7 is bigger than 6, so it replaces the ID, forwards it and marks itself as a participant. 3 receives the message. Since 3 is already a participant, and 3 is smaller than 7, it‚Äôll just forward on the message. In fact, 6 and 2 will just forward on the message too. It‚Äôll only differ when 7 receives the message, so we‚Äôll skip 2 and 6 for now. Computer Science / Software Engineering Notes Network 7 receives the message. Since it‚Äôs already participating, and the message ID is equal to 7‚Äôs ID, it realises that they are the new coordinator. It creates an ELECTED message with it‚Äôs ID in it, sets itself as 7‚Äôs elected process, and sends the ELECTED message to its neighbour. 7 will also mark itself as a non-participant. 3 receives the ELECTED message. 3 is not 7, so it sets 3‚Äôs elected process as 7 and forwards the message. 3 will also mark itself as a non-participant. 6 and 2 will do the same thing, so again, the algorithm only differs when the message goes to 7. 7 receives the message. The ELECTED message ID is equal to 7‚Äôs ID, so 7 stops forwarding the message and the message is ‚Äúdeleted‚Äù. A new coordinator has been elected with all participants! - So how good is the ring-based algorithm? - It has safety, because only the process with the largest ID can start an ELECTED message - It has liveness, because eventually every process becomes a participant and receives ELECTED messages B est case Wo rst case The initiating process has the highest identifier. There are N ELECTION messages... ... and N ELECTED messages... The anti-clockwise (last) neighbour has highest identifier. There are 2N - 1 ELECTION messages... ...and N ELECTED messages... Computer Science / Software Engineering Notes Network ...resulting in 2N turnaround messages (messages sent in total) ...resulting in 3N - 1 turnaround messages (messages sent in total). - This works best if more than one process starts an election, because you‚Äôre more likely to get that best case! - However, this algorithm does not tolerate failures. - Can we modify the ring-based algorithm to support failures? - Introducing the modified ring-based election algorithm! - Broken links are detected by the message sender and the ring is repaired (by making the next node your neighbour or something) - Basically, the messages now carries a list of processes that have forwarded this message. - An ELECTION message is started by the initiator and goes full circle once, tracking IDs. After it goes full circle, a new coordinator is selected from the list of processes and an ELECTED message is pushed around, just like the normal ring-based algorithm (except we‚Äôre still tracking IDs). - When the ELECTED message reaches the initiator of the election, it checks if the coordinator appears in the ID list. - If it does, then the election was successful. - If not, then another election is started. Rin g-based algo rithm message Mo dified rin g-based algo rithm message - Well? What‚Äôs good about this one? - For starters, it requires fewer messages (2N at most) and it tolerates failures. - However, the messages are larger. - If two processes initiate concurrently, then we can discard the message sent by the lower ID initiator (we could change it so that the message could remember who initiated the election). - If an initiator fails, the successor to the initiator can notice when the message went all the way around by spotting its own ID in the list of IDs in the message. Then it can act as the new initiator. - Can we have a totally correct election algorithm for fully asynchronous systems? Computer Science / Software Engineering Notes Network - We actually can‚Äôt, because election algorithms can solve consensus, and as you‚Äôll see later, there exists n o co n sen sus algo rithm fo r an y asyn chro n o us system. - If that‚Äôs so, then the modified ring algorithm shouldn‚Äôt work. What‚Äôs wrong with it? - It‚Äôs good in theory, but in a real asynchronous system, you can‚Äôt truly detect leader failures or repair the ring (how do you know who will replace your neighbour?). Synchronous systems - With synchronous systems, we use a bully election algorithm. - The bully algorithm has a few assumptions: - Processes can crash and restart - Message delivery is reliable - It‚Äôs a synchronous system, so we can use timeouts - Each process knows all other processes and can communicate with all - Each process knows which processes have higher IDs - The whole point of the bully algorithm is to select a new non-failing coordinator. - The algorithm goes like this: - If process P recovers from failure, or detects that the current coordinator has failed: - If P has the highest ID, it sends a COORDINATOR message to all other processes - Otherwise, P sends an ELECTION message to all processes with a higher ID than itself - If P receives no ANSWER message after sending an ELECTION message, it declares itself the new coordinator and sends COORDINATOR messages to all processes. - If P receives an ANSWER message after sending an ELECTION message, it waits for a COORDINATOR message from some process with a higher ID (if timeout, it restarts the process) - If P receives an ELECTION message from a process with a lower ID, it sends an ANSWER message back and sends ELECTION messages to all processes with higher IDs. - If P receives a COORDINATOR message, it treats the sender as the coordinator. - Source:https://en.wikipedia.org/wiki/Bully_algorithm - Here is an example (it is worst-case, and only 1 notices 4 dies, when in practice everyone should notice): Image Exp lan atio n Process 4 is the coordinator, as indicated by the yellow colour. Computer Science / Software Engineering Notes Network Process 4 fails and 1 reacts by sending ELECTION messages to all processes with a higher ID. Process 2 and 3 answer process 1‚Äôs ELECTION message. Since processes 2 and 3 received ELECTION messages, they themselves start elections too. 3 answers 2, so 2 waits for a COORDINATOR message from someone higher up. 3 doesn‚Äôt get anything back from process 4 because it‚Äôs failed. 3 is about to hit the timeout and declare itself the coordinator, until... Uh oh! A rat is going to nibble on 3‚Äôs cabling and shut it down! 3, look out! He‚Äôs got air pods on, he can‚Äôt hear me! Oh god oh fuck I‚Äôm literally crying and shaking right now Oh no! Process 3 goes down before it can declare itself as the coordinator! Now 2 is waiting for a COORDINATOR message, but it‚Äôs not going to get one. 2 reaches the timeout and declares itself as the coordinator! It sends the COORDINATOR message to all participants below itself. Computer Science / Software Engineering Notes Network 1 receives the COORDINATOR message and declares 2 the coordinator. - So, what‚Äôs good about this algorithm? - It doesn‚Äôt exactly have safety because even though lower process IDs yield to higher ID ones, if a failed process revives itself while some lower process ID is declaring itself the coordinator, you‚Äôre going to get two different coordinator messages flying around! Who are you going to believe? - It has liveness because all processes participate and know the coordinator at the end. - So what‚Äôs the performance like? B est case Wo rst case When the coordinator is process N, and N fails, and N - 1 detects that failure and elects itself using COORDINATOR messages. There‚Äôs only an overhead of N - 2 coordinator messages and a delay of 1 message (because there‚Äôs no ELECTION/ANSWER messages, only the COORDINATOR messages being passed to everyone) When the least identifier process detects coordinator failure. There‚Äôs a total overhead of (N + 1)(N - 2) messages. Basically, that‚Äôs an O(N 2) complexity. Plus, there‚Äôs a huge delay of all the election and answer messages swarming around. Reliable and Ordered Multicast - Multicast is used for group communication - You spread one message amongst a group of participants - However, how do you ensure reliability (every process gets the message) or order (multicasts sent before should come first)? - We‚Äôll come back to those in a second, but first, let‚Äôs set some ground rules. - Here are some basic operations: - m u l t i c a s t ( g , m ) sends message m to all members of group g - d e l i v e r ( m ) delivers the message m (think of it like an acknowledgement of receiving the message, or a callback. B asically we run this as a confirmation of ‚Äúyes, we‚Äôve got the message‚Äù) - Message m contains information about the sender and the destination group. - C lo sed vs o p en groups:only group members can multicast to a clo sed gro up , whereas non-members can multicast to an o p en gro up . Computer Science / Software Engineering Notes Network - If you still don‚Äôt understand how d e l i v e r ( m ) works, think of it like this:when a node receives a message m, it won't actually \"get\" it until it runs deliver(m). Say if a node receives m1 and m2, but it receives m2 before m1, but it should've received them in order m1, and then m2. Some systems allow the node to wait until m1, and then run deliver(m1) and then deliver(m2). So you see, deliver is mainly used to order messages that were received in the wrong order. Basic multicast - This is just your normal multicast. It doesn‚Äôt guarantee reliability or order. - It works like this: - When we do multicast, we send the message m to each process p in the group g . - When a process p receives message m , it delivers message m to p (acknowledges it) - It really is basic;it‚Äôs just sending the same message to all the processes in the group, which is what multicast is, really. - Also works for open groups! - Only thing is, like I said, it doesn‚Äôt guarantee reliability (i.e. it can‚Äôt handle process or omission failure) or order. Reliable multicast - This version of multicast tolerates process crashes, so it guarantees reliability. - It assumes the following: - Group membership is known (it knows about everyone in the group) - Reliable communication - Processes only fail by crashing - Closed Group - It works like this: - Process p basic-multicasts to all members of a group g (including itself) - When a process receives a message, it performs basic-multicast again (unless we‚Äôre the original sender) and delivers (acknowledges) the message for itself. - So basically, when we receive a multicast message, we multicast the same message too. - Duplicate messages are identified and not delivered. - When receiving a duplicate message, processes do not deliver (acknowledge) the message twice. - Reliable multicast guarantees: - Integrity:a process delivers a message at most once and only group members receive it - Validity:processes deliver (acknowledge) their own multicast messages - A greement:if a process delivers (acknowledges) a multicasted message, then all other processes should too (all or none) Computer Science / Software Engineering Notes Network - This algorithm is good, but it‚Äôs inefficient and does not ensure order. Ordered multicast - Ordered multicast ensures order (obviously). - However, there are different kinds of order: - FIFO o rder:if a single process multicasts message #1, and then message #2, then all receiving processes must deliver (acknowledge) #1, and then #2. Messages sent by different processes can come in any order, since they‚Äôre not related. - C ausal o rder:like FIFO, except it incorporates things like response messages and the relation, so if , then m1 will be delivered first‚Üí ùëö 1 ‚Üí ùëö 2 and then m2. - To tal o rder:all processes receive messages in the same order (it doesn‚Äôt have to be the order in which they‚Äôre sent, just that all processes receive the same order of messages) - Causal order implies FIFO order, but total order does n o t imply FIFO / causal order (because total order says nothing about when the messages were actually sent)! - Here‚Äôs a visual example: Typ e o f o rder Image Exp lan atio n FIFO In the diagram, messages are being sent between three processes. The blocks are the ‚Äúreceiving‚Äù events, and the small black circle dots are the ‚Äúsending‚Äù events. The F1 message (beige blocks) is sent before the F2 message (black blocks) in the same process, hence why you‚Äôll always see, in all processes, beige blocks before the black blocks. The F3 message (orangey brown blocks) is independent of the other messages, so the orangey brown blocks can go anywhere between the other blocks. Computer Science / Software Engineering Notes Network Causal It‚Äôs clear that becauseùê∂ 1 ‚Üí ùê∂ 2 C1 was sent before C2 in the same process, so the beige blocks will always go before the black blocks. In this example, let‚Äôs say that C3 is sent in response to C1 (the beige block), so ùê∂ 1 ‚Üí ùê∂ 3 is true and the orangey brown blocks will always go after the beige blocks. However, C2 and C3 are independent of each other (concurrent), so black blocks and orangey brown blocks can go before or after each other. Total It doesn‚Äôt matter when the messages were sent, each process has the same order of receiving messages:beige, then black. - So now we know the different flavours of ordered multicasting;what do they actually do? - It‚Äôs not important to know the details, just a rough idea is enough. - With Ordered Multicast:FIFO Ordering, sequence numbers are used. - All processes keep a counter of how many multicast messages they‚Äôve sent. - They also package their messages with this counter too. - The counter is incremented when a message is sent. - Processes remember the latest sequence number of the latest message that they received from each process from their group (by default, they probably start at 0) - Messages sent out of order will be queued until the previous messages have been delivered (this is done using the counter in the message). - For example, if process P2 collects message #2 from P1 before it receives message #1, it‚Äôll know to wait for #1 first before delivering #2. - This works with basic / reliable multicast. - With Ordered Multicast:C ausal Ordering, we assume that groups are clo sed and n o n -o verlap p in g. - We need to use vector timestamps. Don‚Äôt be afraid! It‚Äôs pretty much the same use as in the ‚ÄúTime in Distributed Systems‚Äù topic. - Each process has their own vector clock, starting at (0, 0, 0 .. ). Computer Science / Software Engineering Notes Network - When a process sends a message, they increment their slot (e.g. P1 may increment to (1, 0, 0 ...)) and include their vector clock in the message. - When a process receives a message, it does one of two things: - If we haven‚Äôt got the messages that causally precede this message, put it in a queue. - If we have the messages that causally precede this message, then deliver (acknowledge) it and check the queue for messages that come after this one (and deliver those, too). - Don‚Äôt think about how the vector clocks work too hard;just keep in mind that, with the vector clocks, you can tell if a message causally precedes another message. - If you‚Äôre still confused, take a look at this example diagram which should clear things up: - With Ordered Multicast:Total Ordering, we use group-specific sequence numbers. - This is like FIFO, but instead of the counters being specific to each process, it‚Äôs specific to the whole group. - For example, when process P2 collects message #2 from P1, that‚Äôs not 2 as in ‚Äúthe second message that P1 sent‚Äù, that‚Äôs 2 as in ‚Äúthe second message that everyone in the group has sent‚Äù. - However, to manage something like this, you‚Äôd need either a: - sequencer process to assign sequence numbers (then you‚Äôd need an election) - distributed agreement on the assignment of sequence numbers - It‚Äôs actually imp o ssible to implement total ordering multicast in an asyn chro n o us system, because doing so would mean we can have complete consensus in an asynchronous system, which is impossible. - Think of consensus as being reducible to total ordering multicast (you know, like with Turing machines). - More info on that in the Consensus topic (hype)! Computer Science / Software Engineering Notes Network Consensus - What is consensus? - Consensus is simply a network collectively picking an option over a set of options, after one process proposes a value. - Let‚Äôs look at an example: - Kris, Ralsei and Susie need to agree on either defeating King or not (to spare Lancer‚Äôs feelings, you see), but can only talk to one person at a time. - However, there is a twist! Toby Fox changed the plot, and now Ralsei is a secret agent working against our Lightner heroes! He‚Äôs planning to mess up our arrangements by giving us false information! - Is there some protocol they can use to decide, despite our traitorous friend? - To solve this means to solve our consensus problem. - The consensus problem can be applied to more than just Deltarune fan-fictions: - B anking:should we commit or abort transaction? - Replicated data:should we commit or abort updates? - Agree on message delivery order in total order multicast (more on their relationship later) - We also need to reach a verdict despite arbitrary process failures! - First of all, we need some assumptions: - There are N processes - We have a reliable connection (messages are always received) - Must tolerate both crash failures (someone drops out) or Byzantine failures (someone lies, like our prince Ralsei) - So how do we actually reach consensus? What‚Äôs the algorithm for it? - First: - Processes are all in an undecided state - Each proposes an initial value drawn from the set of options - Then: - Everyone exchanges values with each other (using reliable multicast) - Each process decides on a value and enters a decided state - Basically, if you‚Äôve done the second coursework for this module, you‚Äôve implemented this already. - You may be thinking ‚ÄúSo what‚Äôs the problem? This looks fine to me.‚Äù - The problem is, does this still work when people start lying, or crashing? - Here are some properties of consensus that we want to achieve: Computer Science / Software Engineering Notes Network - Termin atio n :eventually, each process comes to a conclusion - A greemen t:all processes agree on the same option - In tegrity:if all processes propose the same value, then all processes must agree on that value at the end too (basically, no changing your mind!) - So if the algorithm has no failures, how does it fare? - It has termination and integrity because it uses reliable multicast - Because it‚Äôs a majority vote, we have agreement - But with failures, it doesn‚Äôt work so well anymore! - With crash failures, asynchronous systems can‚Äôt detect that (doesn‚Äôt know if they‚Äôve crashed or if they‚Äôre just really slow) - With Byzantine failures (lying), you need a certain number of truthful participants (this is even hard for synchronous systems, let alone asynchronous) - Now just before we jump right in to how synchronous and asynchronous differ, let me tell you what‚Äôs so special about consensus and RTO (reliable total order multicast). - This is assuming that only crash failures are allowed! - It can be said that if we solve the consensus problem, we can solve the RTO multicast problem. - If you‚Äôd like, you can think of it like consensus is reducible to RTO multicast, except it works both ways. - Implementing consensus using RTO-multicast: - Processes pick their options - Everyone uses RTO-multicast to multicast their options to everyone - Everyone picks an agreed option based on message order (last option, first option, whatever. It‚Äôs usually the first option) - Boom;you‚Äôve got a consensus. - This works because to do RTO-multicast, the participants have to have a consensus on the order of messages, so we can just use that to our advantage. - Implementing RTO-multicast using consensus: - For each value to be delivered, run a consensus algorithm to distribute it to everyone. - Because the consensus algorithm picks one option out of many, for each run you do, the outcome of that consensus defines the order of the RTO-multicast. - For example, if the first run they decide on A, then the second run they decide on C, then the third run they decide on B, the consensus algorithm has pretty much mapped out a global order for us:A, C, B! Synchronous - If processes crash, then we need rounds to make the algorithm work.ùëì ùëì + 1 - In all these rounds, participants send new votes to each other. Computer Science / Software Engineering Notes Network - This works because even if a process crashes, as long as it sends its vote to one other participant, that participant will send that new vote to other participants, and soon everyone will know that vote, long after that participant is dead! - At the end of it all, everyone should have the same votes (because the rounds can only end if there are no more new votes to send) - Hence, everyone can decide on a vote. - If there‚Äôs no failures, we can just use 2PC (Two-phase commit). That works fine. - In fact, 2PC is literally just consensus, except the participants don‚Äôt share votes. - It‚Äôs like a non-failure-safe consensus! - What about arbitrary failures? - Ah, now here‚Äôs where it gets interesting. - Let‚Äôs say you have processes , andùëÅ of them are liars.ùëì - Did you know that it‚Äôs impossible to get a consensus if ?ùëÅ ‚â§ 3 ùëì - In other words, if a third of your participants are liars, there‚Äôs no way you can get a consensus. This is called the Byzantine generals problem. - Where did this rule come from? - Let‚Äôs go back to our example above: - Kris decides that they should defeat King. - Susie wants to hear everyone‚Äôs opinions. Kris says ‚ÄúLet‚Äôs defeat King‚Äù. Ralsei says ‚ÄúKris doesn‚Äôt want to defeat King‚Äù. - What? They contradict each other! Who should Susie believe? Kris or Ralsei? - If only there was some other truth-teller that could be the tie-breaker in this dilemma... - In this example, and . , which is true, so no consensusùëÅ = 3 ùëì = 1 3 ‚â§ 3 ( 1 ) ‚Üí 3 ‚â§ 3 can be made. If only we had one extra truth-teller, then we could reach a consensus. Asynchronous - This is a bit of a depressing one (like the Halting problem) - Asynchronous systems don‚Äôt have timeouts, so we can‚Äôt tell the difference between a crashed process and a process that‚Äôs just taking its sweet time. - So there is actually n o consensus algorithm for asynchronous systems. - If there is no consensus algorithm, that means it‚Äôs also impossible to solve RTO-multicast. Computer Science / Software Engineering Notes Network - However, not all hope is lost. We can‚Äôt have a perfect consensus algorithm, but we can have an almost perfect algorithm using imperfect, close-to-reliable failure detectors. - In practice, this is usually good enough. Consistency models - Don‚Äôt worry;SEC / CRDTs are not examinable, so these notes will cover standard models only. That means less reading for you! - So what is a consistency model? - Basically, it‚Äôs a network model that copies information between nodes. - Why do we want that? - Better performance - Better scalability - Better availability - Better fault tolerance - We go into more detail in Leonardo‚Äôs bit, but basically there‚Äôs this C A P theo rem. - We can only have two of either: - C o n sisten cy:All nodes are updated with the right information - A vailability:Requests are served as long as one server is available - Partitio n To leran ce:Stuff still works, even if we partition servers - There‚Äôs two main strategies we can apply: - Prioritise consistency (C P):high cost, no conflicts - Prioritise availability (A P):low cost, possible conflicts - We say there‚Äôs two strategies, but in reality there‚Äôs a range of models we can use. - At the top of the range, we have strong consistency models. - They use CP. - When updates are committed, replicas need a consensus on the ordering of the updates. - At the bottom of the range, we have weak consistency models. - They use AP. - No global ordering;guarantees on consistency are relaxed - So what are the kinds of models we can use? - Strong consistency (e.g. Google‚Äôs BigTable) - Sequential consistency - ... - Causal consistency - Eventual consistency (e.g. Amazon‚Äôs Dynamo) - You need to learn all four of these, so let‚Äôs get started! Computer Science / Software Engineering Notes Network Strong consistency - Messages have global timestamps - The order of messages must respect these timestamps - Once a write is complete, all later reads return the value of that write or a later write. - Once a read is complete, all later reads return the value of that read or a later write. - So, for example, if process A writes something to a variable, and then process B writes another thing to that variable, the only thing people are ever going to read is that write that B did, because it overwrote A. - That‚Äôs it! It‚Äôs as you expect. Achieving this is expensive, and sometimes not necessary. Sequential consistency - This one is a little weird. It may seem counterintuitive at first, but bear with me! - Sequential consistency takes the operations performed by all the nodes, merges them into a sequence, and operates that sequence. - Think of it like a card shuffle, but instead of cards, it‚Äôs operations. - I also have an example if it‚Äôs not clear: - We have nodes 1, 2, 3 and 4. - They each perform operations on a variable x, like so: - What sequential consistency does is, it takes all those operations: - ... and in each ‚Äúiteration‚Äù, the arrow points to a node (it could be random, but it depends on the system), and it executes the operation on that ‚Äúnode queue‚Äù. - For example, let‚Äôs run the first iteration... Computer Science / Software Engineering Notes Network - Look at that! The arrow picked node 2! So now the system executes w r i t e ( x , 2 ) and writes x as 2 in the central data store... - The arrow has now picked node 3, node 3 will read value ‚Äòx‚Äô. It reads it as ‚Äò2‚Äô. - The arrow has now picked node 4, so now node 4 will read ‚Äòx‚Äôas 2. - The arrow has picked node 1, so now x will be overwritten as 1. - ... and then the arrow will pick node 3 to read, and then node 4 to read and then that‚Äôll be that. - So, when you think about it, the arrow picked the operations in such a way that: - What? How can those reads at the end return 1, when just before read returned 2? How can reading something change the value? - It‚Äôs not that read changed the value of x. It‚Äôs that the write operation of setting x to 1 (from node 1) didn‚Äôt take effect until after nodes 3 and 4 read x for the first time. - Think of it like threads:let‚Äôs say node 1 was just really slow for some reason, and took ages to write 1 to x. By the time node 1 has a chance to do anything, node 2 has already written 2 to x, and nodes 3 and 4 have already read x as 2. But before 3 and 4 reads x again, node 1 changes x to 1, so when 3 and 4 reads x again, it‚Äôs 1. - The arrow in the example picks an order of operations, and those operations become global in the sense that all replicas will perform the operations in that order. Computer Science / Software Engineering Notes Network - This is usually implemented using a totally-ordered multicast algorithm. - Shout out to James Bornholt for the analogy of using a ‚Äúswitch‚Äù to visualise sequential consistency in action! Causal consistency - Causal consistency is a little stronger than eventual consistency, as it uses the event causality relation (if you forgot, it‚Äôs the a happened before b thing)ùëé ‚Üí ùëè - If it uses event causality, then yes, you guessed it, this uses vector clocks. - Again, don‚Äôt think about it too hard. Just keep in mind that, because of vector clocks, we can tell if an operation should go before another operation. - Because we use vector clocks, causal consistency has better performance than sequential consistency. - Basically, causal consistency makes sure that if , it‚Äôll be sure to executeùëé ‚Üí ùëè operation a before b. - If we have two concurrent actions, then we don‚Äôt really care;either way will do. - Let‚Äôs have a short example: - Now, if node 3‚Äôs first r e a d ( x ) is a response to node 1‚Äôs w r i t e ( x , 1 ) , then when the replicas receive the operations to perform on their data, they‚Äôll make sure to execute node 1‚Äôs w r i t e ( x , 1 ) and then node 3‚Äôs r e a d ( x ) . - Assuming that all other operations are concurrent, it‚Äôll do them in any order. Because they‚Äôll do them in any order, causal consistency does not have a global order, making it less consistent than sequential or strong consistency. Eventual consistency - Eventual consistency is lazy;it‚Äôll eventually update the replicas. - But the implementation is easy;all you need to do is guarantee that updates actually reach the replicas! - However, we can have conflicts. If we do have conflicts, we can either: - use a consensus algorithm to decide, say, which write came first - roll back to previous configuration - delegate the problem to the application (let them handle it) - Amazon‚Äôs Dynamo uses the delegation solution to conflicts. - The main things about eventual consistency is that replicas eventually reach equivalent states, and that reads may not be up-to-date straight away. Computer Science / Software Engineering Notes Network - The good thing is that the reads and writes are fast, because they happen in the background (they‚Äôre not such a huge priority), and this can work even if the network is partitioned. - The bad thing is that consistency is very weak and we still need consensus anyway for conflicts. Garfield:Eventual consistency in cat form Strong eventual consistency - I know you don‚Äôt have to learn this, but it‚Äôs just one sentence. - There‚Äôs a good compromise between all of these models;it‚Äôs called stro n g even tual co n sisten cy. - That‚Äôs all. Have fun with Leonardo‚Äôs section! Other stuff (Leonardo) Data Replication and Scalability Data Replication - We can replicate data on multiple servers. - Why do that? - Fault tolerance:if one server crashes, the other one can still serve requests - Load balancing:we can distribute the pressure of requests - Location:we can place servers near users and increase performance - However, if we repeat data, how do we keep all the data on all the servers the same? - How do we achieve consistency? - Also, we want our service to be available if there is at least one server that‚Äôs up. - How do we achieve availability? Primary-backup - This is one design choice that allows consistency and availability. - There is one primary server and multiple backup servers (linked through a master-slave pattern) Computer Science / Software Engineering Notes Network - It works like this: 1. A client sends a request to the primary server. 2. If the primary server has already executed this request before, we go to step 5. 3. Primary server executes request and stores response 4. If it‚Äôs a write request, primary server updates and notifies all the backup (slave) servers and waits for ACKs (acknowledgements). 5. Primary server sends response to client. - So basically, we have a main server receiving all the requests, and backup servers that are just updated with new information on the fly. - What happens when a backup server fails? - Easy;if a backup fails, it‚Äôll eventually be restored / replaced, and then it‚Äôll update its state from one of the other backups (if there is one), so we don‚Äôt overload the primary. - When the primary fails... - ... how do we pick a new primary? - We can use an election algorithm to pick someone as a primary. - Since we need elections, and elections solve consensus, and it‚Äôs impossible to have a consensus algorithm in an asynchronous system, we know that primary-backup networks need to be synchronous! I just thought I‚Äôd tell you that. - ... how do clients know who the new primary is? - The primary can register itself as the primary with a name service that clients consult. - Basically, there‚Äôs some service that the client asks ‚Äúwho‚Äôs the primary?‚Äù and the service goes ‚Äúthat guy‚Äù. The new primary can tell that service ‚Äúhey, I‚Äôm the new primary now‚Äù. - ... what happens to pending requests? Computer Science / Software Engineering Notes Network - Clients resend the requests after a certain timeout, if they don‚Äôt get their response. - If the previous primary already executed and propagated that request, then we‚Äôll just go to step 2 and respond. - If not, then we just execute the request as normal with the new primary. - How many server failures can be tolerated? - With N servers, up to N - 1 server failures can be tolerated (because we always need at least 1 server up) CAP theorem - If you‚Äôve read the previous sections, you already know what the C A P theo rem is, but I‚Äôll go into a bit more detail here: - C onsistency: - All replicas are synchronised to have the same state - There must exist a total order of operations that is applied to all replicas (e.g. one guy can‚Äôt do operations in the order A B C and another do A C B , everyone has to do it in the same order) - If a read operation happens after a write, that read operation has to return the value in that write (which may seem trivial, but if you remember from consistency models, this isn‚Äôt always the case) - A vailability: - Requests are served as long as at least 1 server is up - Every request received by a non-failing node must result in a response Computer Science / Software Engineering Notes Network - Partition tolerance: - The data store keeps working if the servers are partitioned - In other words, the system needs to keep functioning even if two nodes lose communications with each other - Let‚Äôs say we got nodes A and B. They‚Äôre synced with each other and everything‚Äôs dandy. But, oh no! Here comes Gennaro with his rifle, and he accidentally shoots the communication cable between A and B while aiming for a fly! If we have partition tolerance, our system can still work and execute requests, even with A and B being independent from each other. - It‚Äôs impossible to have all 3, we can only have at most 2. - Why? Here is a short proof by contradiction. - Proof why CAP theorem is true - Let‚Äôs say all three are true;we have consistency, availability and partition tolerance. - Plus, we have nodes A and B, and a data value x = 0 initially. - We‚Äôve got one client who can write to x and read x. - A and B are independent, and our system still works because we have partition tolerance. - Now, our client will write x = 2 to our node A (and A will acknowledge): Computer Science / Software Engineering Notes Network - A can‚Äôt tell B about this write, because they‚Äôre independent. - Now the client will read x from node B: - Uh oh! The client has read ‚Äò0‚Äôinstead of ‚Äò2‚Äô. - This breaks our rule of consistency, because as we‚Äôve said before, if a read occurs after a write, that read has to return the value of that write. - As you can see, if we have all three rules, we‚Äôve got problems. - However, we can have two out of three. Let‚Äôs have a look at those: - AP (availability, partition tolerance) systems - We give up consistency to always be available and to partition our system. - So, basically, it‚Äôs exactly like our proof above. - Is there anything close to consistency that AP can provide? - Well, there is partially synchronous networks, where we‚Äôre synchronous in ‚Äúperiods‚Äù, and asynchronous every other time. - So our nodes will eventually become consistent. - Eventual consistency is a good example of this. - CP (consistency, partition tolerance) systems - We give up availability to have consistency and partition tolerance. - When our nodes lose connection with each other, we respond to requests with a ‚ÄúFAIL‚Äù message until they‚Äôre back together. - So in that proof above, instead of writing 2 to x, or returning a ‚Äò0‚Äôwhen asking for the data value x, A and B would‚Äôve just said ‚ÄúFAIL‚Äù. Computer Science / Software Engineering Notes Network - CA (consistency, availability) systems - This one‚Äôs a weird one, because here, we don‚Äôt have partition tolerance. - This means we don‚Äôt ‚Äúsupport‚Äù partition tolerance. - It doesn‚Äôt mean we continue working when nodes are separated, or we fail when nodes are separated. It means our system is built such that the concept of ‚Äúseparating nodes‚Äù doesn‚Äôt exist. - This is only applicable to single-site systems (like datacenters) which are not likely to experience network partitions. - But if we have a single-site system, that defeats the purpose of thinking about data replication! - In a distributed system, you cannot give up partition tolerance: https://codahale.com/you-cant-sacrifice-partition-tolerance/ - So CA isn‚Äôt really an option. We mainly care about choosing either consistency (CP) or availability (AP). Scalability - What is scalability? - Scalability:the ability to handle increased workload without adding resources to a system, or to handle increased workload by repeatedly applying a cost-effective strategy for extending a system‚Äôs capacity. - Basically, it means your system can handle lots of work at one time. - How do we assess scalability? - There are three steps: - Scale p arameters:the external parameters that change over time, the things that affect scalability (number of clients, workload, number of data objects etc.) - Scalability metrics:stats and measurements of system properties based on parameters - Laten cy:how long it takes to complete requests from POV of clients - Thro ughp ut:how many requests per second are processed - A vailability:probability that a system will work currently during a certain period Computer Science / Software Engineering Notes Network - Scalability criteria:expected scalability metric values (where your metrics should be at. You wanna hit as many of these as you can) - Worst latency observed by 1% of requests - Fo ur n in es availability:be available 99.99% of the time - Sounds amazing but it‚Äôs still around 53 minutes downtime per year - It‚Äôs always cool to add stuff to your system to make it more scalable, but... - ... there‚Äôs a point at which adding stuff doesn‚Äôt give you enough benefit to make it worthwhile. - This is called the law of diminishing returns. - The more servers you add, the more scalable your network is, right? - But what if you had 9,357,572 servers, and you added one to make it 9,357,573? Would that make much of a difference? - Probably not. You need to strategize your scalability tactics to be more effective! - One good scalability tactic is to identify bottlenecks and mitigate them. - For example, in the primary-backup model, there are two bottlenecks: 1. The primary server, as it‚Äôs the one handling all the requests 2. The backup servers, as the primary needs to wait for all the ACK signals - Here‚Äôs what we can do to mitigate them: 1. Share data on more than one primary server 2. Primary server only waits for majority of ACK signals - But here‚Äôs the drawbacks: 1. If there are data dependencies, we‚Äôll need coordination amongst primary servers 2. Not all backup servers might be up to date, and if the primary fails and a backup server is elected that isn‚Äôt up to date yet, we‚Äôll have problems - Is it worth the risk? I don‚Äôt know. I just write the notes. Highly Available Distributed Data Stores (Amazon Dynamo) - What is Amazon Dynamo? - How does Amazon Dynamo work? it just works - It‚Äôs a distributed key-value storage service run by Amazon. - Key-value store means that data are stored such that each value is mapped to a key, like how a map data structure works - It‚Äôs used for things like: - Shopping carts - Best seller list - Customer preferences - Product catalogue - Now, before you begin, keep this in mind:in the exam, it‚Äôs not important to know the intricate details! So if you don‚Äôt exactly understand how something works, don‚Äôt worry Computer Science / Software Engineering Notes Network too much. You‚Äôll probably be asked things like ‚ÄúHow well does Dynamo scale?‚Äù or ‚ÄúHow is Dynamo an AP system?‚Äù, not something like ‚ÄúWhen you have a ring in Dynamo and you get some data and nodes A, B and C are down and N = 10 and W = 5 and R = 4 and lalalalalalalalalalathequestiongoesonforever‚Äù so be sure you understand the concepts of Dynamo, and don‚Äôt sweat it if you don‚Äôt understand the underlying mechanics too much. - This applies to every other system in Distributed Systems & Networks. Replication - Amazon Dynamo has the following interface: - g e t ( k e y ) - p u t ( k e y , c o n t e x t , o b j e c t ) - It seems like something you‚Äôd expect for a key-value structure, except the c o n t e x t object. - We‚Äôll go over that more in detail later, but it‚Äôs basically for specifying the version of the object to update. - So what kind of structure is Amazon Dynamo? - It uses a Distributed Hash Table (DHT), but with a slight adjustment. - Basically, we have a ring of nodes: - When we put a key-value pairing (e.g. K -> O), we hash the key and it gets a respective position on the ring for that key (think of it like the wheel of fortune;the key points to a ‚Äúrandom‚Äù (it‚Äôs based on hash) spot on the ring): Computer Science / Software Engineering Notes Network - Now, that data object (key-value mapping) is replicated on at least N nodes, from that position, clockwise (say that N = 3, but we decide to replicate 5): - Those 5 nodes make up K‚Äôs p referen ce list, which is a list of nodes that is responsible for a certain key. - Each node is responsible for the keys between itself and its N th predecessor (e.g. D is responsible for keys whose position lie between itself, D, and it‚Äôs N th predecessor, A, because any keys that fall in that range will be added to node D) - The reason why we pick more than N nodes is to account for node failure, so if one of the first N nodes dies (B, C or D), we can use the other nodes (E or F). Consistency - Dynamo sacrifices consistency for availability, but it can have conflicts. - It ensures consistency by allowing changes to propagate to other nodes in the background over time, making Dynamo a lot like eventual consistency. - How does Dynamo resolve conflicts? - It resolves them at read time, so when you try to read data, that‚Äôs when the conflict is resolved. - First, Dynamo tries to do it by itself using distinct data versions (using vector clocks), but if it has trouble, it‚Äôll send the client the list of versions. Computer Science / Software Engineering Notes Network - How does Dynamo‚Äôs get / put requests work? - First, Dynamo finds the first node in the preference list for that key, which becomes the req uest co o rdin ato r. - A request invokes the get / put operation on the first N healthy nodes in the preference list (including the request coordinator). - Now here is where it gets complicated: - Two numbers are picked, W and R. - W is the minimum number of nodes that must perform the put request - R is the minimum number of nodes that must perform the get request - When doing a put request: - Request coordinator performs put locally, then sends the new version to the other N - 1 nodes. - Once the request coordinator gets W - 1 responses, then the write is successful - When doing a get request: - Request coordinator asks all other N - 1 nodes. - Once the request coordinator gets R - 1 responses, then the read is successful. If different versions are found, we return all those that are causally unrelated (concurrent) (basically, a byproduct of syntactic reconciliation). - So, basically, when we write, W out of N nodes are updated, and when we read we consider R out of N nodes‚Äôread operations. - Which nodes out of N are picked? The ones that respond first, usually. - There are several combinations we can get out of this: - - can return stale versions of the objectùëÖ + ùëä ‚â§ ùëÅ Image Exp lan atio n Here, we‚Äôre putting K = 2 into their respective nodes. Since W = 2, we‚Äôll only accept 2 node responses. The green nodes are the nodes that have sent write responses first, filling up our W window. For some reason, the request does not reach D, E and F. Computer Science / Software Engineering Notes Network Here, we‚Äôre trying to get K. However, node D responds because B and C are down. Now we‚Äôve got a stale version of K! - - when we read, we can get multiple versions, leading to aùëÖ + ùëä > ùëÅ quorum-like system Image Exp lan atio n Like last time, we‚Äôre putting K = 2 into their respective nodes. Since W = 2, we‚Äôll only write to the 2 most available nodes. The green nodes are the nodes that have written the update. Here, we‚Äôre trying to get K. B goes down, and R = 2, so we‚Äôll fetch the values C and D have. They‚Äôre two different versions:one is old and one is new! - - optimise reading (because only one node is doing it)ùëÖ = 1 , ùëä = ùëÅ - - optimise writing (because only one node is doing it)ùëÖ = ùëÅ, ùëä = 1 Computer Science / Software Engineering Notes Network - When R = 1 or W = 1, it‚Äôs quicker, but we have less consistency. - For better latency, R and W are usually configured to be less than N. - There‚Äôs a problem with this, though! - A put operation may return before all the nodes are updated, so get operations may return outdated objects. - How do we fix this? - We use versioning! - Basically, if we try to update an object that hasn‚Äôt finished updating yet, we create a branch, similar to Git. - We need to diverge the branches;we don‚Äôt want to deal with lots of branches! - There‚Äôs two ways to diverge them: - Syntactic reconciliation - If the new version subsumes the previous version, then reconciliation is easy. - Semantic reconciliation - If there‚Äôs a bigger conflict, then we will send the branches to the client and the client will take care of it. - For example, with a shopping cart, we would union the carts;the data from adding to a cart is never lost but deleted cart items may resurface - With each version of the object, a vector clock is attached. - The vector clock slots consist of a pair, containing the node ID and the update count. - The context object we talked about before contains vector clock information. - When we send branches to the client, we also send their vector clock information. - Can we see this in action? Of course we can! Image D escrip tio n Here, we write Object #1, written as O1, by node Sx. This is the first time Sx has written anything, so it gets the value of ‚Äò1‚Äôin its vector clock spot. Computer Science / Software Engineering Notes Network Here, we overwrite the object with #2, also done by node Sx. As a result, the update count for Sx is now 2. We write yet again, to object #3. This time, node Sy does it, so Sx‚Äôs counter stays at 2, and Sy‚Äôs counter becomes 1. Here‚Äôs where things get interesting though: Sy‚Äôs writes are taking a long time. Maybe there‚Äôs lag. Anyway, the client overwrites with #4 and Sz, a new node, writes that. Now, a new branch has been formed, because there were two changes to the same version, #2. Now we‚Äôre doing a new read. The client finds out that there‚Äôs a conflict and there‚Äôs branches to join together. The client fixes the conflict and pushes object #5. The vector clock still takes into account who has updated the object in all branches. Computer Science / Software Engineering Notes Network Fault tolerance - How does Dynamo handle faults? - It uses something called slo p p y q uo rum.( Õ°¬∞Õú ñÕ°¬∞) - Basically, if A temporarily goes down, and we want to do some put request, we‚Äôll send the update to D, and D will do the put request instead. - The reason why we don‚Äôt send it to B or C is because D becomes the new coordinator, hence B and C would know of the operation. - Then, when A is back online, D will tell A about the update. - The update has a hint in its metadata that suggests which node was the intended recipient, so D is able to know to inform A of the update. - This is called hin ted han do ff. - This way, Dynamo ensures that get/put requests do not fail due to node/network failures. - Additionally, we can achieve the highest level of availability if we set W to 1, since we only need one node to be available to write anything. - Dynamo also has something called rep lica syn chro n isatio n , where a periodic protocol runs in the background and ensures data is synchronised between nodes. - It‚Äôs based on Merkle trees. - It solves the problem of node D failing before it can update node A in hinted handoff. Why is Amazon Dynamo AP? - Sloppy quorum allows Dynamo to serve even when nodes go offline - Additionally, there are consistency conflicts, so it‚Äôs definitely not CP. - They‚Äôre resolved through: - Syntactic / semantic reconciliation - Replica synchronisation - So eventually all replicas will converge, which means it follows eventual consistency. Computer Science / Software Engineering Notes Network Scalability - Since the keys are dotted around the ring when hashed, data is distributed amongst the nodes pretty well. - It‚Äôs also really easy to add nodes to the ring! - Let‚Äôs show an example: - Remember our first example? - N is 3, so B is in charge of keys landing anywhere between F and B. - C is in charge of keys between G and C. - D is in charge of keys between A and D. - What if we add a node X between A and B? - B isn‚Äôt in charge of F to B keys anymore;it‚Äôs in charge of G to B, because X has distanced B away from F! - C is now in charge of A to C - D is now in charge of X to D - Since B is no longer in charge of any keys between F to G, B can send all those keys to X, because X is now in charge of them. - Additionally, C will send all keys from G to A to X... - ... and D will send all keys from A to X to X. - That‚Äôs it! Now everything is stable again. Computer Science / Software Engineering Notes Network - Dynamo is scalable;the more nodes you add, the less keys each node has to remember. Consistent Distributed Data Stores (Google BigTable) - BigTable, like Amazon Dynamo, is a service that Google provides that stores data. - Google uses it themselves, for things like Google Earth and Google Finance. Data model - BigTable fulfils five properties: - Sparse:NULL values aren‚Äôt stored, to save space - D istributed:data is distributed amongst nodes - Persistent:data is saved on stable storage - Multi-dimensional:data is indexed by row, column and timestamp - Sorted:data is stored on disk in some defined order - So how does BigTable actually work? - Well, you know tables, right? I hope you know what a table is. ID Name Part Stan d 1 Jotaro Kujo 3 Star Platinum 2 Josuke Higashikata 4 Crazy Diamond 3 Giorno Giovanna 5 Gold Experience - Well, in BigTable, categories are clumped together, so instead of accessing a row with all its columns, you can specify a row with a column family, containing columns that are often requested together. - For example, let‚Äôs say Name and Part are clumped together in a family. - We could specify any row, and the family, and we would get back data sets like: - 1 :‚ÄúJotaro Kujo‚Äù, 3 - 2 :‚ÄúJosuke Higashikata‚Äù, 4 - 3 :‚ÄúGiorno Giovanna‚Äù, 5 - Each cell can be timestamped, so if cells change, different versions are created and timestamped. - There‚Äôs also a garbage collection scheme to either keep only N versions available, or to delete versions past a certain date. - There‚Äôs also an implementation of BigTable called WebTable, which Google uses to handle webpages. - The row (ID) is the URL of the webpage. - The columns are the properties of the pages (content, links, language etc.) - The cells are timestamped when the information is retrieved Computer Science / Software Engineering Notes Network - There‚Äôs also an anchor column family, which stores references to the page (think Google PageRank). Architecture - Rows of column families are stored in tablets, sorted by key. - A tablet is like a storage unit that contains some rows. - A bunch of tablets are stored by a tablet server. - All the tablet servers are managed by a master server. - Clients directly talk to the tablet servers and the master server. - Clients ask the master server what tablets to talk to in which server, and the client reads/writes data through the tablets in the tablet servers. - Caution:The data isn‚Äôt actually stored in the tablet! It points to the SSTables (files, see below), with the corresponding data, within the GFS chunkservers (also see below). - The data is only stored in the tablet from a logical perspective, but the chunkservers of GFS are where the data really resides. - BigTable has a file system, called GFS (Go o gle File System). - Files are divided into fixed-size chun ks (of around 64MB), kind of like sectors on a disc. - Chunks are replicated on multiple chun kservers (around 3). - The master from before manages all the chunkservers, and stores things like: - Namespace (to help navigate the chunkservers) - Access control information - Mapping from files -> chunks - Mapping from chunks -> chunkservers - Clients ask the master what chunkserver it should talk to, and then the client talks to them (the client being BigTable;actual clients don‚Äôt talk to the GFS system) - The master can also cache queries by the client. Computer Science / Software Engineering Notes Network - There is one more unit called chubby. It‚Äôs highly available. - Chubby is like a configuration server that stores all the useful tidbits and parameters that BigTable requires to function, such as: - Persistent concurrency locks for files and directories - Handle tablet server lifetimes - Store schema information - Ensures that there is at most one active master at any time - It contains a small namespace with files and directories, and reads/writes to files are atomic. - The entire architecture looks like this: Computer Science / Software Engineering Notes Network - What about scalability? - What happens when there are more client requests? - Tablet servers receive more traffic, because clients directly talk to them. With more traffic to tablet servers, tablet servers are requesting the chuckservers more, so the traffic of tablet servers are proportional to the traffic of chunkservers. - The master server only has as much traffic as there are clients who need to know what tablet servers to talk to;they‚Äôre not as often spoken to as other servers, like tablet servers or chunkservers, so they experience less traffic. - What is the bottleneck? - Tablet servers and GFS chunkservers, because they‚Äôre the ones that all the clients are requesting writes / reads from. - What can be done to mitigate the bottleneck? - You can add more tablet servers / chunkservers, so the data is distributed more and there is less stress on individual servers. Computer Science / Software Engineering Notes Network - However, the more tablet / chunk servers you have, the closer their strain gets to the master‚Äôs strain. Sooner or later, the master‚Äôs strain will be higher than the tablet / chunk servers‚Äôstrain. If that happens, the master itself will become the bottleneck! Plus, it doesn‚Äôt help that there are more servers to request about from the master. Tablets - There are multiple levels of tablets: - First level:Chubby points to root tablet - Second level:Root tablet points to METADATA tablets - Third level:METADATA tablets point to user data tablets - The client library caches tablet locations and also prefetches locations of tablets the user might want to use next. - The master server can keep track of: - Mapping from tablets to tablet servers - Unassigned tablets - The master has a unique ‚Äúmaster lock‚Äù in chubby. - If the chubby session expires, the master kills itself. - If the master dies, a new one is promptly started. - When there is no master, client requests cannot be served. - When a tablet server starts, it acquires a lock in chubby, in the form of a file in some server directory. - The master monitors this server directory to discover new tablet servers. - The master detects if a tablet server isn‚Äôt working by: - Asking the tablet server about its lock Computer Science / Software Engineering Notes Network - If there is a problem, the master tries to get the server‚Äôs lock itself - If the master can get the lock, that means the chubby is OK, it‚Äôs the tablet server that‚Äôs the problem - When the tablet server has a problem, the master deletes all the chubby files associated with it and moves the associated tablets to the unassigned tablets. - If a tablet server loses its lock, it stops serving requests. It‚Äôll try to acquire its lock again as long as the file exists, but if the file does not exist, the server will kill itself. SSTables - An SSTable (So rted Strin gs Table) is a file format used by BigTable to store information. - It is a persistent, immutable ordered map from keys to values. - Remember, it‚Äôs immutable, so we write once and we only read from it afterwards. - We can either look up a single key or iterate over multiple key-value pairs in a key range. - It‚Äôs also split up into blocks, and we can use a block index (which is at the end of an SSTable) to search for blocks and load them in memory. - So what happens when we write to a tablet? - The write operation goes into a buffer called ‚Äúmemtable‚Äù. - As we request more write operations, more goes into the ‚Äúmemtable‚Äù buffer. - Older updates are stored in the SSTables. - The writes are also logged into a commit log. - The read operation is done by merging the memtable and all the SSTables together to get a single value. Computer Science / Software Engineering Notes Network - So what happens to the operations in the memtable? How do we create new SSTables? - We have something called minor compaction, where we empty out the memtable into a new SSTable. - We also have something called major compaction, where we compress all the SSTables and the memtable into one big SSTable (like merging layers in Photoshop), so that we don‚Äôt end up with thousands of SSTables. Computer Science / Software Engineering Notes Network Why is Google BigTable CP? - Availability is given up in the following situations: - If the master dies, no requests can be attended to - When a tablet server dies, the tablets that were handled by that server cannot be used until they are reassigned - If chubby fails, no synchronisation or client requests - If GFS fails, SSTables and commit logs cannot be accessed - Consistency exists in the following situations: - Each row is managed by a single tablet server (requests are serialised) - Writes for a specific tablet to GFS are done by one tablet (reads and writes are serialised) - Writes to GFS are always appends (copy-on-write), so concurrently there are no race conditions (because data is immutable, for more info check PLC notes) - SSTables are write once and then read, so there‚Äôs no interleaving between reads and writes - Commit logs are only read upon compactions and recoveries;reads are not interleaved with writes - Therefore we have strong consistency. Online Distributed Processing - How do we process streams of data / event-based data online? - Our process can‚Äôt quit, because data streams are continuous. - There exists services to help us process data like that! Use cases - It‚Äôs used by Twitter to look at trends coming and fading. That can be interpreted as a data stream, and trends are happening all the time, so the system has to always be on, running and parsing data. Computer Science / Software Engineering Notes Network - It can also be used by Google Trends for search queries. - It‚Äôs also used for user profiling, bus routing, sentiment analysis in tweet streams and fraud monitoring. Requirements - So what do we actually need? - We need: - Real-time computing - Low computation latency (do stuff fast) - Correlation with fresh data (don‚Äôt use old stuff) - Input loads can vary (be scalable) - Hardware / software failures may occur (be fault tolerant) Apache Storm - Apache Storm is an implementation of this. - It has an abstraction that can work with event-based data, it can sustain high input streams and can parallelise computation. Data model - So how does it actually work? - It works like this: - Sp o ut:outputs the raw data that we want to work on - B o lt:modifies the data in some way and either passes it on to another bolt, or stores it - The topology usually looks something like this: - For example, if we wanted to implement some word counting example, we could have: - One spout for the raw data string - A bolt to split the string into words - Another bolt to count the words - So we have something like: Computer Science / Software Engineering Notes Network Architecture - So that‚Äôs the high-level stuff, what about the low-level stuff? - A storm cluster (one of the things we have above) consists of one master node and several wo rker nodes. - The master node runs the Nimbus process, which manages all the workers. - The worker nodes run Supervisor processes, as well as a number of worker processes. Computer Science / Software Engineering Notes Network - The topology is submitted to the master, and the master allocates a component for each Worker node using a scheduler. - Each component can have multiple instances, and each instance is mapped to an executor (a thread). - Workers (processes) are run when the Worker node must run executors for the given topology. - Each Worker node handles their own local input / output, and the supervisor makes sure everything is running alright. - The Nimbus handles potential failures and resource usage. Replication - Let‚Äôs say you have a stream of numbers and you wanted to use this architecture to perform some operations on it: - The yellow operation is stateful, because it requires a state to run (it needs to remember the previously highest score) - The red and orange operations are stateless;they are pure functions and do not rely on some kind of memory or state. - Therefore, we can split the data we receive and replicate these stateless functions to create a pipeline: - We can replicate the same list of stateless operations as many times as we want (within reason). The number of times we do this is called the rep licatio n facto r. - We can apply this practice to Apache Storm, with spouts and bolts: Computer Science / Software Engineering Notes Network - When we have multiple spouts (like that Spout x8), nodes won‚Äôt be so clogged with input data;it‚Äôll be distributed, so even if we receive an influx of data, our system won‚Äôt crash. - When we have multiple bolts (like the Bolt x3, or the Bolt x5), we are doing the same thing as the example above;we‚Äôre pipelining stateless operations to split up the workload amongst multiple nodes. Stream grouping - But how do we split up the data to distribute? In the example above, we just chopped the data in half and fed each pipeline half the data. In practice, that may not be the most efficient approach;we may be able to optimise our splitting by choosing the right gro up in g strategy! - Types of grouping strategies: - Shuffle:data is randomly distributed between pipelines - Fields:pipes data based on some predicate on their fields - A ll:all data is distributed on all pipelines (may be useful if randomness is involved) - No n e:you don‚Äôt care (by default, this is the same as shuffle, but in the future A pache Storm will change this) - D irect:the producer of the data directly picks a pipeline programmatically - Lo cal o r shuffle:will shuffle and pipe data only to the target nodes that are running on the same Worker node as the data source. If there are none that fit that description, then it just works like normal shuffle. - Sources:1 2 - These are Leo‚Äôs slides, so you know what we‚Äôve got to do... - How does Apache Storm scale? - What happens when workload increases? - Computational stress increases for some spouts / bolts - What is the bottleneck? - The CPU or memory for overloaded spout / bolt instances Computer Science / Software Engineering Notes Network - What can be done to mitigate the bottleneck? - Two things: 1. Increase the replication factor of overloaded spouts/bolts, so we distribute the workload 2. Add more Worker nodes so more systems can run more instances of the spouts/bolts, thereby distributing the workload Fault tolerance - A tuple can spark the production of multiple tuples in the topology. - When we say tuple, we just mean some input data (it‚Äôs mainly to account for multiple data elements residing within one data unit) - What this means is that one piece of data going into the topology can result in a whole tree of resulting data units. - That looks like a mathematical structure... - That‚Äôs a D A G (directed acyclic grap h)! - We have a component called an acker that monitors the DAG of each input tuple. - Each bolt sends an ‚Äúack‚Äù signal to the acker when they correctly process each input tuple. - When the acker receives this, it prunes the DAG at that bolt‚Äôs respective position. Computer Science / Software Engineering Notes Network - The acker goes along the bolts, from the finish to the start, receiving acks and pruning the DAG, until there‚Äôs nothing left of the DAG. - When the DAG is empty, the acker knows that the input tuple was processed correctly. In that case, the acker notifies the original spout of that input tuple for garbage collection. - However, if there is a timeout and the DAG isn‚Äôt empty yet, the acker notifies the original spout about the failure and the spout will replay the failed tuple. Computer Science / Software Engineering Notes Network - What about when spouts/bolts fail? - If a worker dies, the supervisor restarts it (unless it fails at boot time;then the Nimbus will reassign the work to a different machine). - If a machine fails, the assigned instances will timeout and the Nimbus will reassign them. - If the Nimbus/Supervisors die, they are restarted - They behave like a fail-fast process (better to die quickly than to waste time in a half-working state) - They are stateless in practice - There is no explicit state management for components in Storm. Batch Distributed Processing - With online distributed processing, it‚Äôs highly complex and hard to maintain. - With batch distributed processing, incoming data is stored;not processed straight away. - It‚Äôs done in batches over time. - Therefore you can have a high input rate because it‚Äôs only being stored;it‚Äôs computationally less expensive than actually processing stuff. - However, because everything is stored, batch might not be suitable for real-time applications. Implementation #1:Google MapReduce - Logically, computation is split into two phases: - Map :( k , v ) - > l i s t o f ( k i , v i ) - Reduce:( k , l i s t o f v i ) - > ( k , v ) - By doing this, we can simplify: - Parallelisation Computer Science / Software Engineering Notes Network - Handling of machine failures - For example let‚Äôs do a word count example - Input:‚ÄúDeer Bear River Car Car River Deer Car Bear‚Äù - Output:[(Bear, 2), (Car, 3), (Deer, 2), (River, 2)] - How do we do this with map and reduce? - It‚Äôs actually 4 steps: - Splitting:split input text into paragraphs (e.g. 3 words each) - Map:just map a word to the number 1 - Shuffling:order the key-value mappings into groups of equal keys - Reduce:count the number of mappings and reduce to one key mapped to the count Implementation #2:Apache Hadoop - Hadoop also does map and reduce - However it has a job tracker, which delegates jobs to task trackers, which delegates tasks to task processes Computer Science / Software Engineering Notes Network - Task trackers have a limited number of tasks - If full, tasks go into a queue and wait for other tasks to finish - Bottleneck:if there're too many tasks and the task tracker can‚Äôt take them all, there will be too many tasks in the queue. - Solution:add more task trackers (seems simple enough) - If there‚Äôs too many task trackers, job tracker will become the bottleneck (unfortunately there‚Äôs no mitigation for that) - Hadoop Distributed File System (HDFS) - Remember GFS with BigTable? This is kind of like that. - Data is organised into files and directories. - It‚Äôs designed for: - Single writer - Multiple readers - Data is replicated for optimisation, minimising data loss and improving availability. - Data is divided into chunks, usually of max size 64MB (getting deja vu?) - Each chunk is replicated over DataNodes (chunkserver equivalent in BigTable) - The replication factor of DataNodes is a configuration parameter - The NameNode decides which chunk is stored in which DataNode. - When we write, access the NameNode first, and then write to the DataNote. Computer Science / Software Engineering Notes Network - When we read, the NameNode picks out the closest DataNode for us. - What about splitting and shuffling that Google MapReduce had? - Yes, Hadoop does that too. - Each mapper keeps its own output partitioned by key and notifies the JobTracker about what keys it has. - Each reducer is informed by the JobTracker on what keys to process and collects the corresponding data from TaskTrackers. - Apache Hadoop has something called locality awareness. - In typical development, each TaskTracker is placed in a machine with its own DataNode. - Mappers get their data from DataNodes. Wouldn‚Äôt it be a pain if the mappers had to fetch data from nodes all over the network every time they wanted data? - That‚Äôs why the JobTracker assigns mappers to TaskTrackers with DataNodes storing data that the respective mapper needs. - When that happens, the mapper doesn‚Äôt need to fetch their data from across the network;they can just do it locally, saving lots of time and minimising data movement. - What happens when stuff fails? - If a task fails: - The JobTracker detects it - Task is assigned to another TaskTracker - If a task fails more than a certain number of times, the whole job fails - If a TaskTracker has too many failed tasks, it is blacklisted - If a TaskTracker fails: - It‚Äôs blacklisted (obviously) - All the tasks for that TaskTracker are reassigned to another TaskTracker - If a JobTracker fails: - It‚Äôs a single point of failure! (basically, you‚Äôre fucked) TL;DR - Look! It‚Äôs the reference guide of Computer Science! - Well, more specifically, Software Engineering MEng... - How are you doing today? Good? - Studying hard? - What? No? - What‚Äôs that, you say? The slides are crap and make you want to commit not continue your lifespan any longer? You‚Äôre also too lazy to read the above notes because you‚Äôve left revision to the last minute because you have no self-control and regret your life choices? - Scroll down. Don‚Äôt worry, I gotchu. - However, if you do have time, please read all of the above notes at least once before you move on to this reference section. Computer Science / Software Engineering Notes Network Kirk‚Äôs stuff OSI mo del TC P/IP mo del Tan en baum‚Äôs bo o k Application Application Application Presentation Transport Transport Session Internet Network Transport Link Link Network Hardware Physical Data Link Physical - Types of medium: - Coaxial cable - Twisted pair - Power line - Fibre optic - Wireless (laser, sound, ultrasonic, pulses, radar) - Packet:a unit of data in the Network layer (our payload) - Frame:a unit of data in the Link layer (what the link layer actually sends) - Ho p by ho p tran smissio n :where data is transported through intermediate nodes to its destination. - Packet-switched n etwo rk:A network where packets dynamically find their own way to a destination without a set path - Link layer models: - C o n n ectio n less, n o ackn o wledgemen ts - A ckn o wledged, co n n ectio n less service - A ckn o wledged, co n n ectio n -o rien ted service - A RQ (auto matic rep eat-req uest):error-control mechanism that uses ACKs and timeouts to ensure reliable communications with unreliable recipient - Three kinds of ARQ protocols: - Stop-and-wait - Go-back-N - Selective-repeat - Detect errors using p arity bit or C RC (cyclic redun dan cy check) - Ethern et:de facto link layer standard Computer Science / Software Engineering Notes Network - Ethernet used to use C SMA /C D (C arrier Sense Multiple A ccess with C ollision D etection) - Ethernet frames have priority setting from 1 to 7, which affects prioritisation at switches. - WiFi:wireless alternative to Ethernet. Works in 2.4GHz or 5GHz. - Wifi uses CSMA/CA (C arrier Sense Multiple A ccess with C ollision A voidance) - Can use Req uest to Sen d / C lear to Sen d (RTS/C TS) to increase performance - MA C (Media A ccess C o n tro l) address:a unique ID for network interface controllers (NICs) at the link layer. (48 bits long, can be extended to 64 bit) - C o n cen trato r device:central hardware in a network;nodes connect to it - Hubs an d rep eaters:Old! Just reroute packets - B ridges an d switches:Smart! Learn what packets go where - A RP (A ddress Reso lutio n Pro to co l):a protocol used by host:given IP address, can get MAC address - 4 kinds of message: - Un icast - B ro adcast - Multicast - A n ycast - IP address p lan : range of local IPs a host can have - IP subn et:a localised network behind a router - Sp an n in g tree p ro to co l:enables and disables switches so a path is always available for packets (within reason) - VLA N (virtual LA N):a logical network;not physical. Each node can be in different physical LANs but be in the same VLAN. - IP (or In tern et Pro to co l) is the main protocol used in the network layer. - Properties: - Packet-switched, connectionless - Unreliable - Routing - Globally unique, delegated addresses - Main protocols: - IPv4 - IPv6 - ICMP - for diagnostics and control - ICMPv6 - IPSEC - for security Computer Science / Software Engineering Notes Network - Sto re-an d-fo rward p acket switchin g:a technique where data is sent to an intermediary node, then passed on to either another intermediary node or the destination node. Basically the same as hop by hop transmission. - IPv4 datagram: - MTU (or Maximum Tran smissio n Un it) is the size of the largest data unit that can be communicated in a single network layer transaction. - If data unit is bigger than MTU, fragmentation happens. - IPv4 classes: C lass Prefix ran ge Prefix len gth A 0.0.0.0 to 127.0.0.0 8 bits B 128.0.0.0 to 191.255.0.0. 16 bits C 192.0.0.0 to 223.255.255.0 24 bits D 224.0.0.0 to 239.255.255.255 n/a E 240.0.0.0 to 255.255.255.255 n/a - Maximise address space using: - D HC P (or D yn amic Ho st C o n figuratio n Pro to co l) - NA T (or Netwo rk A ddress Tran slatio n ) - C lassless In ter-D o main Ro utin g - Properties of subnet: - Subnet network address - Subnet prefix length - Subnet mask (same information as prefix length) - Subnet IP broadcast address - Can use mask to get from IP in subnet to network address and broadcast address - IC MP (or In tern et C o n tro l Message Pro to co l):protocol for checking status between hosts (pinging is included in this). - Ro uter advertisemen t:telling other routers about yourself Computer Science / Software Engineering Notes Network - Types of routing: - Static routing:configure routes manually - Dynamic routing:establish routes on-the-fly - A ggregatin g p refixes:sending packets to networks with smaller prefixes, so that we don‚Äôt need to access specific routers - Routers build up their routing table with routing protocols. - D istan ce vecto r:only talk to neighbouring routers and build up a shortest distance to our destination using the Bellman-Ford algorithm. - Lin k state:talk to all routers to establish full knowledge of site - Link state usually better than distance vector - A uto n o mo us system (A S):a network or a collection of networks that are all managed and supervised by a single entity or organisation, typically an ISP (Internet Service Provider). - In terio r ro utin g p ro to co l:exchanging routing information between gateways (routers) within autonomous systems - Exterio r ro utin g p ro to co l:exchanging routing information between autonomous systems - B o rder Gateway Pro to co l (B GP):allowed autonomous systems to store and exchange routing information about packet destinations. The de facto exterior routing protocol. - UD P (User D atagram Pro to co l):connectionless, low overhead protocol;‚Äúfire and forget‚Äù basis - UDP properties: - Connectionless - Application layer has to retransmit, if required - Constant bit rate - Low overhead - TC P (Tran smissio n C o n tro l Pro to co l):connection oriented protocol - TCP properties: - Connection management - Flow control - Tries to avoid congestion - Retransmission - Reassembles segments in correct order - TCP connection establishment: Computer Science / Software Engineering Notes Network TC P UD P C o n n ectio n Connection oriented Connectionless:‚Äúfire and forget‚Äù Reliability Handles ACK & retransmissions Application needs to handle ACK & retransmissions if needed D ata Order Guaranteed that it arrives and in the correct order No guarantee that data is received in the order sent Header 20-bytes minimum 8-bytes Go o d fo r Applications that need high reliability Applications that need fast and efficient transmission Examp le p ro to co ls HTTP(S), FTP, SMTP, Telnet, SSH DHCP, TFTP, SNMP, RIP, RTP, COAP - So cket:created when sender and receiver act as end-points. - D NS (D o main Name System):pairs up domain names to IP addresses - Domain names are delegated through To p Level D o main (TLD ) registrars - D NS reso lver:server that acts as a DNS - DNS record types: Computer Science / Software Engineering Notes Network - DNS servers use a hierarchical delegation structure, where DNS servers point to other DNS servers that know about certain URL suffixes. - D NS glue:mapping one DNS server to another - IP an ycast:same IP visible in multiple locations - Fast flux D NS:association between IP address and domain name is changed frequently - Public D NS servers:open public DNS servers, can be used for speed, reliability, parental controls etc. - Application layer services: - Teln et:simple unencrypted terminal emulation protocol - Email: - SMTP (Simp le Mail Tran sfer Pro to co l):send emails - IMA P (In tern et Message A ccess Pro to co l):receive emails - HTTP (Hyp erText Tran sfer Pro to co l):uses TCP on port 80 to send text - HTTP/2:header is now binary, uses server push, multiplex multiple requests on the same TCP connection - QUIC (Quick UD P In tern et C o n n ectio n s):UDP protocol, trying to replace TCP, pushed by Google - C o A P (C o n strain ed A p p licatio n Pro to co l):HTTP-like protocol with minimal overheads - RTSP (Real Time Streamin g Pro to co l):used for streaming video/audio - SMB (Server Message B lo ck):file sharing protocol by Microsoft - NFS (Netwo rk File System):file-sharing protocol used on Linux and Unix - P2P (Peer-to -Peer):every device has the same priority and shares data with each other - IPv6 has 128-bit addresses - Written in colon-separated hex format - Repeated zeros are replaced with double colon - IPv6 dedicated address scopes: - : : 1 / 1 2 8 - lo o p back Computer Science / Software Engineering Notes Network - : : / 1 2 8 - un sp ecified (equivalent to 0.0.0.0) - f e 8 0 : : / 1 0 - Lin k-lo cal address (used only on local link) - f c 0 0 : : / 7 - Un iq ue Lo cal A ddress (ULA , used within a site) - 2 0 0 0 : : / 3 - Glo bal Un icast - f f 0 0 : : / 8 - Multicast - Other properties of IPv6: - No more NAT - More ‚Äúplug and play‚Äù than IPv4 - Streamlined header - Fragmentation occurs at sender - IPv6 header is 40 bytes, and can daisy chain extension headers - IPv6 RA :Router advertisement for IPv6 - StateLess A ddress A uto C o n figuratio n (SLA A C ):automatic basic network configuration for IPv6 - D ual stack:having both IPv4 and IPv6 - Tunnelling technologies: - 6in 4 - encapsulates v6 packets in v4 packets - Teredo - encapsulates v6 into UDP v4 - D S-Lite (no, not the console) - encapsulates v4 packets in v6 packets - VPNs work too - IPSEC encryption is baked into v6 - v6 hosts can pick their own address - D NS amp lificatio n attack:attacker sends lots of messages to DNS with target‚Äôs IP, so DNS spam target - DNS cookies can be used to help mitigate DNS amplification attacks - Stateless firewall:firewall that only tests incoming packets on predicates - Stateful firewall:firewall that can remember things and keep track of packets - Some firewalls even act on the application layer and can read packets to tell if the content looks alright - NID S (Netwo rk In trusio n D etectio n System):sniffs network activity, checking for intruders - NA C (Netwo rk A ccess C o n tro l):solution that helps against physical network breaches - Exten sible A uthen ticatio n Pro to co l (EA P):a protocol that authenticates clients - IPSEC (IP Security):encryption at the network layer;prevents against sniffing - VPNs (Virtual Private Netwo rk):simulates direct connection between devices - Two kinds of VPN: Computer Science / Software Engineering Notes Network - Site-to -site VPN:connects two networks together - Remo te-access VPN:clients connect to a VPN server - D D o S (D istributed D en ial o f Service attack):lots of clients target a network and takes it down - Ways to mitigate DDoS: - A n ycast/co n ten t delivery n etwo rks:spread the load across lots of networks/systems - Resp o n sive n etwo rk team:block attacks as they occur and redistribute services across different connections - Go o d relatio n ship s with up stream p ro viders:get them to help blocking attack traffic - WEP (Wired Eq uivalen t Privacy):Old, don‚Äôt use this. It‚Äôs crackable in, like, 3 minutes. - WPA (WiFi Pro tected A ccess I):Fixed version of WEP that uses Temp o ral Key In tegrity Pro to co l (TKIP) - WPA /2 (WiFi Pro tected A ccess II):More complex version of WPA, uses 128-bit AES - WPA -Perso n al:uses pre-shared keys - WPA -En terp rise:uses 802.1x authentication (for that extra pinch of security) Tim‚Äôs stuff - Distributed System Models - Physical models: - Early 80‚Äôs:up to 100 nodes connected by LAN - In tern et-scale (90‚Äôs):large nodes connected by Internet;nodes are static, not embedded and autonomous - C o n temp o rary:hundreds of nodes, and nodes can change location. Can be embedded - Emergin g:systems of systems - Types of communication paradigms: - In ter-p ro cess communication:low-level communication e.g. Java sockets - Remo te invocation:two-way communication, sending and receiving - In direct communication:one-to-many communication using groups, message queues, distributed shared memory systems etc. - Two main architectural models: - C lien t-server architecture:there‚Äôs one central ‚Äúserver‚Äù node, and lots of other ‚Äúclient‚Äù nodes that query a server with resources. Servers can also be used as clients. - Peer-to -p eer architecture:all processes share similar roles, and data is distributed amongst peers. Used in software like Gnutella or BitTorrent. Computer Science / Software Engineering Notes Network - Three strategies for infrastructure: - Use of multiple servers - several servers implement a service and distribute resources and services to increase performance - Proxies and caches - make web proxies store often used data to make it more quickly accessible - Mobile code - send code to the recipient, so they can run the code locally, which improves performance (but can also be a security threat) - Architectural patterns: - Layering:layers services, each layer makes use of the service below it - Two-tier and three-tier architectures:like MVC but with networks - Thin clients:clients just have an API or interface, and all the work is done at the server - Proxies:proxy offers same interface as the server they‚Äôre mirroring - Fundamental models: - Interaction:how participants interact with each other - Failure:describes types of failures - Security:ensures security in processes and communication - Distributed Object Systems - RMI (Remo te Metho d In vo catio n ):call methods on remote objects as if they were local - Stub:proxy for a remote object. Implements same methods as remote interface - You need a registry and a server to run a complete RMI server. - Java security manager uses a policy file to enforce rules;helps to trust code coming to your computer - In RMI, multiple clients may access critical region. - Use Java monitors to ensure no deadlocks (basically just s y n c h r o n i z e d ) <- guaran teein g mutual exclusio n - Can also use w a i t , n o t i f y and n o t i f y A l l , which uses observer pattern - RMI limitation:client and server must run JVM - Data Serialisation - Can send objects over networks with S e r i a l i z a b l e interface, O b j e c t O u t p u t / I n p u t S t r e a m and version UID - Can use serialisation to send mobile code - Can pass references to objects with RMI and callbacks - You can override r e a d O b j e c t and w r i t e O b j e c t and define your own language-dependent format. - JSON (JavaScrip t Object No tatio n ):a language-independent syntax for exchanging structured data Computer Science / Software Engineering Notes Network - GSON:JSON helper API made by Google in Java - JSON-LD :encoding linked data to JSON using a common schema - Loose Coupling Time co up led Time un co up led Sp ace co up led Message is directed specifically towards receiver. Receiver must be present when the message is sent. Example:sockets, remote invocation Message is directed specifically towards receiver. Receiver doesn‚Äôt have to be present when the message is sent. Example:snail mail Sp ace un co up led Sender doesn‚Äôt know exactly who they‚Äôre sending to. Receiver must be present when the message is sent. Example:IP multicast Sender doesn‚Äôt know exactly who they‚Äôre sending to. Receiver doesn‚Äôt have to be present when the message is sent. Example:publish & subscribe with message queues - Gro up co mmun icatio n :sending messages to a group of clients (usually done with multicast) - Syn chro n o us gro up co mmun icatio n :connections are strongly established and messages are sent out in real-time - A syn chro n o us gro up co mmun icatio n :messages are sent via UDP to everyone - Desired properties of group communication: - Reliability: - Integrity:message received is identical to the one sent - Validity:every message is eventually delivered - Agreement:if a message is delivered to one member, it‚Äôs delivered to all - Ordering:sender order is preserved (FIFO), and can either have: - Causal ordering:just make sure if message m2 is sent in response to m1, m2 is received by all members after m1. - Total ordering:all messages are sent in the same order, regardless of causality. - Publish an d subscribe:a model where publishers send messages to clients who mark themselves as ‚Äúsubscribed‚Äù - Hetero gen eity:supports different components written by different developers - Subscription models: Computer Science / Software Engineering Notes Network - C han n el-based:subscribers subscribe to a channel, so they receive all events - To p ic-based:subscribers subscribe to a set of topics, so they only receive messages sent to those topics - C o n ten t-based:subscribers filter messages based on queries, and only receive those. - Implementation models: - C en tralised:A single publisher sends messages to multiple subscribers via point-to-point messages (it lacks resilience and scalability) - D istributed:A network of publishers work together (also called federated) - Peer-to -p eer:Some fully peer-to-peer implementations are possible - MQTT (Message Queue Telemetry Tran sp o rt):uses message queues to send messages to receivers - Uses a HTTP URL-like method for querying sub-topics - Can use wildcards: - Single-level wildcards ‚Äú+‚Äù selects every topic at that hierarchy - Multi-level wildcards ‚Äú#‚Äù selects every topic path - Cheaper to maintain than HTTPS - Subscription can be: - Durable:messages are stored until next time subscriber connects - Non-durable:messages remain as long as subscriber is connected - RabbitMQ:implementation supporting many protocols and languages - Distributed Transactions - Distributed data must follow ACID rules - Problems: - Lost updates:update is overwritten - Inconsistent retrievals:read in the middle of a write - Fix:Serial eq uivalen ce:Locks / optimistic concurrency control - Problems: - Dirty reads:transaction wants to abort after another transaction happened during it - Premature writes:write happens just before an abort - Fix:Distributed commit protocols - Sin gle-p hase co mmit:waits for everyone‚Äôs acknowledgement before committing - Two -p hase co mmit:send out a vote. If everyone votes to commit, commit. If single no, then abort - If coordinator crashes -> Two-phase commit = blo ckin g p ro to co l - Two -versio n lo ckin g:have multiple locks for each operation;a lock may not be given if another kind of lock has already been set Computer Science / Software Engineering Notes Network Lo ck req uested Lo ck already set Read Write Commit None OK OK OK Read OK OK WAIT Write OK WAIT Commit WAIT WAIT Corina‚Äôs stuff - Time in Distributed Systems - Extern al syn chro n isatio n :all processes are synched up to some external clock, like UTC - C ristian ‚Äôs algo rithm:get time from server, then offset it with ùëá ùëüùëúùë¢ùëõùëë 2 - Netwo rk Time Pro to co l (NTP):clients are synced up to UTC in a hierarchy system - In tern al syn chro n isatio n :processes sync each other up using their own clocks - B erkeley‚Äôs algo rithm:master polls everyone‚Äôs clocks, returns amount by which they need to adjust - Relation , where and are events:ùëé ‚Üí ùëè ùëé ùëè - If and in the same process and occurs before b, thenùëé ùëè ùëé ùëé ‚Üí ùëè - If is sending and is receiving, thenùëé ùëè ùëé ‚Üí ùëè - Transitivity rule:if and thenùëé ‚Üí ùëè ùëè ‚Üí ùëê ùëé ‚Üí ùëê - is allowedùëé ‚Üí ùëé - Concurrent:ùëé || ùëè - Lamp o rt‚Äôs lo gical clo ck:each process has integer clock value, it updates when receiving / sending / executing an event. implies , not the otherùëé ‚Üí ùëè ùêø( ùëé) ‚â§ ùêø( ùëè) way around. - To tally o rdered lo gical clo ck:like Lamport, but it‚Äôs a pair including process ID - Vecto r clo ck:uses a vector instead of an integer, where each process has their own slot in the vector (isomorphic to a list of totally ordered logical clocks). impliesùëé ‚Üí ùëè and implies .ùëâ( ùëé) ‚â§ ùëâ( ùëè) ùêø( ùëé) ‚â§ ùêø( ùëè) ùëé ‚Üí ùëè - Distributed Mutual Exclusion - Types of failure detectors: - Unreliable:either unsuspected or suspected - Reliable:either unsuspected or failure - Assumptions: - Network is reliable but asynchronous - Processes don‚Äôt fail - Processes spend finite time in critical section (they don‚Äôt hang while there) Computer Science / Software Engineering Notes Network - Correctness properties: - Safety:at most one process is in critical section - Liveness:requests to enter/exit eventually succeed - Fairness:access to critical section granted in happened-before order C en tral Server A lgo rithm Rin g-based algo rithm Token-based, uses a central server, clients ask for a token and waits if it‚Äôs not available. - safety - liveness - no fairness - good performance - single point of failure Tokens are passed around a ring of processes. - safety - liveness - no fairness - no bottleneck - higher bandwidth usage Ricart an d A grawala‚Äôs A lgo rithm Maekawa‚Äôs Vo tin g algo rithm Uses totally-ordered time stamps. Must receive responses from all other participants before using critical region. - safety - liveness - fairness - good performance - failure of even just one node has big repercussions Only need all responses from our respective group to access critical region. All groups overlap. - safety - no liveness - no fairness - performance is slightly better than Ricart and Agrawala - can have deadlocks (but can be mitigated) Computer Science / Software Engineering Notes Network - Leader Election - Assumptions: - N processes with unique, totally ordered IDs - Messages are eventually delivered (no failed packets) - Process with highest ID must win the election - Correctness: - Safety:a participant‚Äôs vote must either be or P (where P is non-crashed‚ä• process with highest ID) - Liveness:all processes participate & eventually set their vote to something other than (or they crash)‚ä• Rin g-based algo rithm B ully electio n algo rithm Pass ELECTION and ELECTED messages around in a ring, updating the process ID inside it. Used in asyn chro n o us systems. - safety - liveness - does not tolerate failures (however we can modify to use a list, which mitigates this) - O(N) in both worst and best case When a coordinator fails, failure detection systems fire off in other nodes and they send ELECTION and COORDINATOR messages to decide the new coordinator. Used in syn chro n o us systems. - no safety - liveness - O(N 2) worst case, O(N) best case Computer Science / Software Engineering Notes Network - Reliable and Ordered Multicast - C lo sed gro up :only members can multicast - Op en gro up :anyone can multicast - B asic multicast:sends messages directly to all participants. No specific order or reliability - Reliable multicast:basic multicasts, then everyone who receives a new message basic multicasts that too. Ensures reliability. It‚Äôs what we implemented in the second coursework. - Ordered multicast:a multicast that ensures some form of order - FIFO o rder:messages sent before other messages must come first. Process-specific sequence numbers are used. - C ausal o rder:extension of FIFO, but uses causal relation (includes‚Üí concepts like responses). Vector timestamps are used. - To tal o rder:all messages received in the same order by all processes. Group-specific sequence numbers are used. Imp o ssible to use in asyn chro n o us system, because total order can solve consensus. - Consensus - B yzan tin e failures:processes lying/giving false information in a consensus algorithm - Solve consensus => can solve RTO multicast - Solve RTO multicast => can solve consensus - In synchronous systems, we can use 2PC to get consensus - Impossible to get consensus if , where N is processes and f is number ofùëÅ ‚â§ 3 ùëì liars. Called Byzantine generals problem. - In asynchronous systems, no algorithm for consensus - Can have almost-perfect algorithm, like modified ring-based algorithm - Consistency models C P Stro n g co n sisten cy (Go o gle B igTable) - Messages have global timestamps - Order of messages respect timestamp - Expensive, and not always necessary Seq uen tial co n sisten cy - Shuffles read and write operations together, like multi-threading or if a switch selects operations each iteration Stro n g even tual co n sisten cy - Good compromise (don‚Äôt need to know this one) C ausal co n sisten cy - Uses the causal relation and vector clocks - Operations are only in order by the causal relation - Better performance than sequential A P Even tual co n sisten cy (A mazo n D yn amo ) Computer Science / Software Engineering Notes Network - Lazy;eventually update replicas - Can have conflicts, so we can use consensus or roll back Leonardo‚Äôs stuff - Data Replication and Scalability - Primary-backup :one primary server, many back-up servers. Back-up servers are updated with updates passed to primary server. - Bottleneck:primary and back-up servers - Mitigation: - Share data on lots of primary servers, but we‚Äôll need coordination. - Primary server only waits for some ACKs, but not all back-ups may be up-to-date. - C A P theo rem:Pick two out of three: - C onsistency - A vailability - Partition tolerance - Assessing scalability: - Scale p arameters:raw data that changes over time - Scalability metrics:measurements of parameters - Scalability criteria:conditions based on metrics that should be true - Highly Available Distributed Data Stores (Amazon Dynamo) - A mazo n D yn amo :key-value store based on a ring architecture (distributed hash table). - Preferen ce list:list of nodes responsible for a key. More than N - Req uest co o rdin ato r:first non-faulty node in the preference list Computer Science / Software Engineering Notes Network - Three parameters: - N - number of nodes to request reads/writes - W - number of expected nodes to respond to writes - R - number of expected nodes to respond to reads - - can return stale versions of the objectùëÖ + ùëä ‚â§ ùëÅ - - when we read, we can get multiple versionsùëÖ + ùëä > ùëÅ - - optimise readingùëÖ = 1 , ùëä = ùëÅ - - optimise writingùëÖ = ùëÅ, ùëä = 1 - How to diverge branches: - Syn tactic reco n ciliatio n :if new version subsumes previous version, simply merge - Seman tic reco n ciliatio n :send branches to client to decide. Uses vector clocks with node ID and update count pairs - Slo p p y q uo rum:if node in preference list dies, pick a node outside N but within preference list to update and remind dead node when it comes back online (called hin ted han do ff) - Rep lica syn chro n isatio n :periodic protocol runs in background and ensures everything is synced. Based on Merkle trees. - Why AP:sloppy quorum lets Dynamo run even when nodes go down. There are conflicts, so it‚Äôs not CP - Bottleneck:all the nodes, collectively - Mitigation:add more nodes - Scalability:adding nodes is easy, the following nodes gives the new node the keys they‚Äôre not in charge of anymore - Consistent Distributed Data Stores (Google BigTable) - Go o gle B igTable:table-based store that splits up columns into families - Rows of families => stored in tablets - Tablets => stored in tablet servers Computer Science / Software Engineering Notes Network - Tablet servers => managed by master server - Tablets point to SSTables with data in chunkservers - GFS (Go o gle File System):file system that BigTable uses - Files => divided into chun ks - Chunks => replicated onto chun kservers - Chunkservers => managed by master server - C hubby:highly available config server storing files, directories, parameters, tidbits to help BigTable run - Tablet levels: - First level:Chubby -> root tablet - Second level:Root tablet -> METADATA tablets - Third level:METADATA tablets -> user data tablets - Master server and tablet servers have their own locks in Chubby - SSTable (So rted Strin gs Table):file format used by BigTable to store data - Immutable ordered key-value - Split up into blocks - memtable is buffer, SSTable store locked immutable changes - writes:goes to memtable, reads:merge memtable and SSTables together to read Min o r co mp actio n Majo r co mp actio n Empty out memtable into new SSTable Compress all SSTables and memtable into Computer Science / Software Engineering Notes Network one big SSTable - Why CP:if master dies, no requests, or when tablet server dies, tablet cannot serve requests;less availability - GFS is copy-on-write, so reads/writes are serialised, no race conditions, more consistency - Bottleneck:tablet servers and GFS chunkservers - Mitigation:add more tablet servers / chunkservers, but then master will become bottleneck - Online Distributed Processing - A p ache Sto rm:used to handle streams of incoming data / events - Sp o ut:outputs raw data - B o lt:modifies data in some way and passes it on / stores it - One master node, many wo rker nodes - Master node runs Nimbus process, which has a scheduler - Worker nodes have a sup erviso r with many executo rs (threads) running worker processes - Whole thing is called a cluster. - Rep licatio n :pipelining stateless operations to distribute workload - Grouping strategies: - Shuffle:random - Fields:based on fields predicate Computer Science / Software Engineering Notes Network - A ll:all data is sent on all pipes - No n e:don‚Äôt care - D irect:producer picks explicitly - Lo cal o r shuffle:pipe data to nodes running on same worker node - Bottleneck:CPU / memory of overloaded spout/bolts. - Mitigation:increase replication factor or add more worker nodes - acker monitors DAG of input tuple and prunes DAG when bolt acks acker. - When DAG is empty, acker sends message to spout saying input processing was successful - When timeout, acker sends message to spout saying it‚Äôs failed. Spout may repeat input. - Batch Distributed Processing - We store data instead of processing it straight away - Not suitable for real-time systems - Uses splitting -> map -> shuffling -> reduce procedure - Go o gle Map Reduce:implementation of batch distributed processing - A p ache Hado o p :another implementation of batch distributed processing - JobTracker -> delegates jobs to TaskTrackers - TaskTracker -> delegates tasks to task processes - Bottleneck:task tracker, if too many tasks - Mitigation:add more task trackers. If we add too many, job tracker will be bottleneck - HD FS (Hado o p D istributed File System):file system used by Hadoop, designed for single writer multiple reader - Data => divided into chunks - Chunks => replicated over DataNodes - NameNode => decides which chunk goes in which DataNode Computer Science / Software Engineering Notes Network - Lo cality awaren ess:job tracker assigns mappers to task trackers with data nodes storing the data they need - Task fails:Job tracker detects it, moves it to another task tracker - Task tracker fails:blacklisted, all tasks moved to another task tracker - Job tracker fails:you‚Äôre stuffed;single point of failure üéäYou‚Äôve reached the end. Good luck on the exam! üéä","libVersion":"0.3.2","langs":""}