{"path":"Git Ignore/Heavy Stuff/Matthew Barnes Notes/Theory of Computing Notes.pdf","text":"Computer Science / Software Engineering Notes Network Theory of Computing Matthew Barnes, Mathias Ritter B o o ks 4 A uto mata theo ry: Regular lan guages 5 Deterministic Finite Automata 5 Alphabets and strings 5 Languages 6 Deterministic finite automata (DFAs) 6 Product construction 9 Regular languages 10 Nondeterminism, subset construction and œµ-moves 15 Nondeterminism 15 Subset construction 18 œµ-moves 21 Regular expressions and Kleene‚Äôs theorem 23 Defining regular expressions 23 Atomic patterns 23 Compound patterns 24 Examples 24 Kleene‚Äôs theorem 24 Reg exp to ŒµNFA 25 ŒµNFA to reg exp 26 Limitations of regular languages 29 Pumping (üéÉ) Lemma for regular languages - contrapositive form 30 A uto mata theo ry: C o n text free lan guages 3 4 Pushdown Automata (PDA) 34 Transition relation 34 Configuration 35 Acceptance 35 By final state 36 By empty stack 36 Example PDA accepting palindromes 36 Context free grammars 38 Chomsky Normal Form 41 Greibach Normal Form 42 Removing epsilon and unit productions 42 Removing left-recursive productions 42 Converting between CFG, CNF and GNF 44 Computer Science / Software Engineering Notes Network Converting a CFG to CNF 44 Converting a CFG to GNF 46 PDA and CFG conversions 49 CFG to PDA 49 PDA to CFG 51 Proving closure 58 Union 58 Concatenation 58 Kleene star 59 Intersection with regular languages 59 Limits of context-free languages 60 Pumping (üéÉ) Lemma for context-free languages - contrapositive form 63 C o mp utability theo ry 6 7 Turing machines 67 Decidability 68 Recursive and R.E languages 68 Proof:Recursive Sets Closed under Complement 68 (Semi) Decidable properties 70 Universal Turing machines 71 Multiple tapes 71 Simulating Turing machines 71 Encoding Turing machines 71 Constructing a UTM 72 Halting problem 72 Proof by contradiction 72 Proof by diagonalisation 73 Decidable / Undecidable problems 74 Reductions 77 Properties of reductions 82 Rice‚Äôs theorem 83 C o mp lexity theo ry 8 5 Big-O and Big-œ¥ 86 Big-œ¥ 86 Big-O 86 The class P 87 Feasible and infeasible problems 87 Decision problems 87 Definition 88 The PATH problem 89 The HAMPATH problem 90 Regular and context-free languages 90 Computer Science / Software Engineering Notes Network The class NP 91 Non-deterministic Turing machine 91 Time complexity of Turing machines 92 Definition 95 The SAT problem 95 The HAMPATH problem 96 The TSP(D) problem 97 The 3COL problem 97 NP = P? 97 Presburger arithmetic 98 NP-Completeness 99 Polynomial time reduction 99 3COL to SAT 100 NP-hard 101 The Cook-Levin theorem 101 What is NP-completeness 101 Space complexity 101 Space complexity 101 PSPACE 103 NPSPACE 103 Savitch‚Äôs Theorem 104 EXPTIME 104 Relationships between complexity classes 104 PSPACE-hard 104 PSPACE-completeness 105 TL; D R 1 0 5 Automata theory:Regular languages 105 Automata theory:Context free languages 106 Computability theory 107 Complexity theory 108 Computer Science / Software Engineering Notes Network Books - There are two main books for this module. I‚Äôve added PDF links to both of them. - Dexter C. Kozen, Automata and Computabilty, Springer, 1999 (Kozen) - Sipser M, Introduction to the Theory of Computation, PWS, 1997 (Sipser) Computer Science / Software Engineering Notes Network Automata theory:Regular languages - Automata relates to machines with finite memory. - Unlike maths, where we can have infinite of something, we cannot have infinite of something in an automata because it‚Äôll run out of memory. - Automata also relates to pattern matching, modelling, verification of hardware etc. Deterministic Finite Automata Alphabets and strings - An alp habet is a finite set of elements. It is denoted with capital sigma, Œ£. - Examples: - Œ£ = {0, 1} - Œ£ = {a, b, c} - Œ£ ‚â† {1, 2, 3, 4, ...} - A strin g ‚Äòs‚Äôover Œ£ is a finite sequence of elements of Œ£. - Two strings ‚Äòs‚Äôand ‚Äòt‚Äôare equal when they have the same elements of the same order. - Examples: - Œ£ = {0, 1}, s = ‚Äú0100110‚Äù - Œ£ = {a, b}, s = ‚Äúabbaba‚Äù - The set o f all strin gs is denoted with sigma star, Œ£*. - It will always be infinite, unless the alphabet is empty. - In every alphabet, including an empty alphabet, the set contains the emp ty strin g ‚Äòœµ‚Äô. - More names for Œ£* are ‚Äúfree monoid on Œ£‚Äù, or ‚ÄúKleene star of Œ£‚Äù. - Examples: - Œ£ = {}, Œ£* = { œµ } - Œ£ = {a}, Œ£* = { œµ, a, aa, aaa, aaaa ... } - Œ£ = {0, 1}, Œ£* = { œµ, 0, 1, 10, 11, 100, 001, 000 ...} - We can clean up our notation by not including Œ£, but just replacing it with its definition: - {}* = { œµ } - {a}* = { œµ, a, aa, aaa, aaaa ... } - {0, 1}* = { œµ, 0, 1, 10, 11, 100, 001, 000 ...} - The len gth # of a string is its number of elements. - Examples: - #(abba) = 4 - #(00101) = 5 Computer Science / Software Engineering Notes Network - #(joestar) = 7 - The emp ty strin g is usually denoted with a lunate epsilon character, œµ. - Laws: - œµ = ‚Äú‚Äù - #(œµ) = 0 - œµœµ = œµ - You can co n caten ate two strings, ‚Äòs‚Äôand ‚Äòt‚Äô, like this:‚Äòst‚Äô. - Example: - s = ‚Äúab‚Äù, t = ‚Äúba‚Äù, st = ‚Äúabba‚Äù - s = 011, t = 101, st = 011101 - s = ‚Äúza‚Äù, t = ‚Äúwarudo‚Äù, st = ‚Äúzawarudo‚Äù - s = œµ, t = œµ, st = œµ - œµs = sœµ = s Languages - A lan guage L over an alphabet Œ£ is some subset of strings in Œ£*. - Examples: - Œ£ = {a, b, c} - L1 = {œµ, a, bb, cba} - L2 = {bbb, aaa} - L3 = {cccccacccccc} - L4 = √ò = {} - Two languages are equal when they contain the same strings (in terms of sets, they are equal). - If the language should also contain the empty string œµ it must be explicitly added to the language as an element of the set. Deterministic finite automata (DFAs) - A fin ite auto mata is a mathematical model of a system with a finite number of states and a finite amount of memory space. - A state is a description of a system at some point in time. - A tran sitio n allows the DFA to go from one state to the other. - Think of DFAs like flow-charts;you go from one state to the next until you reach the goal state. - There are three kinds of finite automata: - Deterministic - Nondeterministic - Nondeterministic with œµ-moves - Right now, we‚Äôll focus on deterministic finite automata. - A DFA (deterministic finite automata) has 5 properties: Pro p erty Symbo l D escrip tio n Computer Science / Software Engineering Notes Network States Q Possible states that the automata can be in. Alphabet Œ£ The alphabet that the transition names depend on. Transitions Œ¥ A function that allows the automata to go from one state to the other by consuming a symbol. This takes an element of Œ£ and a state from Q, and outputs the next state from Q to transition to. Start state s The state that the automata starts at. Final states (accept states) F Set of states at which, if the automata ends at them, it accepts the string that was entered into it. - To define a DFA mathematically, use the properties above into a tuple: - Example, given that M is a DFA: - M = (Q, Œ£, Œ¥, s, F) - An automata takes in a string that contains letters from the alphabet and reads it from left to right, with each letter being an action (or transition) that changes the state of the automata. - All states must have all possible transitions, i.e. each state must have exactly one transition for every element of the alphabet - If the automata en ds o n a fin al state, it‚Äôll accep t the string. - If the automata do es n o t en d o n a fin al state, it‚Äôll reject the string. - You can also represent DFAs as graphs (pictures), similar to state-machine diagrams: Computer Science / Software Engineering Notes Network - This small arrow pointing to the ‚Äò0‚Äôstate coming from nowhere means that ‚Äò0‚Äô is the initial state. - The states that are not filled in are not final states. - The states that are filled in are final states. - The arrows represent the transitions between states, which are triggered by the input character shown - This DFA accepts strings like abbab and babbbab, but not abba or œµ. - To say that a string ‚Äòs‚Äôtakes the DFA from state 0 to state 1, you would write that as: - - Where: - Left-hand side = beginning state - Right-hand side = ending state - Text on the top = string transition - More examples: - - - Computer Science / Software Engineering Notes Network Product construction - Product construction is where you merge two DFAs together, so that the combined DFA is actually the two component DFAs running in parallel. - The states aren‚Äôt just single string / character names. The states are referenced in a tuple (or pair), with each element being a state name from one of the component DFAs. - Let‚Äôs define the DFAs of L1 and L2 as this, respectively: - Now, if we found the product of the DFA of L1 and the DFA of L2, then the states of that product would be: - (0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2), (3, 0), (3, 1), (3, 2) - The product transition would need a pair state and a transition name. For example, you could go from (2,0) to (3,1) by using ‚Äòa‚Äô, or you could go from (0,0) to (1,0) by using ‚Äòb‚Äô. - The set of final states F is F1 ‚®Ø F2, where F1 is the set of final states of L1 and F2 is the set of final states of L2. Therefore, with normal, unedited product construction, for the DFA to accept the string, we need to be in a final state for both component DFAs. - This can be changed, however, to just ‚Äúat least one DFA to be on a final state‚Äù if we define F to be (Q1 ‚®Ø F2) ‚à™ (F1 ‚®Ø Q2), where Qx is the set of states for a DFA. - Therefore, the language expressed by the product of and is .ùêø 1 ùêø 2 ùêø 1 ‚à© ùêø 2 - It‚Äôs best to view this as a table, where you can see the DFAs of L1 and L2 simultaneously: L1 ‚Äôs D FA state L2 ‚Äôs D FA state Pro duct state Tran sitio n Step 0 0 (0,0) None (yet) 0 1 1 (1,1) a 1 2 1 (2,1) b 2 Computer Science / Software Engineering Notes Network 3 2 (3,2) a 3 - To view this more simply, you can just follow two DFAs at the same time, and put one‚Äôs state on the left of the tuple and the other‚Äôs state on the right of the tuple. It‚Äôs nothing more than running two DFAs at the same time, inputting the same word into both of them. - If you‚Äôre confused check this helpful video out. Regular languages - When you have a DFA called M, then L(M) is the language of all accepted strings. - For example, in the previous DFA, L(M) = {b, ab, aab, bb, abb ...} and it will not include elements like ‚Äòa‚Äô, ‚Äòœµ‚Äô, ‚Äòba‚Äôor ‚Äòbba‚Äôbecause they all will not be accepted by that DFA. - A regular lan guage L is when there exists some DFA M such that L(M) exists. - More informally, a language L is regular if you can come up with some DFA where it‚Äôll accept allthe words in L and only those words in L. - For example, the language { ab, ba, aa, bb } is regular because I can construct a DFA that accepts only those words: - All finite languages are regular, because we could (in theory) just build a control flow tree of constant size (you can visualize it as a bunch of nested if-statements that examine one digit after the other) (citation). - The empty language √ò is regular, because you can create a DFA that can‚Äôt accept anything (for example, a DFA with no final states), not even the empty string. If a DFA can‚Äôt accept any strings, then the L(M) of that DFA would be the empty set √ò, making √ò regular. - The set of all strings Œ£* is regular, because you can set up a DFA consisting of a single final state that transitions to itself for any symbol. This accepts any element from the alphabet Œ£, like this one when Œ£ = {a, b, c} and Œ£* = {œµ, a, b, c, ab, bc, abc, cba ...}: Computer Science / Software Engineering Notes Network - If L is regular, then the complement (Œ£* - L, or ~L) is always regular. - For example, let‚Äôs take the language L = {ab, ba, aa, bb} from before because we know that‚Äôs regular (therefore there must be a DFA whose L(M) is L). The alphabet that it‚Äôs from is Œ£ = {a, b}. The complement of L, ~L, will be the set of all strings from Œ£* except for the ones in L. - If we take the DFA whose L(M) is L from before and flip all the final states to non-final states and vice versa, we can create a new DFA whose L(M) is ~L (citation). - This works on any language. We‚Äôre simply getting the ‚Äúinverse‚Äù of this DFA. - If L1 and L2 are regular, then the union, L1 ‚ãÉ L2, is regular. - If we want to prove that L1 ‚ãÉ L2 is regular, we need to show a DFA exists for L1 ‚ãÉ L2. - We can use product construction for L1 and L2 , then we can modify it a bit to suit what we need. - First of all, let‚Äôs define the result of the product of L1 ‚ãÉ L2 to be M. - Now, we change the set of final states F of M to be ‚Äúat least one DFA must be on a final state to accept the string‚Äù, so we define F to be (Q1 ‚®Ø F2) ‚à™ (F1 ‚®Ø Q2), where Qx is the set of states for a DFA. - By doing that, we have now defined a DFA where L(M) is L1 ‚ãÉ L2. - If L1 and L2 are regular, then the intersection, L1 ‚à© L2, is regular. - This one‚Äôs even easier than the union one. - Basically, we use product construction for the DFAs L1 and L2. - That‚Äôs it. We don‚Äôt even need to change the set of final states. This is because, by default, the product of two DFAs require both DFAs to be on a final state for the aggregate DFA to accept the string, which is the intersection. - If L1 and L2 are regular then L1 L2 = { xy | x ‚àà L1, y ‚àà L2 } is regular. - This proof requires NFAs (nondeterministic finite automata), which are covered in more detail later, but basically it‚Äôs the same as DFA except you can have multiple transitions in NFAs, and you can take multiple paths at the same time. Think of it like two threads running in parallel, or two trains travelling on different paths in parallel. Computer Science / Software Engineering Notes Network It‚Äôs similar to a fork node in an activity diagram in UML and how it models concurrency in a system. - First, we define two DFAs for L1 and L2: - M1 = (Q1, Œ£, Œ¥1, s1, F1) - M2 = (Q2, Œ£, Œ¥2, s2, F2) - Now, we‚Äôre going to create an NFA from these two DFAs: - M3 = (Q1 ‚à™ Q2, Œ£, Œ¥1 ‚à™ Œ¥2, s1, F2) - and for each state q ‚àà F1, Œ¥(q, œµ) = s2 (what this means is, for each final state of the first DFA, make a transition that goes from that final state to the starting state of the second DFA). The transition has the name ‚Äòœµ‚Äô, which means that we can take this transition without using up any characters in the string, it‚Äôs basically a free move, but more on that in a later topic. See ‚Äòœµ-moves‚Äô). - What this NFA really means is that we start off in terms of M1, but we need to finish off in terms of M2. - For example, take the two example DFAs for a second: - If we define a new NFA, like we did above, for these two example DFAs, it‚Äôll look something like the illustration below. I‚Äôve created two illustrations of the same NFA: one without annotations, and one with annotations. The p ro p er o n e Computer Science / Software Engineering Notes Network The illustrative o n e - First of all, the top half of this NFA is basically M1. However, when we reach M1‚Äôs final state, there‚Äôs actually an epsilon move taking the NFA to its bottom half. If we don‚Äôt reach that epsilon move, we can‚Äôt move onto the bottom half of the NFA. When we reach that epsilon move, the string (up to this point) should be one of M1‚Äôs accepted strings. - Second, the bottom half of the NFA is M2. Once we‚Äôve reached the bottom half, we‚Äôve found an M1 string, now we just need an M2 string. Once we‚Äôve got an M2 string, we‚Äôll be on a final node and the string will be accepted. - By reaching the final node, we know that the input string is made up of an M1 accepted string as the first half, and an M2 accepted string as the second half. This is literally the definition of L1 L2, so we can safely say that the L(M) of this NFA is L1 L2. - This NFA should accept any concatenated string from L1 and L2. Therefore, L1 L2 is regular. Computer Science / Software Engineering Notes Network - If L is regular then L* = { x1 ... xk | k ‚àà N, xi ‚àà L } is regular. - L* is basically the set of every possible word you can make by concatenating the words of L onto themselves. - So if L had ‚Äúadd‚Äù and ‚Äúdad‚Äù, L* would have words like ‚Äúadddad‚Äù, ‚Äúdadadddad‚Äù, ‚Äúdaddaddad‚Äù etc. and it would go on infinitely. - The operator * is called ‚ÄúKleene star‚Äù, and we‚Äôve been using it already (when we write Œ£* to refer to the set of all words of that alphabet). - Yet again, we‚Äôll need NFAs to prove this. - Let‚Äôs use my ‚Äúadd dad‚Äù example above, and construct a DFA, M, where L(M) is L: - The red nodes are ‚Äúerror nodes‚Äù, where the DFA goes when we know the string will be rejected. - This accepts ‚Äúadd‚Äù and ‚Äúdad‚Äù, but we need it to accept words like ‚Äúadddad‚Äù as well. - Luckily, epsilon-moves allow us to very easily construct an NFA that does this: Computer Science / Software Engineering Notes Network - Now, when we complete the word ‚Äúadd‚Äù or ‚Äúdad‚Äù, we can move straight back to the start node and search for ‚Äúadd‚Äù or ‚Äúdad‚Äù again. Remember, epsilon moves don‚Äôt require any characters to use, so we can go straight from the end of ‚Äúadd‚Äù to the start of ‚Äúdad‚Äù, for example. - The reason why we create a new final start state that immediately goes to the old start state is because Kleene star supports the empty string (in the picture, it‚Äôs state 8) - To more generalise this proof, let‚Äôs define a general DFA: - M = (Q, Œ£, Œ¥, s‚Äô, F ‚à™ s‚Äô) - Now, we set epsilon moves branching from all the final states to the new final starting state: - ‚àÄq ‚àà F, Œ¥(q, œµ) = s‚Äô - (For all states q in the set of final states F, there is a transition function where when the NFA is in state q, and the empty epsilon move œµ is input, the state transitioned to is the new final start state s‚Äô.) - That‚Äôs all there is to this proof. Nondeterminism, subset construction and œµ-moves Nondeterminism - With a DFA, there is always a next state to go to when you input a letter. - However, what if there are cases where there isn‚Äôt always a next state to go to? What if there‚Äôs multiple states we can go to? - That‚Äôs what an NFA is (nondeterministic finite automata), it‚Äôs basically a DFA that can either branch off to multiple states, or fail if there are no states to go to. In other words, it guesses where it‚Äôs supposed to go. If the guesses are wrong, they ‚Äúdie‚Äù. Computer Science / Software Engineering Notes Network - In other words, a state no longer has |Œ£| transitions, where each transition is every letter of the automata‚Äôs alphabet. - The whole gimmick of an NFA is that we can go through different ‚Äúpaths‚Äù simultaneously. Some paths can die, some paths can survive and reach final states. We only need one path to be on a final state to accept the string. - \"It is helpful to think about this process in terms of guessing and verifying. On a given input, imagine the automaton guessing a successful computation or proof that the input is a \"yes\" instance of the decision problem, then verifying that its guess was indeed correct.\" Source:Kozen textbook - Example: - As you can see, it‚Äôs slightly different from a DFA: - There are two ‚Äòb‚Äôtransitions in state ‚Äò0‚Äô - There are no transitions in state ‚Äò1‚Äô - Let‚Äôs walk through this NFA to get a feel for how NFAs work: Step D escrip tio n Strin g so far Illustratio n 1 So far, we haven‚Äôt gone anywhere. The arrow that seems to come from nowhere indicates where we are initially, so we start at state ‚Äò0‚Äô. The smiley faces indicate different ‚Äúpaths‚Äùthat the NFA is going through. A different coloured face is a different path, and their journey is displayed on the right, for example the green path has just started on 0, so a green ‚Äò0‚Äôis shown on the right. Œµ 0 2 Let‚Äôs try inputting ‚Äòa‚Äôand see where that leads us. There‚Äôs only one transition we can go down if we input ‚Äòa‚Äô,so no new simultaneous paths are created; we just stick with our original one. The ‚Äòa‚Äôpath just goes from 0 to 0, so our green path goes from ‚Äò0‚Äôto ‚Äò0‚Äô. ùëé 0 ‚Üí 0 Computer Science / Software Engineering Notes Network 3 Let‚Äôs try inputting a ‚Äòb‚Äôand see where that leads us. There are two paths that ‚Äòb‚Äôcan take us, from 0 to 0 or from 0 to 1. Here, our green path splits into two, one red and one blue . The red one picks the path that stays on 0, and the blue path picks the one that goes to 1. Right now, there exists a path that is on a final state: the blue one. Therefore, if we left the string as just , this NFA will accept that string.ùëéùëè ùëéùëè 0 ‚Üí 0 ‚Üí 0 0 ‚Üí 0 ‚Üí 1 4 Let‚Äôs try inputting another ‚Äòb‚Äôand see where that leads us. The red and blue paths will both need to go through a ‚Äòb‚Äôtransition. Since the blue path doesn‚Äôt have a blue transition where it is, it‚Äôll‚Äòdie‚Äô. The red path needs to go down a ‚Äòb‚Äô transition, too. There are two transitions that the red path can go down, the one that goes from 0 to 0 and the one that goes from 0 to 1. Like last time, the red path splits into two different paths: a yellow path and purple path. The yellow path takes the transition from 0 to 0, therefore the yellow path is still on 0. The purple path takes the transition from 0 to 1, therefore the purple path is now on 1. The NFA should accept this string too, since the purple path is on a final state. ùëéùëèùëè 0 ‚Üí 0 ‚Üí 0 ‚Üí 0 0 ‚Üí 0 ‚Üí 0 ‚Üí 1 - Now, let‚Äôs formally construct an NFA: - ùëÄ = ( ùëÑ, Œ£, ‚àÜ, ùë†, ùêπ) - where: - is the set of all statesùëÑ - is an alphabetŒ£ - is the transition function , which basically means input a state‚àÜ ùëÑ √ó Œ£ ‚Üí 2 ùëÑ and a letter from the alphabet and get a set of all states we could be in (see ‚ÄòSubset construction‚Äô) - is the start stateùë† - is the set of final statesùêπ - Let‚Äôs formally construct the NFA as shown above: Computer Science / Software Engineering Notes Network ùëÄ = ( ùëÑ, Œ£, ‚àÜ, ùë†, ùêπ) ùëÑ = { 0 , 1 } Œ£ = { ùëé, ùëè} ‚àÜ( 0 , ùëé) = { 0 } ‚àÜ( 0 , ùëè) = { 0 , 1 } ‚àÜ( 1 , ùëé) = ‚àÖ ‚àÜ( 1 , ùëè) = ‚àÖ ùë† = 0 ùêπ = { 1 } - There is some notation that is worth noting: - When you see something like: - This means that the NFA will go from 0 to 2 if you input ‚Äòa‚Äô, and then ‚Äòb‚Äô. There should be some intermediate state, either ‚Äò0‚Äô, ‚Äò2‚Äô, or even ‚Äò1‚Äô, that you enter when you input ‚Äòa‚Äôand leave when you input ‚Äòb‚Äô. Subset construction - It‚Äôs easy to convert DFAs into NFAs, because DFAs are a subset of NFAs. - But how do you convert NFAs to DFAs? - You use subset construction. Basically, each state is a subset of states that we could‚Äôve gone to in our NFA counterpart. - For example, in our NFA, if we‚Äôre in state 0 and by inputting ‚Äòb‚Äôwe can either go to 0 or go to 1, in the DFA we‚Äôll actually go to the state {0,1} because we can go to either 0 or 1 in the NFA. - Let‚Äôs define an NFA , then let‚Äôs create a DFA which is based on :ùëÄ ùëÅ ùëÄ ùê∑ ùëÄ ùëÅ - ùëÄ ùëÅ = ( ùëÑ, Œ£, ‚àÜ, ùë†, ùêπ) - ùëÄ ùê∑ = ( ùëÑ', Œ£, Œ¥, ùë†, ùêπ') - ùëÑ' = 2 ùëÑ - Œ¥( ùëã, œÉ) = ùëû‚ààùëã ‚ãÉ ‚àÜ( ùëû, œÉ) - ùêπ' = { ùëã | ‚àÉùëì ‚àà ùêπ. ùëì ‚àà ùëã, ùëã ‚àà ùëÑ'} - This may look like an alien language to you now, but I‚Äôll go through each line and explain it in plain English, then I‚Äôll apply subset construction to the example above. - First things first, what‚Äôs going on up there? Lin e in weird maths lan guage Lin e in p lain En glish ùëÄ ùëÅ = ( ùëÑ, Œ£, ‚àÜ, ùë†, ùêπ) Here, we create an NFA with the parameters , , , and .ùëÑ Œ£ ‚àÜ ùë† ùêπ Computer Science / Software Engineering Notes Network ùëÄ ùê∑ = ( ùëÑ', Œ£, Œ¥, ùë†, ùêπ') Here, we create a DFA with the parameters , , , and . TheùëÑ' Œ£ Œ¥ ùë† ùêπ' parameters , and are all dependent on the parameters forùëÑ' Œ¥ ùêπ' the NFA .ùëÄùëÅ ùëÑ' = 2 ùëÑ is the set of all states, like . However , is the powerset ofùëÑ { 0 , 1 } 2 ùëÑ , so it‚Äôs the set of all subsets of , so for example,ùëÑ ùëÑ { ‚àÖ, { 0 } , { 1 } , { 0 , 1 } } Because of this, the states in the DFA is all the subsets of , soùëÑ you could have a state , a state or even a state .{ 0 } { 0 , 1 } ‚àÖ Œ¥( ùëã, œÉ) = ùëû‚ààùëã ‚ãÉ ‚àÜ( ùëû, œÉ) From before, we know that is a transition function that definesŒ¥ how we go from one state to the other. Therefore, the inputs must be a state and a letter. is our state input. It‚Äôs actually a set, which makes sense, becauseùëã the states in our DFA are all subsets of .ùëÑ is our letter input. Nothing strange here; it‚Äôs just a letter within theœÉ alphabet .Œ£ Don‚Äôt be too confused with the that comes after. This simply ùëû‚ààùëã ‚ãÉ means that, for each NFA state in our input , we‚Äôre going to applyùëã the NFA transition function on that state with our input letter andœÉ put the result in our state output. More formally, is a bit like the sum in maths , except ùëû‚ààùëã ‚ãÉ ùëñ=0 ùëò ‚àë ùëì( ùëò) instead of adding all the terms, it unions all the terms. Remember that the transition function also outputs a state. Since the states of our DFA are subsets of , the DFA transition functionùëÑ also outputs a subset of .Œ¥ ùëÑ For example, let‚Äôs say we input . The output will beŒ¥( { 0 , 1 } , ùëé) . I‚Äôllgo over this in more detail in our example‚àÜ( 0 , ùëé) ‚à™ ‚àÜ( 1 , ùëé) below , but the point is that this transition function just transitions all the states in and unions them all together into one big output.ùëã ùêπ' = { ùëã | ‚àÉùëì ‚àà ùêπ. ùëì ‚àà ùëã, ùëã ‚àà ùëÑ'} The set of final states is a subset of .ùêπ' ùëÑ' For a DFA state to be a final state, it needs to contain an NFA state that is in .ùêπ For example, if 0 is a non-final state and if 1 is a final state in the NFA, then in the DFA, {0} would not be a final state, but {0,1} and {1} would be final states. That‚Äôs basically what the left expression gets; a subset of whereùëÑ' all elements contain at least one final state from .ùêπ - Now that we‚Äôve got the formalities out the way, we can work on an example. Let‚Äôs convert the NFA above into a DFA. - As said above, we‚Äôll define our DFA as and our NFA asùëÄ ùê∑ = ( ùëÑ', Œ£, Œ¥, ùë†, ùêπ') , so we‚Äôll go through this step-by-step by explaining howùëÄ ùëÅ = ( { 0 , 1 } , { ùëé, ùëè} , ‚àÜ, 0 , { 1 } ) we get each parameter for the DFA :ùëÄ ùê∑ Computer Science / Software Engineering Notes Network What we‚Äôre defining How we did it ùëÑ' The value of is , so we just need to get the powerset of , or the ‚ÄòsetofùëÑ { 0 , 1 } { 0 , 1 } subsets‚Äô. This is: ùëÑ' = { ‚àÖ, { 0 } , { 1 } , { 0 , 1 } } Œ£ This is just the same as before, nothing new here: Œ£ = { ùëé, ùëè} Œ¥ First of all, let‚Äôs create a transition table. This is a table where the input letters go on the top, the states go on the left, and you can look up transition results by looking up a state and a letter: ùëé ùëè ‚àÖ { 0 } { 1 } { 0 , 1 } Now we work through this table from top to bottom. First of all, there‚Äôs the empty set state. You can‚Äôt go from any state from the empty set state; it‚Äôs practically a death state. So just input all empty set states here. ùëé ùëè ‚àÖ ‚àÖ ‚àÖ { 0 } { 1 } { 0 , 1 } Now we‚Äôre moving onto the singleton states. For and , just have a look at the{ 0 } ùëé NFA and see what states you‚Äôd end up at if you were at 0 and you took the paths labelled ‚Äòa‚Äô.As you can see, you‚Äôd just end up back at 0, so we just input there.{ 0 } As for and , you can see that you can go to 0 or 1 using a ‚Äòb‚Äôpath on 0, so we{ 0 } ùëè can input there. Continue this until we‚Äôre done with all the singleton states.{ 0 , 1 } ùëé ùëè ‚àÖ ‚àÖ ‚àÖ { 0 } { 0 } { 0 , 1 } { 1 } ‚àÖ ‚àÖ Computer Science / Software Engineering Notes Network { 0 , 1 } Now we‚Äôre faced with a state with more than one element! Remember the definition from before: we need to perform the transition function on all the elements, then union the results together . For example, on and , we need to union the{ 0 , 1 } ùëé results of doing and , and and . Just above the and cell, we can{ 0 } ùëé { 1 } ùëé { 0 , 1 } ùëé see the results of those. We just need to union those together , by which I mean, union and together . When we do that, we get , so in this transition table,{ 0 } ‚àÖ { 0 } when you input on the state , you get . Repeat this for all the states andùëé { 0 , 1 } { 0 } inputs until you finish the table. ùëé ùëè ‚àÖ ‚àÖ ‚àÖ { 0 } { 0 } { 0 , 1 } { 1 } ‚àÖ ‚àÖ { 0 , 1 } { 0 } { 0 , 1 } Once you‚Äôre done, that‚Äôs pretty much it! This transition table is your new transition function for your DFA. This video goes into more detail and I strongly suggest it if you still struggle with this. ùë† It‚Äôs pretty much the same as the original, but you encapsulate it in a set: ùë† = { 0 } ùêπ' Get all the elements of :ùëÑ' { , , , }‚àÖ { 0 } { 1 } { 0 , 1 } Now get rid of the ones that do not have final states in them: { , , , }‚àÖ { 0 } { 1 } { 0 , 1 } So therefore, your new is:ùêπ' { , }ùêπ' = { 1 } { 0 , 1 } œµ-moves - An epsilon-move (œµ-move) is a type of transition that you can use without needing to ‚Äúspend‚Äù or ‚Äúconsume‚Äù any symbols. - It‚Äôs basically a free move. - An NFA that uses epsilon-moves are called œµNFAs. - They‚Äôre formally defined like this: - ùëÄ œµ = ( ùëÑ, Œ£, Œ∏, ùë†, ùêπ) - where - Œ∏: ùëÑ √ó ( Œ£ + { œµ} ) ‚Üí 2 ùëÑ - This is basically the same as an NFA, except transitions now support epsilon-moves. Computer Science / Software Engineering Notes Network - Here is an example of an œµNFA: - From the starting state, you can go to the left-most state and the right-most final state, all without consuming any symbols. - You can also convert œµNFAs to NFAs. Don‚Äôt worry! It‚Äôs not as long as subset construction. - You only need to edit the transition function and the set of final states. - With an œµNFA we can create an NFA like so:ùëÄ œµ ùëÄ ùëÅ - ùëÄ œµ = ( ùëÑ, Œ£, Œ∏, ùë†, ùêπ) - ùëÄ ùëÅ = ( ùëÑ, Œ£, ‚àÜ, ùë†, ùêπ') - ‚àÜ( ùëû, œÉ) = - ùêπ' = - Your next line will be ‚ÄúIs this going to be translated into plain English again?‚Äù - Please see below for a translation into plain English. Lin e in weird maths lan guage Lin e in p lain En glish ùëÄ œµ = ( ùëÑ, Œ£, Œ∏, ùë†, ùêπ) We‚Äôre just defining an œµNFA with these parameters. ùëÄ ùëÅ = ( ùëÑ, Œ£, ‚àÜ, ùë†, ùêπ') We‚Äôre just defining an NFA with these parameters. These parameters will be based off of the parameters for .ùëÄœµ ‚àÜ( ùëû, œÉ) = When you input a state and a symbol, the output will be all the possible states it can reach using epsilon-moves and that symbol. ùêπ' = The new set of final states is a superset of the old set of final states, meaning we still keep the final states the same, but we add more. We add the states that can epsilon-move towards a final state. - Now I‚Äôll go over an example, by converting that œµNFA above into an NFA: Computer Science / Software Engineering Notes Network What we‚Äôre defining How we did it ‚àÜ First, let‚Äôs create that transition table again. Just for example‚Äôs sake, I‚Äômcalling the initial state 0, the left-most state 1 and the final state 2: ùëé ùëè 0 1 2 If you were at state 0 and had an input ‚Äòa‚Äô,what states could you get to? Well, you could go down the left epsilon-move to get to state 1 and spend the ‚Äòa‚Äôon going back to state 1. That‚Äôs pretty much it, so here, we‚Äôd input just state 1. If you were at state 0 and had an input ‚Äòb‚Äô,what states could you get to? You could go down the left epsilon-move and use ‚Äòb‚Äôto go to state 1 or use your ‚Äòb‚Äôto get to state 2. If you went down the right epsilon-move, you wouldn‚Äôt be able to use ‚Äòb‚Äô,so you can ignore it. Seems like you can get to states 1 and 2, so we put that in the transition table. We keep going like this until we fill out the transition table: ùëé ùëè 0 { 1 } { 1 , 2 } 1 { 1 } { 1 , 2 } 2 ‚àÖ ‚àÖ This transition table is our new transition function! ùêπ' For this one, you could look at the final states in the graph, and work your way back up the epsilon-moves, looking for non-final states that can epsilon-move to the final state. As you can see in the graph above, if you start at state 2 (the final state) and work your way up the epsilon-move, you‚Äôllfind yourself at state 0. Therefore, we can make state 0 a final state. However , you cannot go up to state 1 from state 2, so state 1 cannot be a new final state. Obviously, we keep the old final states from the œµNFA: ùêπ' = { 0 , 2 } Regular expressions and Kleene‚Äôs theorem Defining regular expressions - A string s matches a regular expression wheneverŒ± ùë† ‚àà ùêø( Œ±) - Regular expressions can be defined using atomic and compound patterns Computer Science / Software Engineering Notes Network Atomic patterns - There exist the following atomic patterns, which do not need to be broken down further: Pattern Matched by ‚Ä¶ ùêø( œÉ) = { œÉ} ‚Ä¶ the single symbol from the alphabet:œÉ Œ£ ùêø( Œµ) = { Œµ} ‚Ä¶ the empty string ùêø( ‚äò) = { } ‚Ä¶ nothing ùêø( #) = Œ£ ‚Ä¶ any single symbol from the alphabet Œ£ ùêø( @) = ùêø( #* ) = Œ£* ‚Ä¶ any string formed by the symbols in (including the emptyŒ£ string), i.e. any string in Œ£* Compound patterns - Compound patterns are defined recursively, based on the atomic patterns. Pattern A Strin g will match if ... ùêø( Œ± + Œ≤) = ùêø( Œ±) ‚à™ ùêø( Œ≤ ‚Ä¶ it matches orŒ± Œ≤ ùêø( Œ± ‚à© Œ≤) = ùêø( Œ±) ‚à© ùêø( Œ≤ ‚Ä¶ it matches both andŒ± Œ≤ ùêø( Œ±Œ≤) = ùêø( Œ±) ùêø( Œ≤) ‚Ä¶ it can be broken down into two parts such that the first part matches and the second part matchesŒ± Œ≤ ùêø( ‚àº Œ±) =‚àº ùêø( Œ±) ‚Ä¶ it does not match Œ± ùêø( Œ±* ) = ùêø( Œ±) * ‚Ä¶ it matches 0 or more repetitions of .Œ± ùêø( Œ±+ ) = ùêø( Œ±) + ‚Ä¶ it matches 1 or more repetitions of .Œ± Examples - Œ£ = { ùëé, ùëè, ùëñ, ùë°, ùë£} All strings that end in ‚Äúvita‚Äù: or more elegant:( ùëé + ùëè + ùëñ + ùë° + ùë£) * ùë£ùëñùë°ùëé @ùë£ùëñùë°ùëé - Œ£ = { ùëé, ùëè} All strings with an even number of a‚Äôs:ùëè * ( ùëéùëè * ùëéùëè * ) * - Œ£ = { ùëé, ùëè} All strings with an odd number of a‚Äôs:ùëè * ( ùëéùëè * ùëéùëè * ) * ùëéùëè * Kleene‚Äôs theorem - If is a regular expression then is a regular language.Œ± ùêø( Œ±) Computer Science / Software Engineering Notes Network - All strings that match a regular expression form a language. This language is regular. - If L is a regular language then for some regular expression .ùêø = ùêø( Œ±) Œ± - If a language is regular, then there exists a regular expression that matches all strings in that language (and not more/less). - Therefore, we can conclude that finite automata and regular expressions describe the same languages;they are equally powerful. - In order to prove this theorem, we need to show that we can convert a regular expression to a finite automaton and vice versa. Reg exp to ŒµNFA - We will convert a regular expression to a ŒµùëÅùêπùê¥ - Basically, we‚Äôre going to split our regular expression into ‚Äúbuilding blocks‚Äù, then we‚Äôre going to convert those ‚Äúbuilding blocks‚Äù into automata individually. - With each regex ‚Äúbuilding block‚Äù, we need to show that we can build an automata out of it. In other words, for each possible regex ‚Äúbuilding block‚Äù, we need to show that it‚Äôs language is regular. - Once we‚Äôve shown that all our building blocks are regular, we can use said building blocks to build an automata out of any regex expression. - We can prove we can convert by induction, as regular expressions are built inductively. - This means that we can build any regular expression by combining our atomic patterns, which results in a compound pattern. Think of the atomic patterns as our basic building blocks: - First we check if our basic building blocks are regular. - Then we assume that the blocks we use to build compound patterns are regular. - Then we check if the compound patterns are regular. - If they are regular we have completed the proof. - Let‚Äôs start with checking the base cases, these are our basic building blocks, represented by atomic regular expressions: - is regular:ùêø( œÉ) - is regular:ùêø( Œµ) Computer Science / Software Engineering Notes Network - is regular:ùêø( ‚äò) - These are all atomic regular expressions we have to check, as # and @ are redundant, meaning that they can also be represented by compound patterns. - Now, assume that the building blocks we use to build compound patterns are regular. Then we will check if the compound patterns are regular: - ùêø( Œ± + Œ≤) = ùêø( Œ±) ‚à™ ùêø( Œ≤) - We have already proved above that the union of two regular languages is regular. - ùêø( Œ±Œ≤) = ùêø( Œ±) ùêø( Œ≤) - It was also proved above that the concatenation of two languages are regular. - ùêø( Œ±* ) = ùêø( Œ±) * - Again, we have proved above that kleene star is regular. - These are all compound regular expressions we have to check as all other compound regular expressions are redundant, meaning that they can also be represented by other compound patterns. - Now we have completed the proof that from any regular expression we can construct an automaton. ŒµNFA to reg exp - First of all, let‚Äôs simply state what we want to do. We want to prove that there is always a way to convert an ŒµNFA to a regular expression. - We will construct an NFA ùëÄ = ( ùëÑ, Œ£, ‚àÜ, ùë†, ùêπ) - is the set of statesùëÑ - is the alphabetŒ£ - is the transition function‚àÜ - is the start stateùë† - is the set of final statesùêπ - This is what we want:the regular expression which describes all possible pathsŒ±ùë¢,ùë£ ùëã - starting at the state u - ending at the state v - passing through 0 or more intermediary states, which are in the set X. - It‚Äôs important to note that we do not need to pass through any intermediate states in X, but we have the opportunity to pass through as many as we want. Computer Science / Software Engineering Notes Network - If we can define the regex mathematically, then we‚Äôve shown that we canŒ±ùë¢,ùë£ ùëã convert an ŒµNFA to a regex, thereby finishing our proof. - We shall prove this by induction! In case you‚Äôve forgotten, proof by induction goes like this: 1. Base case 2. Inductive step - Yes, there will be some weird maths language, but don‚Äôt worry;I‚Äôll translate it for you. It sounds scary at first, but once you see the proof, it‚Äôs not that bad: Step Weird maths lan guage No rmal En glish + p retty p ictures Base case Let ùëé 1 , ùëé 2 , ùëé 3 ... be all symbols such that Œ¥( ùë¢, ùëé ùëñ) = ùë£ for 1 ‚â§ ùëñ ‚â§ ùëò 1 . ùëñùëì ùë¢ ‚â† ùë£ ùëéùëõùëë ùëò > 0 Œ± ùë¢,ùë£ √ò = ùëé 1 + ùëé 2 + ùëé 3 + ...{ } 2 . ùëñùëì ùë¢ ‚â† ùë£ ùëéùëõùëë ùëò = 0 Œ± ùë¢,ùë£ √ò = √ò 3 . ùëñùëì ùë¢ = ùë£ ùëéùëõùëë ùëò > 0 Œ± ùë¢,ùë£ √ò = Œµ + ùëé 1 + ùëé 2 + ... + Œµ{ } 4 . ùëñùëì ùë¢ = ùë£ ùëéùëõùëë ùëò = 0 Œ± ùë¢,ùë£ √ò = Œµ{ } Firstly, our base case. The simplest case is going from the initial state to the final state without going through any intermediate states. This is what we‚Äôre defining on the left here; from top to bottom, we‚Äôre defining 1. If the initial state isn‚Äôtthe same as the final state and there are transitions from initial state to final state 2. If the initial state isn‚Äôtthe same as the final state and there are no transitions from initial state to final state 3. If the initial state is the final state and there are transitions from the initial state to the final state 4. If the initial state is the final state and there are no transitions from the initial state to the final state All those symbols are allùëé1 , ùëé2 , ùëé3 ... transitions that go straight from the initial state to the final state. Inductive step Œ± ùë¢,ùë£ ùëã+ { ùëû} = Œ± ùë¢,ùë£ ùëã + Œ± ùë¢,ùëû ùëã ( Œ± ùëû,ùëû ùëã ) * Œ± ùëû,ùë£ ùëã First, we have a proposition (assumption). We propose that exists and works.Œ± ùë¢,ùë£ ùëã Then, we define a out of .Œ± ùë¢,ùë£ ùëã+ { ùëû} Œ± ùë¢,ùë£ ùëã Once we do that, we‚Äôve defined our inductive step. By doing this, we show that if there exists a regex from u to v through intermediate states X, there also exists a regex from u to v with Computer Science / Software Engineering Notes Network intermediate states X + {q}, where ‚Äòq‚Äôis any other state in the automata. This means we can keep adding on states from our base case until we‚Äôve filled inŒ± ùë¢,ùë£ √ò all the states in our automata. - As you can see from the proof, we can just keep adding on new states to our . Thatùëã means we can add our initial state and final state to this regular expression, and then append all the intermediate states onto and it‚Äôll work.ùëã - That‚Äôs great, but how do you actually convert an ŒµNFA to a regular expression? We‚Äôve proved that we can do it, so how do we actually do it? - Below you‚Äôll see an example of how to actually convert an ŒµNFA into a regular expression. It involves breaking down the regex you need by taking out intermediate states, until you get something trivial, then working your way back up again. - EXAMPLE: - Given the following NFA - We need to find a regular expression that starts at state A, ends at state C and passes through any of A,B,C zero or more times. - Therefore, we are looking for Œ±ùê¥,ùê∂ { ùê¥,ùêµ,ùê∂} - The starting state u is going to be A - The ending state v is going to be C - The set of states which we can pass through X is equal to Q - Now, we are going to rewrite this regular expression using the formula above - We are going to pull out one of the states from X - It is best to choose a state that reduces the paths we can go a lot - I‚Äôm going to pull out B. This gives: Œ± ùê¥,ùê∂ { ùê¥,ùêµ,ùê∂} = Œ± ùê¥,ùê∂ { ùê¥,ùê∂} + { ùêµ} =Œ± ùê¥,ùê∂ { ùê¥,ùê∂} + Œ± ùê¥,ùêµ { ùê¥,ùê∂} ( Œ± ùêµ,ùêµ { ùê¥,ùê∂} ) * Œ± ùêµ,ùê∂ { ùê¥,ùê∂} Computer Science / Software Engineering Notes Network - We can decompose this further into Œ±ùê¥,ùê∂ { ùê¥,ùê∂} = Œ±ùê¥,ùê∂ { ùê¥} + { ùê∂} = Œ±ùê¥,ùê∂ { ùê¥} + Œ±ùê¥,ùê∂ { ùê¥} ( Œ±ùê∂,ùê∂ { ùê¥} ) * Œ±ùê∂,ùê∂ { ùê¥} Œ±ùê¥,ùêµ { ùê¥,ùê∂} = Œ±ùê¥,ùêµ { ùê∂} + { ùê¥} = Œ±ùê¥,ùêµ { ùê∂} + Œ±ùê¥,ùê¥ { ùê∂} ( Œ±ùê¥,ùê¥ { ùê∂} ) * Œ±ùê¥,ùêµ { ùê∂} Œ±ùêµ,ùê∂ { ùê¥,ùê∂} = Œ±ùêµ,ùê∂ { ùê¥} + { ùê∂} = Œ±ùêµ,ùê∂ { ùê¥} + Œ±ùêµ,ùê∂ { ùê¥} ( Œ±ùê∂,ùê∂ { ùê¥} ) * Œ±ùê∂,ùê∂ { ùê¥} - It is up to you how far you decompose. - If you are able to see what the regular expression is right away, you don‚Äôt need to decompose. However, if you barely decompose, the chances that you miss a path are high. - We could decompose what we have got now even further, but I don‚Äôt think that it is necessary to do so as the regular expressions for these are fairly easy to find. - Let‚Äôs take a look at the first decomposed regular expression: b + b(a+b)*(a+b) = b(a+b)*Œ±ùê¥,ùê∂ { ùê¥,ùê∂} = - Any string that starts with b or that starts with b followed by one or more mixed a‚Äôs and/or b‚Äôs will be matched. This can be simplified into a string starting with b followed by zero or more mixed a‚Äôs and/or b‚Äôs. - Let‚Äôs take a look at the second decomposed regular expression: a + Œµ(Œµ)*a = a + a = aŒ±ùê¥,ùêµ { ùê¥,ùê∂} = - Any string that contains exactly one a will be matched. - Let‚Äôs take a look at the third decomposed regular expression: a + a(a+b)*(a+b) = a(a+b)*Œ±ùêµ,ùê∂ { ùê¥,ùê∂} = - This is very similar to the first one. It will match a string starting with a followed by zero or more mixed a‚Äôs and/or b‚Äôs. - As you might have noticed, I didn‚Äôt decompose the blue part. The reason for that is that the blue regular expression starts and ends in the same state, meaning that it can only take transitions to the state itself (if exists): - bŒ± ùêµ,ùêµ { ùê¥,ùê∂} = - Any string that contains exactly one b will be matched. - Now, let‚Äôs put together the regular expressions from the coloured parts: Computer Science / Software Engineering Notes Network - b(a+b)* + ab*a(a+b)*Œ± ùê¥,ùê∂ { ùê¥,ùêµ,ùê∂} = - This is the regular expression that is represented by this NFA - we are done! - Often, there is more than one regular expression that is represented by an automaton, meaning that there is no single correct solution. For example, the regular expression (ab*a + b)(a + b)* is correct as well. Limitations of regular languages - Is every language regular? No! - For example, look at the language { ùëé ùëõ ùëè ùëõ | ùëõ ‚àà ‚Ñï} - Our automaton has finitely many states. - It‚Äôs going to scan the string from the left to the right, starting with the a‚Äôs. - Then, when it‚Äôs going to scan the b‚Äôs, it has to remember how many a‚Äôs there were previously. - Since n can be infinitely big, there is no way to do this with our finite number of states! - We are going to prove by contradiction that the language is not{ ùëé ùëõ ùëè ùëõ | ùëõ ‚àà ‚Ñï} regular. - Suppose we have an automaton that accepts this language. Since theùëÄ number of states it has is finite, we are going to say that it has states.ùëò - Next, we are going to choose such that . We can always find an thatùëõ ùëõ > ùëò ùëõ is greater than because is not bounded, i.e. can be infinitely large.ùëò ùëõ - Now, our automaton is going to start to scan the ‚Äôs from the left to the right.ùëõ ùëé Since we have less states than the number of a‚Äôs, there must be a state we are going to enter at least twice (pigeonhole principle)! We are going to call this state . Between the first time we enter and the second time we enterùëû ùëû ùëû we are going to scan ‚Äôs. After the second time we entered our automatonùëô ùëé ùëû is going to continue to the final state. - When the automaton enters state for the first time, it goes on a path thatùëû leads it to again. Then, after arriving at for the second time, it goes on aùëû ùëû path that leads it to the final state. - Here is the problem:Why arrive at , and then take a path that leads toùëû ùëû again? Why not take the path that goes to the final state upon arriving at forùëû the first time? This means that our automaton would accept a string with Computer Science / Software Engineering Notes Network number of ‚Äôs. However, now the number of ‚Äôs is not anymore equal toùëõ ‚àí ùëô ùëé ùëé the number of ‚Äôs and here we have our contradiction!ùëè Pumping (üéÉ) Lemma for regular languages - contrapositive form - We can use the contrapositive form of the pumping lemma for regular languages to show that a language is not regular. We cannot use the pumping lemma to show that a language is regular! - It works by splitting up the language into parts, then ‚Äúpumping‚Äù a subpart until you get a string that isn‚Äôt in the language. This is similar to what we have just done before. - The different steps of the proof can be understood as a game versus a demon. 1. The demon chooses a number such that .ùëò ùëò > 0 - We cannot choose a value for k, we only know that it is greater than 0. 2. We choose a string such that .ùë•ùë¶ùëß ‚àà ùêø ùë¶| |‚â• ùëò - We can choose any string that is within the language. However, we haveùë•ùë¶ùëß to make sure that, no matter what k is, our string is always in theùë•ùë¶ùëß language. We do not need to cover the whole language with our string! - and can be empty, there is no restriction concerning them.ùë• ùëß - The length of the part must be at least . A way to make sure that this isùë¶ ùëò always the case is to let the part be equal to something to the power of .ùë¶ ùëò - due to the lower bound of k.|ùë¶| Ôπ•0 - As a general tip, try to make as trivial as possible, like in the followingùë¶ example: - For instance, we could let to make sure that is at least long ( is aùë¶ = ùëé ùëò ùë¶ ùëò ùëé symbol from the alphabet). 3. The demon splits the part of the string into such that , i.e. Theùë¶ ùë¢ùë£ùë§ ùë£| | > 0 ùë£ ‚â† Œµ. whole string would be .ùë•( ùë¢ùë£ùë§) ùëß - You cannot choose how the string is going to be split! All you know is that the part of the string is not going to be empty.ùë£ - Therefore, you have to do a general case and define such that every wayùë¢ùë£ùë§ of splitting the string is possible and we do not introduce any restrictions. - and can be empty, there is no restriction concerning them.ùë¢ ùë§ - For instance, if , then and because v cannot beùë¶ = ùëé ùëò ùë£ = ùëé ùëô 1 ‚â§ ùëô ‚â§ ùëò empty. Furthermore, the remaining part . If we add the two parts,ùë¢ùë§ =ùëé ùëò‚àí ùëô we are going to get back to . Also, we haven‚Äôt made any assumptionsùë¶ = ùëé ùëò about how the string is going to be split. 4. We pick an such that the string If this is the case we have provenùëñ ‚â• 0 ùë•ùë¢ùë£ ùëñ ùë§ùëß ‚àâ ùêø. that the language is not regular! - We can pick any we want as long as it is equal to or greater than 0.ùëñ Computer Science / Software Engineering Notes Network - Our goal is to choose an such that the resulting string is outside of theùëñ language. - For instance, and . If we now choose , we are goingùë£ = ùëé ùëô ùë¢ùë§ =ùëé ùëò‚àí ùëô ùëñ = 0 to get . We have now removed ‚Äôs compared to what we hadùë¢ùë£ 0 ùë§ = ùëé ùëò‚àí ùëô ùëô ùëé as in the step before, which was . Also we know that ,ùë¢ùë£ùë§ ùë¢ùë£ùë§ = ùë¶ =ùëé ùëò 1 ‚â§ ùëô meaning that we removed at least one !ùëé 5. You MUST say ‚ÄúTherefore L is not regular‚Äù, if you don‚Äôt, you will lose marks. - If this still doesn‚Äôt make any sense, look at a few examples below, and then read the general case above again. Examp le D escrip tio n { ùëé ùëõ ùëè ùëõ | ùëõ ‚àà ‚Ñï} 1. The demon chooses such thatùëò ùëò > 0 2. Now choose a string and .ùë•ùë¶ùëß ‚àà ùêø ùë¶| |‚â• ùëò - I‚Äôll do it like , so and( Œµ) ( ùëé ùëò ) ( ùëè ùëò ) ùë• = Œµ, ùë¶ = ùëé ùëò , ùëß = ùëè ùëò .ùë•ùë¶ùëß ‚àà ùêø - For every value of I will get a specific string which isùëò in the language of .ùëé ùëõ ùëè ùëõ - It is ok that I cannot get the empty string ( which isùëé 0 ùëè 0 in the language) because I do not need to cover the whole language. 3. The demon splits your into a such thatùë¶ ùë¢ùë£ùë§ ùë£ ‚â† Œµ. - Now, we have to do the splitting in a general case. - Since cannot be empty, then and .ùë£ ùë£ = ùëé ùëô 1 ‚â§ ùëô ‚â§ ùëò - Since , then .ùë¢ùë£ùë§ = ùë¶ =ùëé ùëò ùë¢ùë§ =ùëé ùëò‚àí ùëô 4. We pick an such that the stringùëñ ‚â• 0 ùë•ùë¢ùë£ ùëñ ùë§ùëß ‚àâ ùêø. - Now for this example, choose ùëñ = 0 . - Then as the number of b‚Äôs will beùë•ùë¢ùë£ 0 ùë§ùëß = ùëé ùëò‚àí ùëô ùëè ùëò ‚àâ ùêø bigger than the number of a‚Äôs, no matter what value k is. 5. Therefore L is not regular { ùëé ùëõ! | ùëõ ‚àà ‚Ñï} 1. The demon chooses such thatùëò ùëò > 0 2. Now choose a string and .ùë•ùë¶ùëß ‚àà ùêø ùë¶| |‚â• ùëò - I‚Äôm going to choose , soùë• = ùëé ( ùëò+ 1 ) !‚àí ùëò , ùë¶ = ùëé ùëò , ùëß = Œµ ùë•ùë¶ùëß = ( ùëé ( ùëò+ 1 ) !‚àí ùëò ) ( ùëé ùëò ) ( Œµ) = ùëé ( ùëò+ 1 ) ! ‚àà ùêø. 3. The demon splits your into a such thatùë¶ ùë¢ùë£ùë§ ùë£ ‚â† Œµ. - , as it cannot be empty we have .ùë£ = ùëé ùëô 1 ‚â§ ùëô ‚â§ ùëò - The remaining part becauseùë¢ùë§ = ùëé ùëò‚àí ùëô ùë¢ùë£ùë§ = ùë¶ = ùëé ùëò Computer Science / Software Engineering Notes Network 4. We pick an such that the stringùëñ ‚â• 0 ùë•ùë¢ùë£ ùëñ ùë§ùëß ‚àâ ùêø. - We pick ùëñ = 2 . - Then ùë•ùë¢ùë£ 2 ùë§ùëß = ùëé ( ùëò+ 1 ) !‚àí ùëò ùëé ùëò‚àí ùëô ùëé 2 ùëô = ùëé ( ùëò+ 1 ) !+ ùëô =‚àâ ùêø because the power we have got here is not going to be a factorial! - Let me prove why this is not going to be a factorial: - is going to be some factorial .( ùëò + 1 ) ! ‚â• 2 ! - The next higher factorial is going to be .( ùëò + 2 ) ! - However, our power is going to be( ùëò + 1 ) ! + ùëô in the middle of these two factorials: Therefore,( ùëò + 1 ) ! < ( ùëò + 1 ) ! + ùëô < ( ùëò + 2 ) !. it cannot be a factorial! - If you still have some doubts, try it out with the smallest k we could have, . Then chooseùëò = 1 the largest l we can choose, . So we haveùëô = 1 which holds. For any choice of2 ! < 2 ! + 1 < 3 ! the next higher factorial is going to growùëò > 1 even faster, therefore this will always hold. 5. Therefore L is not regular { ùëé ùëõ | ùëõ ùëñùë† ùëùùëüùëñùëöùëí} 1. The demon chooses such thatùëò ùëò > 0 2. Now choose a string and .ùë•ùë¶ùëß ‚àà ùêø ùë¶| |‚â• ùëò - I‚Äôm going to choose where isùë• = Œµ, ùë¶ = ùëé ùëù , ùëß = Œµ ùëù going to be the next prime number . Since the‚â• ùëò number of primes is infinite this will always work, no matter how large is.ùëò - Therefore, ùë•ùë¶ùëß = ùëé ùëù ‚àà ùêø. 3. The demon splits your into a such thatùë¶ ùë¢ùë£ùë§ ùë£ ‚â† Œµ. - The length of is going to be , soùë¢ùë£ùë§ ùëù |ùë¢ùë£ùë§| = ùëù. - Since we haveùë• = ùëß = Œµ |ùë•ùë¢ùë£ùë§ùëß| = ùëù. - That‚Äôs all info we need to continue our proof, you will see why in the next step. 4. We pick an such that the stringùëñ ‚â• 0 ùë•ùë¢ùë£ ùëñ ùë§ùëß ‚àâ ùêø. - We will pick ùëñ = ùëù + 1 . - I‚Äôm going to show that the length of is notùë•ùë¢ùë£ ùëù+ 1 ùë§ùëß going to be equal to a prime number, therefore it is outside of the language. - |ùë•ùë¢ùë£ ùëñ ùë§ùëß| = |ùë•ùë¢ùë£ ùëù+ 1 ùë§ùëß| = |ùë•ùë¢ùë£ 1 ùë§ùëß| + |ùë£ ùëù | = ùëù + |ùë£ ùëù | = , which is not going to be a prime= ùëù * ( 1 + |ùë£|) number since we also have a factor here but( 1 + |ùë£|) prime numbers should only be divisible by 1 or itself (p). - Therefore, ùë•ùë¢ùë£ ùëù+ 1 ùë§ùëß ‚àâ ùêø. Computer Science / Software Engineering Notes Network 5. Therefore L is not regular { ùëöùëö ùëÖ | ùëö ‚àà Œ£ * , ùëö ùëÖ ùëñùë† ùëñùë°ùë† ùëüùëíùë£ùëíùëüùë†ùëí} and |Œ£| ‚â• 2 1. The demon chooses such thatùëò ùëò > 0 2. Now choose a string and .ùë•ùë¶ùëß ‚àà ùêø ùë¶| |‚â• ùëò - I‚Äôm going to choose whereùë• = Œµ, ùë¶ = ùëí ùëò , ùëß = ùëëùëëùëí ùëò andùëë, ùëí ‚àà Œ£ ùëë ‚â† ùëí - ùë•ùë¶ùëß = ùëí ùëò ùëëùëëùëí ùëò ‚àà ùêø - The demon splits your into a such thatùë¶ ùë¢ùë£ùë§ ùë£ ‚â† Œµ. - ùë£ = ùëí ùëô - ùë¢ùë§ = ùëí ùëò‚àí ùëô - 1 ‚â§ ùëô ‚â§ ùëò 4. We pick an such that the stringùëñ ‚â• 0 ùë•ùë¢ùë£ ùëñ ùë§ùëß ‚àâ ùêø. - Pick ùëñ = 0 - Now and because weùë•ùë¢ùë£ 0 ùë§ùëß = ùëí ùëö ùëëùëëùëí ùëò ùëö ‚â† ùëò deleted at least one by letting .ùëí ùëñ = 0 - Therefore ùë•ùë¢ùë£ 0 ùë§ùëß ‚àâ ùêø 5. Therefore L is not regular Automata theory:Context free languages Pushdown Automata (PDA) - Pushdown automata are an extension to the automata we have seen before. - We will take an and add a stack to the control unit.ŒµùëÅùêπùê¥ - The stack does not have a size limit, i.e. is infinitely big. - More formally, a PDA is a 7 tuple ùëÄ = ( ùëÑ, Œ£, Œì, Œ¥, ùë†, ‚ä•, ùêπ) - is the set of statesùëÑ - is the input alphabetŒ£ - is the stack alphabet (the set of things we can put on the stack)Œì - is the transition relation (more detail see below)Œ¥ - is the start stateùë† ‚àà ùëÑ - is the initial stack symbol‚ä• - is the set of final statesùêπ ‚äÜ ùëÑ Transition relation - Now, let‚Äôs take a closer look at the transition relation :Œ¥ Œ¥ ‚äÜ ( ùëÑ√ó ( Œ£ ‚à™ { Œµ} ) √óŒì) √ó ( ùëÑ√óŒì * ) - is the state the PDA is currently in.ùëÑ Computer Science / Software Engineering Notes Network - is the symbol we are currently reading. This symbol could be anyŒ£ ‚à™ { Œµ} symbol from our alphabet or epsilon, which means that we can do epsilon moves by reading nothing! - is the symbol which is currently on top of the stack. When we make aŒì transition we are going to pop (remove) this symbol from the top of the stack. - is the resulting state after we have made the transition.ùëÑ - is going to be 0 or more symbols from our stack alphabet that we are goingŒì * to push on the stack when we make the transition. - Let‚Äôs look at how one tuple of our transition relation looks like: Œ¥ ‚àã ( ( ùëû,œÉ,Œ≥) , ( ùëû ' ,Œ≥ 1 Œ≥ 2 ... Œ≥ ùëò) ) Here, we are in the state , we will read the symbol , and we see on top of theùëû œÉ Œ≥ stack. We will then pop (remove) off the stack, go to the next state and pushŒ≥ ùëû ' (add) on the stack. We will start pushing with and end with , such thatŒ≥ 1 Œ≥ 2 ... Œ≥ ùëò Œ≥ ùëò Œ≥ 1 we now have on top of the stack.Œ≥ 1 - Keep in mind that if is not on the top of the stack, we cannot perform this transition.Œ≥ Think of it as like a ‚Äúsecond input‚Äù. - Graphically, the transition looks like this: Configuration - A configuration is a complete description of our PDA at a certain point in time. It is represented as an element of: Configurations ‚äÜ ( ùëÑ√óŒ£ * √óŒì * ) - is the current state.ùëÑ - is the whole part of the input we still have left to scan/read. Note that thisŒ£ * is not only the next symbol. - is the whole stack content. Note that this is not only the symbol on top ofŒì * the stack;it‚Äôs the entire thing. - Therefore, every configuration will be of the form Configurations ‚àã ( ùëû,œÉ 1 œÉ 2 ... œÉ ùëò,Œ≥ 1 Œ≥ 2 ... Œ≥ ùëò ‚ä•) Computer Science / Software Engineering Notes Network - We can define relations between those configurations, which tell us how to go from one configuration to the next configuration. We have to distinguish between two cases:The case when we consume a symbol from the input, and the case where we don‚Äôt consume any symbol and take an epsilon move. - Case 1:We consume a symbol. We write the relation as: ( ùëû,œÉùë†,Œ≥ùëî) ‚Üí( ùëû ' ,ùë†,‚Ñéùëî) when there exists such an element in Œ¥ ( ( ùëû,œÉ,Œ≥) , ( ùëû ' ,‚Ñé) ) ‚àà Œ¥ - Case 2:We don‚Äôt consume a symbol and take an epsilon move. We write the relation as: ( ùëû,ùë†,Œ≥ùëî) ‚Üí( ùëû ' ,ùë†,‚Ñéùëî) when there exists such an element in Œ¥ ( ( ùëû,Œµ,Œ≥) , ( ùëû ' ,‚Ñé) ) ‚àà Œ¥ Acceptance - A PDA can accept a string either by empty stack or by final state. - We can turn a PDA that accepts by final state into a PDA that accepts by empty stack and vice versa. By final state - A PDA will accept a string by final state if we can go from the start configuration to a final configuration which contains a final state and where we don‚Äôt have any string left to scan/consume. Between those two configurations there can be 0 or more other intermediary configurations which we pass through. - Formally, this is written as: ( ùë†,ùë•,‚ä•) ‚áí( ùëì,Œµ,ùëî) - We will start at state s with the whole input string x still remaining to scan, and our stack contains the initial stack symbol only. - We will go through as many intermediary states as we want to. - We will end in a state f where we don‚Äôt have anything remaining to scan, and our stack content is g. - Therefore, the language accepted by the PDA is ùêø( ùëÄ) = { ùë• | ‚àÉùëì‚àà ùêπ . ( ùë†,ùë•,‚ä•) ‚áí( ùëì,Œµ,ùëî) } By empty stack - A PDA will accept a string by empty stack if we can go from the start configuration to a final configuration where the stack is completely empty and where we don‚Äôt have any string left to scan/consume. Between those two configurations there can be 0 or Computer Science / Software Engineering Notes Network more other intermediary configurations which we pass through. - Formally, this is written as: ( ùë†,ùë•,‚ä•) ‚áí( ùëû,Œµ,Œµ) - We will start at state s with the whole input string x still remaining to scan, and our stack contains the initial stack symbol only. - We will go through as many intermediary states as we want to. - We will end in a state q where we don‚Äôt have anything remaining to scan, and our stack is empty. - ‚ÄúStack is empty‚Äù means that we do n o t have or any other symbol on the‚ä• stack - Therefore, the language accepted by the PDA is ùêø( ùëÄ) = { ùë• | ‚àÉùëû‚àà ùëÑ . ( ùë†,ùë•,‚ä•) ‚áí( ùëû,Œµ,Œµ) } Example PDA accepting palindromes - A Palindrome is a string where the reverse of that string is equal to the original string. - Examples:abba, abdba, aaaa - A PDA that will accept all palindromes by final state (and also empty stack) looks like this: where , i.e. is any symbol from our alphabet .œÉ ‚àà Œ£ œÉ Œ£ - Let‚Äôs start from scratch and build a PDA that looks like this. - We are going to differentiate between palindromes with an even number of symbols and those with an odd number of symbols - Our strategy for constructing the PDA that accepts palindromes with an even number of symbols will be the following: - We scan the word until we reach the middle of it. - Then we scan the second half of the word, expecting the symbols from the first half of the word in reverse order. - If this is the case, our word is a palindrome. - Now, we can assign a state for every step of our strategy Computer Science / Software Engineering Notes Network - We will be in state 1 when we scan the first half of the word. - We will be in state 2 when we scan the second half of the word. - We will be in the final state when we have finished scanning the whole word and the reverse of the first half is equal to the second half of the word. - Let‚Äôs think about our transitions for each of our states: - When we are in state 1 - We will stay in state 1 and keep adding the current symbol to the stack if we haven‚Äôt reached the middle of the word. - We will make a transition to state 2 when we have reached the middle of the word, without changing the stack. - When we are in state 2 - We will stay in state 2 and keep popping the current symbol from the stack as long as the current symbol is equal to the symbol at the top of the stack. - We will make a transition to the final state if our stack contains only the initial stack symbol, and remove the initial stack symbol. - However, there is still one problem:Palindromes with an odd number of symbols, such as ‚Äúabdba‚Äù. How to deal with them? We can throw away the symbol in the middle! For this example, it means that we throw away ‚Äúd‚Äù and we will check the remaining string ‚Äúabba‚Äù. We have already defined a PDA for checking palindromes with an even number of symbols above. - In order to integrate the ‚Äúthrow away the middle symbol‚Äù action into our existing PDA we will add one transition from state 1 to 2 where we consume a symbol but don‚Äôt change the stack contents. - Some questions you might ask yourself are: - How does the PDA know when it has reached the middle of the word? - How does the PDA know that it has arrived at the middle symbol of an odd string, which can be thrown away? - The answer is that the PDA is going to guess. The PDA can do this because it is non-deterministic, similar to NFAs we have seen before. In other words, the PDA can take any of the transitions that are possible. - If we have a palindrome as a string and we process this palindrome, there will be one combination of transitions where the PDA will go into the final state at the end. - Let‚Äôs simulate our PDA on the string ‚Äúabcba‚Äù, which is a palindrome: ( 0 ,ùëéùëèùëêùëèùëé, ‚ä•) ‚Üí( 0 , ùëèùëêùëèùëé, ùëé ‚ä•) ‚Üí( 0 , ùëêùëèùëé,ùëèùëé ‚ä•) ‚Üí( 1 , ùëèùëé,ùëèùëé ‚ä•) ‚Üí( 1 , ùëé, ùëé ‚ä•) ‚Üí( 1 , Œµ, ‚ä•) Computer Science / Software Engineering Notes Network ‚Üí( 2 , Œµ, Œµ) The PDA has reached state 2 and will therefore accept. - Let‚Äôs simulate our PDA on the string ‚Äúabcde‚Äù, which is not a palindrome: ( 0 ,ùëéùëèùëêùëëùëí, ‚ä•) ‚Üí( 0 , ùëèùëêùëëùëí, ùëé ‚ä•) ‚Üí( 0 , ùëêùëëùëí,ùëèùëé ‚ä•) ‚Üí( 1 , ùëëùëí,ùëèùëé ‚ä•) X at this point our computation dies because there is no transition we could take (d‚Üí ‚â† b). Therefore the PDA will reject. Context free grammars - A CFG, consisting of terminal and non-terminal symbols, is used to generate strings (sentences) by following its production rules. - The terminal symbols are the symbols which will form the string we are going to generate. - The non-terminal symbols are going to be replaced by other symbols. These other symbols can be terminals, non-terminals or a mix of both. - There exist so called ‚Äúproductions‚Äù which tell us how to replace the non-terminal symbols. - We have to keep replacing non-terminal symbols until we arrive at a string that consists solely of terminal symbols. This process is called ‚Äúderivation‚Äù. - The final string is also called a sentence. - Formally, a CFG is a quadruple ( ùëÅ, Œ£, ùëÉ, ùëÜ) - is a finite set of nonterminal symbolsùëÅ - is a finite set of terminal symbolsŒ£ - are the productionsùëÉ ‚äÜ ùëÅ √ó ( ùëÅ + Œ£) * - is the start nonterminalùëÜ ‚àà ùëÅ - To define production rules ‚Ä¶ - we will use the shorthand ùê¥ ‚Üí Œ± to mean ( ùê¥, Œ±) ‚àà ùëÉ - we will use the shorthand ùê¥ ‚Üí Œ± 1 |Œ± 2 |... |Œ± ùëò to mean ùê¥ ‚Üí Œ± 1 , ùê¥ ‚Üí Œ± 2 ,..., ùê¥ ‚Üí Œ± ùëò - To express that is derivable from we will write orŒ≤ Œ± Œ± ‚áí Œ≤ - Without :This means that given the string , we have applied someùëò Œ± production rules and arrived at string Œ≤. - With :This means that given the string , we have applied exactlyùëò Œ± ùëò production rules and arrived at string Œ≤. - The language generated by a CFG G is the set of all its sentences, i.e. the set of all strings that can be generated by using its production rules. Computer Science / Software Engineering Notes Network - ùêø( ùê∫) = { ùë• ‚àà Œ£ * | ùëÜ ‚áí ùë•} - The language generated is going to be equal to the set of all strings x that are derivable from the start non-terminal. - We can apply as many production rules as we want, as long as we end with a string (sentence) that solely consists of terminals. - This language L(G), generated by some CFG G, is called context-free (CFL). - If it‚Äôs all still a bit too confusing for you, look at the table below, where we convert context-free languages into context-free grammars: Lan guage C o n vertin g it to a grammar { ùëé ùëõ ùëè ùëõ | ùëõ ‚àà ‚Ñï} - Every string with the same number of a‚Äôs followed by the same number of b‚Äôs will be in the language. - We have shown that this language is not regular, however, it is context free as we can come up with a CFG for it. - The CFG is ùëÜ ‚Üí ùëéùëÜùëè | Œµ - We can produce 0 a‚Äôs and b‚Äôs, i.e. the empty string, by applying only the second production rule: ùëÜ ‚áí Œµ - We can produce 1 a and 1 b by applying the first production rule once and the second production rule last: ùëÜ ‚áí ùëéùëÜùëè ‚áí ùëéùëè - We can produce 2 a‚Äôs and 2 b‚Äôs by applying the first production rule 2 times and the second production rule last: ùëÜ ‚áí ùëéùëÜùëè ‚áí ùëéùëéùëÜùëèùëè‚áí ùëéùëéùëèùëè - Therefore, we can produce a‚Äôs and b‚Äôs by applyingùëõ ùëõ the first production rule times and the secondùëõ production rule last. - We achieve this through pumping in the middle ofùëéùëÜùëè the string every time we want to add an and a .ùëé ùëè { ùëé ùëõ ùëè ùëõ | ùëõ > 0 } - ùëÜ ‚Üí ùëéùëÜùëè | ùëéùëè { ùëé ùëõ ùëè ùëö ùëê 2 ùëõ | ùëõ, ùëö > 0 } - ùëÜ ‚Üí ùëéùëÜùëêùëê | ùëéùêµùëêùëê - ùêµ ‚Üí ùëèùêµ | ùëè { ùëé ùëõ ùëè ùëö ùëê 2 ùëõ | ùëõ, ùëö ‚â• 0 } - ùëÜ ‚Üí ùëéùëÜùëêùëê | ùêµ - ùêµ ‚Üí ùëèùêµ | Œµ L(G) is the set of all palindromes over the alphabet Œ£ = { ùëé, ùëè, ùëê} - ùëÜ ‚Üí ùëéùëÜùëé | ùëèùëÜùëè | ùëêùëÜùëê | ùëé | ùëè | ùëê | Œµ Computer Science / Software Engineering Notes Network L(G) is the set of all balanced parentheses - ùëÜ ‚Üí ( ùëÜ) | ( ) | ùëÜùëÜ { ùë¶ùëè 2 ùëõ ùë• | ùëõ ‚â• 0 , ùë¶, ùë• ‚àà { ùëé} * , |ùë¶ùë•| = ùëõ} En glish, p lease So you have a bunch of ‚Äòa‚Äôs, then a bunch of ‚Äòb‚Äôs, then another bunch of ‚Äòa‚Äôs. There needs to be twice as many ‚Äòb‚Äôs as ‚Äòa‚Äôs. Examples: Œµ abb abbbb a bbbb aa - Simplify: ùêø( ùê∫) = { ùëé ùëò ùëè 2 ( ùëò+ ùëë) ùëé ùëë | ùëò + ùëë ‚â• 0 } - We know that and are just going to beùë¶ ùë• repetitions of the letter ùëé. - We let , then we can use those for theùëõ = ùëò + ùëë number of times we repeat the first and the lastùëé . We put and in the correspondingùëé ùëò ùëë exponents to denote these repetitions. - Simplify further: ùêø( ùê∫) = { ùëé ùëò ùëè 2 ùëò ùëè 2 ùëë ùëé ùëë | ùëò ‚â• 0 , ùëë ‚â• 0 } - We use and to denote repetitions of theùëò ùëë letters, so they can‚Äôt be negative. For example, what would mean? It doesn‚Äôt make sense,ùëé ‚àí 1 as we can‚Äôt repeat the letter minus one times.ùëé - We split into . No magic here,ùëè 2 ( ùëò+ ùëë) ùëè 2 ùëò ùëè 2 ùëë just exponent rules. - We can now split this into two grammars which we will then concatenate, because CFL are closed under concatenation. - One will be for the first half:{ ùëé ùëò ùëè 2 ùëò | ùëò ‚â• 0 } - ùêø ‚Üí ùëéùêøùëèùëè | Œµ - One will be for the second half:{ ùëè 2 ùëë ùëé ùëë | ùëë ‚â• 0 } - ùëÖ ‚Üí ùëèùëèùëÖùëé | Œµ - Now, the final grammar will be the concatenation of the grammar for the left and the right part: - ùëÜ ‚Üí ùêøùëÖ - ùêø ‚Üí ùëéùêøùëèùëè | Œµ - ùëÖ ‚Üí ùëèùëèùëÖùëé | Œµ Chomsky Normal Form - A CFG is in Chomsky normal form (CNF) when all productions are of the form - ùê¥ ‚Üí ùêµùê∂ Two non-terminals are derivable by one non-terminal - ùê¥ ‚Üí Œ± One terminal is derivable by one non-terminal - Note that we don‚Äôt have here, therefore we cannot generate the empty string.Œµ - Chomsky normal form is harder to convert into a PDA, but it‚Äôs used in things like the CYK algorithm which parses context-free grammars. Computer Science / Software Engineering Notes Network Lan guage C FG in C ho msky No rmal Fo rm ùêø( ùê∫) = { ùëé ùëõ ùëè ùëõ | ùëõ > 0 } - ùëÜ ‚Üí ùëãùêµ | ùê¥ùêµ - ùê¥ ‚Üí ùëé - ùêµ ‚Üí ùëè - ùëã ‚Üí ùê¥ùëÜ ùêø( ùê∫) = { ùëé ùëõ ùëè ùëö ùëê 2 ùëõ | ùëõ, ùëö > - ùëÜ ‚Üí ùëãùê∂' | ùëåùê∂' - ùëã ‚Üí ùê¥ùëÜ - ùëå ‚Üí ùê¥ùêµ' - ùê¥ ‚Üí ùëé - ùêµ' ‚Üí ùêµ'ùêµ | ùëè - ùêµ ‚Üí ùëè - ùê∂' ‚Üí ùê∂ùê∂ - ùê∂ ‚Üí ùëê Greibach Normal Form - A CFG is in Greibach normal form (GNF) when all productions are of the form - whereùê¥ ‚Üí Œ±ùêµ 1 ùêµ 2 ...ùêµ ùëò ùëò ‚â• 0 One terminal followed by non-terminals is derivable by one non-terminalùëò - Note that we don‚Äôt have here, therefore we cannot generate the empty string.Œµ - Greibach normal form makes it easier to show that there is a PDA for every CFG, and can also be used with recursive descent parsers. Lan guage C FG in Greibach No rmal Fo rm ùêø( ùê∫) = { ùëé ùëõ ùëè ùëõ | ùëõ > 0 } - ùëÜ ‚Üí ùëéùëÜùêµ | ùëéùêµ - ùêµ ‚Üí ùëè ùêø( ùê∫) = { ùëé ùëõ ùëè ùëö ùëê 2 ùëõ | ùëõ, ùëö > 0 - ùëÜ ‚Üí ùëéùëÜùê∂' | ùëéùêµùê∂' - ùêµ ‚Üí ùëèùêµ | ùëè - ùê∂' ‚Üí ùëêùê∂ - ùê∂ ‚Üí ùëê Removing epsilon and unit productions - A production of the form is called an epsilon productionùê¥ ‚Üí Œµ - Assume we have another production ùêµ ‚Üí Œ±ùê¥Œ≤ - We can get rid of the epsilon production and refine this production - Our new refined and only production will be ùêµ ‚Üí Œ±Œ≤ Video with example: Simplification of CFG (Removal of Null Productions) - A production of the form is is a called a unit productionùê¥ ‚Üí ùêµ Computer Science / Software Engineering Notes Network - Assume we have another production ùêµ ‚Üí Œ± - We can get rid of this production and refine the unit production - Our new refined and only production will be (Instead of A B , weùê¥ ‚Üí Œ± ‚Üí ‚Üí Œ± are removing the step in the middle) Helpful video with example: Simplification of CFG (Removal of Unit Productions) - Since we can remove both epsilon and unit productions, we can conclude that for every CFG there exists another CFG that accepts the same language, except that it cannot accept epsilon: ùêø( ùê∫ ' ) = ùêø( ùê∫) ‚àí { Œµ} Where is the grammar but without any epsilon or unit productionsùê∫ ' ùê∫ Removing left-recursive productions - This is o n ly req uired fo r co n versio n to GNF an d therefo re n o t examin able - A left-recursive production looks like the following: ùê¥ ‚Üí ùê¥Œ± | Œ≤ - This rule generates a string starting with exactly one and ending with one or moreŒ≤ Œ± - It is left recursive because when we want to generate more , we are going toŒ± prepend them to the string, i.e. we are going to add them on the left side of the string. - In other words, we are generating the string from the right to the left, starting with the rightmost (last) symbol. - Every left recursive rule must have the part because it allows us to break out of| Œ≤ our recursion, i.e. it allows us to end ‚Äúspamming‚Äù , by replacing the non-terminalŒ± ùê¥ with at some point in our derivation.Œ≤ - We want to eliminate the left recursion in ùê¥ ‚Üí ùê¥Œ± | Œ≤ - We know this rule produces whereŒ≤Œ± ùëõ ùëõ ‚â• 1 - We can easily create with this new rule:Œ± ùëõ - ùê∑ ‚Üí Œ±ùê∑ | Œ± - Now, we need to add another rule to produce the in front:Œ≤ - ùê∂ ‚Üí Œ≤ùê∑ - So in total we need these two rules to eliminate the left-recursion: - ùê∂ ‚Üí Œ≤ùê∑ - ùê∑ ‚Üí Œ±ùê∑ | Œ± - In general, we can have multiple alternatives that are left-recursive, and multiple alternatives to break out of our left-recursion. We have to get rid of all of them. - Our left-recursive production is in the form ùê¥ ‚Üí ùê¥Œ± 1 | ùê¥Œ± 2 | ... | ùê¥Œ± ùëò | Œ≤ 1 | Œ≤ 2 | ... | Œ≤ ùëô - For every alpha, we need the following new rule: - ùê∑ ‚Üí Œ± ùëòùê∑ | Œ± ùëò Computer Science / Software Engineering Notes Network - For every beta, we need the following new rule: - ùê∂ ‚Üí Œ≤ ùëôùê∑ - So all in all, we need the following rules for every alpha, beta: - ùê∂ ‚Üí Œ≤ ùëôùê∑ - ùê∑ ‚Üí Œ± ùëòùê∑ | Œ± ùëò - What? You still don‚Äôt understand? - No, don‚Äôt feel bad! Have a look at a few examples below, they might help: With left-recursio n Witho ut left-recursio n ùê¥ ‚Üí ùê¥Œ± | Œ≤ ùê¥ ‚Üí Œ≤ùê¥' ùê¥' ‚Üí Œ±ùê¥' | Œ± ùê∏ ‚Üí ùê∏ + ùëá | ùëá ùê∏ ‚Üí ùëáùê∏' ùê∏' ‚Üí + ùëáùê∏' | + ùëá ùê¥ ‚Üí ùê¥ùêµŒ± | ùê¥ùëé | ùëé ùê¥ ‚Üí ùëéùê¥' ùê¥' ‚Üí ùêµŒ±ùê¥' | ùëéùê¥' | ùêµŒ± | Œ± ùê¥ ‚Üí ùê¥ùê∂ | ùê¥ùëéùëë | ùëèùëê | ùê∂ ùê¥ ‚Üí ùëèùëêùê¥' | ùê∂ùê¥' ùê¥' ‚Üí ùê∂ùê¥' | ùëéùëëùê¥' | ùê∂ | ùëéùëë - You don‚Äôt get it? Yare yare daze... it‚Äôs alright. There are just some topics that are really hard to master. We won‚Äôt judge. - What better last-resort revision technique to fall back on than Indian YouTubers? - For this topic, I recommend this one. Sure, he leaves his answers with epsilon productions, but all the examples above are from this video and it‚Äôs really easy to follow. Converting between CFG, CNF and GNF - For any context-free grammar, there exists a corresponding CNF and GNF that produces the same language, except epsilon. Converting a CFG to CNF 1. Remove all epsilon and unit productions like described above 2. For all add a new nonterminal to our set of non-terminalsœÉ ‚àà Œ£ ùëÅ œÉ ùëÅ - We will now have a new non-terminal symbol for each of our symbols in the alphabet - We will use these later when we define some new productions Computer Science / Software Engineering Notes Network 3. In all productions, replace any terminal with the the non-terminalœÉ ùëÅ œÉ - We will replace all terminal symbols in every production by the new non-terminal symbols we have generated in the step before 4. Add productions to our set of productionsùëÅ œÉ ‚Üí œÉ ùëÉ - We will need those productions to produce the terminals, since we replaced all of them with our new non-terminals.ùëÅ œÉ 5. While there exists a production ... with , i.e. while thereùê¥ ‚Üí ùêµ 1 ùêµ 2 ùêµ ùëò ùëò > 2 exists a production that derives more than 2 non-terminals and therefore cannot be in CNF - Remove this production from ùëÉ - Add a new non-terminal toùê∂ ùëÅ - It has to have a different name in every iteration of this ‚Äúwhile-loop‚Äù - Add the following two productions to ùëÉ - ùê¥ ‚Üí ùêµ 1 ùê∂ - ùê∂ ‚Üí ùêµ 2 ... ùêµ ùëò - Now our grammar is in CNF. - If this is a little hard to take in, try following through the example below: Step Pro gress D escrip tio n 0 ùëÜ ‚Üí ùê¥ùëÜùêµ ùê¥ ‚Üí ùëéùê¥ùëÜ | ùëé | Œµ ùêµ ‚Üí ùëÜùëèùëÜ | ùê¥ | ùëèùëè We haven‚Äôt done anything yet, I just wanted to show you the grammar first before we start converting it. It‚Äôs on the left. 1 Remove ùê¥ ‚Üí Œµ ùëÜ ‚Üí ùê¥ùëÜùêµ | ùëÜùêµ ùê¥ ‚Üí ùëéùê¥ùëÜ | ùëé | ùëéùëÜ ùêµ ‚Üí ùëÜùëèùëÜ | ùê¥ | ùëèùëè | Œµ Remove ùêµ ‚Üí Œµ ùëÜ ‚Üí ùê¥ùëÜùêµ | ùëÜùêµ | ùê¥ùëÜ | ùëÜ ùê¥ ‚Üí ùëéùê¥ùëÜ | ùëé | ùëéùëÜ ùêµ ‚Üí ùëÜùëèùëÜ | ùê¥ | ùëèùëè Remove ùêµ ‚Üí ùê¥ ùëÜ ‚Üí ùê¥ùëÜùêµ | ùëÜùêµ | ùê¥ùëÜ | ùëÜ ùê¥ ‚Üí ùëéùê¥ùëÜ | ùëé | ùëéùëÜ ùêµ ‚Üí ùëÜùëèùëÜ | ùëéùê¥ùëÜ | ùëé | ùëéùëÜ | ùëèùëè Remove ùëÜ ‚Üí ùëÜ ùëÜ ‚Üí ùê¥ùëÜùêµ | ùëÜùêµ | ùê¥ùëÜ ùê¥ ‚Üí ùëéùê¥ùëÜ | ùëé | ùëéùëÜ In this step, we‚Äôre simply removing the -productionsŒµ and the unit productions, as detailed in the previous section. First, we remove the -production in A, but then it shiftsŒµ it to B. So then, we remove the -production in B. We‚Äôve gottenŒµ rid of all the -productions, but now we‚Äôve got to get ridŒµ of all the unit productions. We get rid of the unit productions in B and S. For the one in B, we just replace it with A‚Äôs contents, and for the one in S, we just remove it, because is trivial.ùëÜ ‚Üí ùëÜ Computer Science / Software Engineering Notes Network ùêµ ‚Üí ùëÜùëèùëÜ | ùëéùê¥ùëÜ | ùëé | ùëéùëÜ | ùëèùëè 2 ùëé => ùê¥ 0 ùëè => ùêµ 0 In this step, we create a non-terminal for every terminal that exists. I call these and .ùê¥0 ùêµ0 3 ùëÜ ‚Üí ùê¥ùëÜùêµ | ùëÜùêµ | ùê¥ùëÜ ùê¥ ‚Üí ùê¥ 0 ùê¥ùëÜ | ùê¥ 0 | ùê¥ 0 ùëÜ ùêµ ‚Üí ùëÜùêµ 0 ùëÜ | ùê¥ 0 ùê¥ùëÜ | ùê¥ 0 | ùê¥ 0 ùëÜ | ùêµ 0 ùêµ 0 In this step, I convert all terminals into their respective non-terminals that I‚Äôvedefined in the last step. At first, this doesn‚Äôt make much sense, until the next step... 4 ùê¥ 0 ‚Üí ùëé ùêµ 0 ‚Üí ùëè In this step, I set up productions such that the non-terminals can produce their respective terminals. Now the previous step makes sense! 5 ùëÜ ‚Üí ùê¥ùëÜùêµ ùëÜ ‚Üí ùê¥ ùëã 0 ùëã 0 ‚Üí ùëÜùêµ ùê¥ ‚Üí ùê¥ 0 ùê¥ùëÜ ùê¥ ‚Üí ùê¥ 0 ùëã 1 ùëã 1 ‚Üí ùê¥ùëÜ ùêµ ‚Üí ùëÜùêµ 0 ùëÜ ùêµ ‚Üí ùëÜùëã 2 ùëã 2 ‚Üí ùêµ 0 ùëÜ ùêµ ‚Üí ùê¥ 0 ùê¥ùëÜ ùêµ ‚Üí ùê¥ 0 ùëã 3 ùëã 3 ‚Üí ùê¥ùëÜ In this step, I split up productions that have more than 2 non-terminals. I create non-terminals called so I don‚Äôtùëãùëõ run out of names and so that I know that any non-terminal called is just used for shortening.ùëã Every red highlighted production is a production I need to shorten, and the blue highlighted production underneath is the shortened version. Finish ùëÜ ‚Üí ùê¥ùëã 0 | ùëÜùêµ | ùê¥ùëÜ ùê¥ ‚Üí ùê¥ 0 ùëã 1 | ùê¥ 0 ùëÜ | ùëé ùêµ ‚Üí ùëÜùëã 2 | ùê¥ 0 ùëã 3 | ùê¥ 0 ùëÜ | ùêµ 0 ùêµ 0 | ùëé ùëã 0 ‚Üí ùëÜùêµ ùëã 1 ‚Üí ùê¥ùëÜ ùëã 2 ‚Üí ùêµ 0 ùëÜ ùëã 3 ‚Üí ùê¥ùëÜ ùê¥ 0 ‚Üí ùëé ùêµ 0 ‚Üí ùëè This isn‚Äôtreally a step. I‚Äôvejust compiled all the productions and put them into one place, so you can see the finished CNF result! This grammar accepts the same language as the one at the start, except now it‚Äôs in a different form: Chomsky Normal Form. Computer Science / Software Engineering Notes Network Converting a CFG to GNF This is n o t examin able acco rdin g to Gen n aro , but still wo rth readin g to give further in sight in to co n text-free grammars. 1. Convert the CFG into CNF. 2. Re-order the rules such that the start rule is at the top, the next derivable rules are below and so on. In other words it should be the case that for every possible derivation we are going down in the list of rules we have, but never up. - This will not always be possible, but try to order them as much as possible according to this schema. - You can‚Äôt do anything wrong here, the purpose of this ordering is to minimise the amount of work you will have to do. 3. Replace all non-terminals with non-terminals of the form ùê¥ 1 , ùê¥ 2 ,..., ùê¥ ùëò where is equal to the number of all non-terminals. Start with the first rule atùëò the top and work down, otherwise we cannot benefit from the ordering we did in the last step. 4. Check if for every production , it is true that Check the rulesùê¥ ùëò ‚Üí ùê¥ ùëóùëã ùëò < ùëó. in ascending order, i.e. start with the rule where . If we find one ruleùëò = 0 where this does not hold, we must modify this rule immediately before we continue to check other rules. We have to deal with the following two cases: - inùëò > ùëó ùê¥ ùëò ‚Üí ùê¥ ùëóùëã - Replace with whatever produces, i.e. deriveùê¥ ùëó ùê¥ ùëó ùê¥ ùëó - If for the resulting rule still , keep replacing until this is notùëò > ùëó the case anymore. - (left-recursive rule), soùëò = ùëó ùê¥ ùëò ‚Üí ùê¥ ùëòùëã - Eliminate left recursion according to description above. 5. Now, we are taking a closer look at every production starting with a non-terminal, i.e. every production which is not in GNF yet. For all of those rules it must hold that where . Starting with the rule whereùê¥ ùëò ‚Üí ùê¥ ùëóùëã ùëò < ùëó the highest number and working in descending order, derive Theùëò = ùê¥ ùëó. result of deriving will be either a terminal symbol or two non-terminalùê¥ ùëó symbols: - If we get another non-terminal, repeat this step with the current rule, i.e. derive the left-most non-terminal again, check again, and so on. Computer Science / Software Engineering Notes Network - If we get a terminal symbol, our production must be in GNF, meaning that it starts with a terminal followed by some non-terminals. This means that this rule is OK, we can leave it as it is and continue to the next rule. 6. Rename all non-terminals back to their old names. 7. There might exist some rules which are unreachable from the start symbol. Remove those rules. - Now, our grammar is in GNF. Congrats if you are not confused at this point. - If you need to visualise this problem (or if you‚Äôre masochistic), an example of this is provided below: Step Pro gress D escrip tio n 0 ùëÜ ‚Üí ùê¥ùëè ùê¥ ‚Üí ùëéùëÜ | ùëé Here, we haven‚Äôt done anything yet! This is the grammar we want to convert to GNF. Right now, it‚Äôs not in any normal form. 1 ùëÜ ‚Üí ùê¥ùêµ ùê¥' ‚Üí ùëé ùê¥ ‚Üí ùê¥'ùëÜ | ùê¥' ùêµ ‚Üí ùëè In this step, we convert the grammar into CNF using the method described above that you should have read. 2 ùëÜ ‚Üí ùê¥ùêµ ùê¥ ‚Üí ùê¥'ùëÜ | ùê¥' ùê¥' ‚Üí ùëé ùêµ ‚Üí ùëè In this step, we reorder the steps so that, when going through productions, you go from the top and work your way down; you don‚Äôt go back up. Sometimes, this isn‚Äôtalways completely possible, for example the production uses , which isùê¥ ‚Üí ùê¥'ùëÜ | ùê¥' ùëÜ further up. 3 ùê¥ 1 ‚Üí ùê¥ 2 ùê¥ 4 ùê¥ 2 ‚Üí ùê¥ 3 ùê¥ 1 | ùê¥ 3 ùê¥ 3 ‚Üí ùëé ùê¥ 4 ‚Üí ùëè In this step, we replace all non-terminals with , whereùê¥ùëò is the position of the non-terminal from the top to theùëò bottom. 4 ùê¥ 1 ‚Üí ùê¥ 2 ùê¥ 4 ùê¥ 2 ‚Üí ùê¥ 1 | ùê¥ 3 ùê¥ 3 ‚Üí ùëé ùê¥ 4 ‚Üí ùëè ---------------------------- ùê¥ 1 ‚Üí ùê¥ 2 ùê¥ 4 ùê¥ 2 ‚Üí ùê¥ 2 ùê¥ 4 | ùê¥ 3 ùê¥ 3 ‚Üí ùëé ùê¥ 4 ‚Üí ùëè In this step, we look for any productions whereùê¥ùëò ‚Üí ùê¥ùëóùëã .ùëò > ùëó There doesn‚Äôt actually exist any productions in the example where this is true, so I‚Äôvecreated a sub-example to demonstrate this step. This won‚Äôt affect the example we‚Äôre working on. That‚Äôs why the text looks like that. In the first block, we notice the production where this condition is true. So weùê¥ 2 ‚Üí ùê¥ 1 | ùê¥ 3 replace in that production with its derivation.ùê¥1 Next, we notice that, in the production Computer Science / Software Engineering Notes Network ---------------------------- ùê¥ 1 ‚Üí ùê¥ 2 ùê¥ 4 ùê¥ 2 ‚Üí ùê¥ 3 ùê¥ 5 ùê¥ 3 ‚Üí ùëé ùê¥ 4 ‚Üí ùëè ùê¥ 5 ‚Üí ùê¥ 4 ùê¥ 5 | ùê¥ 4 ---------------------------- ùê¥ 1 ‚Üí ùê¥ 2 ùê¥ 4 ùê¥ 2 ‚Üí ùê¥ 5 ùê¥ 4 | ùê¥ 3 ùê¥ 3 ‚Üí ùëé ùê¥ 4 ‚Üí ùëè ùê¥ 5 ‚Üí ùëè | ùëé , , which means that we haveùê¥ 2 ‚Üí ùê¥ 2 ùê¥ 4 | ùê¥ 3 ùëò = ùëó left recursion. Therefore, we introduce another non-terminal to rectify this called .ùê¥5 Finally, on the last block, we notice that inùëò > ùëó . Therefore, we convert bothùê¥ 5 ‚Üí ùê¥ 4 | ùê¥ 3 non-terminals into their derivations, which happen to be single terminals. With this, we‚Äôve completed this step. 5 ùê¥ 1 ‚Üí ùê¥ 2 ùê¥ 4 ùê¥ 2 ‚Üí ùê¥ 3 ùê¥ 1 | ùê¥ 3 ùê¥ 3 ‚Üí ùëé ùê¥ 4 ‚Üí ùëè ---------------------------- ùê¥ 1 ‚Üí ùê¥ 2 ùê¥ 4 ùê¥ 2 ‚Üí ùëéùê¥ 1 | ùê¥ 3 ùê¥ 3 ‚Üí ùëé ùê¥ 4 ‚Üí ùëè ---------------------------- ùê¥ 1 ‚Üí ùê¥ 2 ùê¥ 4 ùê¥ 2 ‚Üí ùëéùê¥ 1 | ùëé ùê¥ 3 ‚Üí ùëé ùê¥ 4 ‚Üí ùëè ---------------------------- ùê¥ 1 ‚Üí ùëéùê¥ 1 ùê¥ 4 | ùëéùê¥ 4 ùê¥ 2 ‚Üí ùëéùê¥ 1 | ùëé ùê¥ 3 ‚Üí ùëé ùê¥ 4 ‚Üí ùëè In this step, we look at all the productions that are not in GNF, and we substitute productions until all the productions are in GNF. We start with the highest rule (which is the furthest down in our list) and work in descending order . For example, in the first block, is not inùê¥ 2 ‚Üí ùê¥ 3 ùê¥ 1 GNF. So we substitute ‚Äôs production into it, making theùê¥3 first part ‚Äòa‚Äô. Next, is not in GNF, so we substitute theùê¥ 2 ‚Üí ùê¥ 3 same thing in that, and we get .ùê¥2 ‚Üí ùëé After that, the only production that is not in GNF is . So we substitute into that one, and weùê¥ 1 ‚Üí ùê¥ 2 ùê¥ 4 ùê¥2 get .ùê¥ 1 ‚Üí ùëéùê¥ 1 ùê¥ 4 | ùëéùê¥ 4 There are no longer any more productions that are not in GNF. We‚Äôre now in Greibach normal form! But we‚Äôre not done yet; our non-terminal symbols are all . Weùê¥ùëò need to change them back. 6 ùëÜ ‚Üí ùëéùëÜùêµ | ùëéùêµ ùê¥ ‚Üí ùëéùëÜ | ùëé ùê¥' ‚Üí ùëé ùêµ ‚Üí ùëè In this step, we‚Äôve just renamed our non-terminal symbols back to normal. 7 ùëÜ ‚Üí ùëéùëÜùêµ | ùëéùêµ ùêµ ‚Üí ùëè In this step, we‚Äôre just getting rid of any productions that are unreachable / unused. Computer Science / Software Engineering Notes Network In this example, the productions for and are neverùê¥ ùê¥' used, so they are deleted. PDA and CFG conversions - PDAs and CFG have the same power, therefore we can convert a PDA to a CFG and vice versa. CFG to PDA - We will do this by first converting a CFG into GNF, and then converting GNF into a one state PDA. - Assume that our Grammar is in GNF. Then all productions will look like: whereùê¥ ‚Üí Œ±ùêµ 1 ùêµ 2 ...ùêµ ùëò ùëò ‚â• 0 One terminal followed by non-terminals is derivable by one non-terminalùëò - The PDA we are going to construct will only have one state and will accept by empty stack. - We are going to call the one and only state .* - Formally, this means that the PDA will accept the string when there exists aùë• derivation: ( *,ùë•,‚ä•) ‚áí( *,Œµ,Œµ) - Therefore, the PDA we will construct is going to be of the form: ùëÄ = ( { *} , Œ£, ùëÅ, Œ¥, *, ùëÜ, ‚äò) rep resen tin g is defin ed as because { *} set of states a singleton set containing the state * we will only have a single state in this PDA Œ£ input alphabet terminal symbols of CFG these are the symbols, produced by the grammar, which our PDA is going to scan ùëÅ stack alphabet non-terminal symbols of CFG this is what we will push on/pop off the stack Œ¥ transition relation see below see below * start state the state * we only have a single state, so we don‚Äôt have much choice where to Computer Science / Software Engineering Notes Network start. S initial stack symbol the start production of CFG we won‚Äôt have anything on the stack when we start scanning our string ‚äò final states empty set our PDA will accept by empty stack, therefore we don‚Äôt need any final states. - Now, we still need to define the transition relation. - We are going to add an element to the relation for every production we have in our grammar. - Therefore, for each , add a transition:ùê¥‚ÜíœÉùêµ 1 ùêµ 2 ... ùêµ ùëò - Formally: ( ( *,œÉ,ùê¥) , ( *,ùêµ 1 ùêµ 2 ... ùêµ ùëò) ) - Graphically: - Example for the grammar of the language ùêø( ùê∫) = { ùëé ùëõ ùëè ùëõ | ùëõ > 0 } - ùëÜ‚ÜíùëéùëÜùêµ | ùëéùêµ - ùêµ‚Üíùëè - The resulting PDA will have - A set of states { *} - The input alphabet { ùëé, ùëè} - The stack alphabet { ùëÜ, ùêµ} - The start state * - The initial stack symbol ùëÜ - The transition relation as shown in the following graphic: Computer Science / Software Engineering Notes Network - If we want to test if our PDA accepts the same language as our grammar, we can try to match every derivation of our grammar with a transition in our PDA - We will do this by giving the leftmost derivation, which means that productions are only applied to the leftmost non-terminal in every step. Grammar derivatio n s PD A tran sitio n s ùëÜ ( *,ùëéùëéùëèùëè, ùëÜ) ‚áí ùëéùëÜùêµ ‚Üí( *, ùëéùëèùëè,ùëÜùêµ) ‚áí ùëéùëéùêµùêµ ‚Üí( *, ùëèùëè,ùêµùêµ) ‚áí ùëéùëéùëèùêµ ‚Üí( *, ùëè, ùêµ) ‚áí ùëéùëéùëèùëè ‚Üí ( *, Œµ, Œµ) PDA to CFG - This proof is pretty much just the previous proof, but in reverse! - The steps we will go through are as follows: 1. Prove that one-state PDAs can be converted to a CFG 2. Prove that any PDA can be converted to a one-state PDA - As you can see, the law of transitivity show that by doing this, we will prove that any PDA can be converted into a CFG. 1. First, we will prove that one-state PDAs can be converted to a CFG. - The obvious thing to do first is to start off with a PDA: - ( { ùëû} , Œ£, Œì, Œ¥, ùëû, ‚ä•, ‚àÖ) - Now we‚Äôre going to create a grammar (in GNF) like this: - ùê∫ = ( Œì, Œ£, ùëÉ, ‚ä•) - ‚àÄ ( ( ùëû, ùëê, ùê¥) , ( ùëû, ùêµ 1 . . . ùêµ ùëò) ) ‚àà Œ¥, ùê¥ ‚Üí ùëêùêµ 1 . . . ùêµ ùëò ‚àà ùëÉ - This is just the previous proof in reverse, so if you understood that, you‚Äôll get this. - If you don‚Äôt, I‚Äôll translate that maths language above for you: Lin e in weird maths lan guage Lin e in p lain En glish ( { ùëû} , Œ£, Œì, Œ¥, ùëû, ‚ä•, ‚àÖ) This one‚Äôs nice and simple;I‚Äôm just defining a PDA with only one state, .ùëû is the alphabet that the PDA acceptsŒ£ is the set of symbols accepted onto the stackŒì is the transition functionŒ¥ is the initial stack symbol‚ä• Where it says just means that there is no final state;‚àÖ Computer Science / Software Engineering Notes Network this PDA will accept by empty stack. ùê∫ = ( Œì, Œ£, ùëÉ, ‚ä•) Again, I‚Äôm just defining a grammar. is the set of non-terminal symbols (notice how it‚Äôs theŒì same as the set of symbols accepted onto the PDA stack) is the set of terminal symbols (notice how it‚Äôs theŒ£ same as the alphabet that the PDA accepts) is the set of productionsùëÉ is the start non-terminal (notice how it‚Äôs the same as‚ä• the initial stack symbol in the PDA) ‚àÄ ( ( ùëû, ùëê, ùê¥) , ( ùëû, ùêµ 1 . . . ùêµ ùëò) ) ‚àà Œ¥, ùê¥ ‚Üí ùëêùêµ 1 . . . ùêµ ùëò ‚àà ùëÉ For every transition that exists in the PDA, there is also a production in the grammar that takes in the input stack symbol, and outputs the input symbol followed by all the stack symbols put into the stack. - Just by simply reversing the previous proof, we can show that a single-state PDA can be converted to a CFG. - But not every PDA is a single-state PDA. To complete the proof, we need to convert any PDA into a single-state PDA. 2. Now, we will prove that any PDA can be converted to a single-state PDA. - To convert a PDA to a single-state PDA, we need to store the state information inside the stack (since we‚Äôre not going to be moving to any state). - Before we do that, let‚Äôs change the PDA a little bit. - Let‚Äôs change it so that when the PDA reaches a single final state, it can clear it‚Äôs entire stack. Basically, we‚Äôre changing it so the PDA only has one final state. - Second, we‚Äôre going to introduce a new type of stack symbol. It looks like this: - „Äàùëùùê¥ùëû„Äâ - where andùëù, ùëû ‚àà ùëÑ ùê¥ ‚àà Œì - All the new stack symbols will be in a new set called Œì‚Ä≤ - We do this so we can store state information on the stack. Computer Science / Software Engineering Notes Network - We‚Äôre also going to change to just , where is the name of the only state in theùëÑ { *} * PDA. - So, basically, our PDA looks like this: - ùëÄ‚Ä≤ = ( { ‚àó} , Œ£, Œì‚Ä≤, Œ¥‚Ä≤ , ‚àó, „Äàùë†‚ä•ùë°„Äâ, ‚àÖ) - (where is the start and is the end)ùë† ùë° - What is ? Well, it‚Äôs defined as follows:Œ¥‚Ä≤ - ùëìùëúùëü ùëíùëéùëê‚Ñé ùë°ùëüùëéùëõùë†ùëñùë°ùëñùëúùëõ ( ( ùëù,œÉ,ùê¥) , ( ùëû 0 ,ùêµ 1 ùêµ 2 ... ùêµ ùëò) ) ‚àà Œ¥ - ùëñùëõùëêùëôùë¢ùëëùëí ( ( ‚àó, œÉ, „Äàùëùùê¥ùëû ùëò„Äâ) , ( ‚àó, „Äàùëû 0 ùêµ 1 ùëû 1 „Äâ„Äàùëû 1 ùêµ 2 ùëû 2 „Äâ... „Äàùëû ùëò‚àí 1 ùêµ ùëòùëû ùëò„Äâ) ) ùëñùëõ Œ¥‚Ä≤ - ùëìùëúùëü ùëéùëôùëô ùëùùëúùë†ùë†ùëñùëèùëôùëí ùëêùëúùëöùëèùëñùëõùëéùë°ùëñùëúùëõùë† ùëúùëì ùëû 1 , ùëû 2 , ... , ùëû ùëò‚àà ùëÑ - ... and when , then:ùëò = 0 - ùëìùëúùëü ùëíùëéùëê‚Ñé ùë°ùëüùëéùëõùë†ùëñùë°ùëñùëúùëõ ( ( ùëù,œÉ,ùê¥) , ( ùëû 0 ,Œµ) ) ‚àà Œ¥ - ùëñùëõùëêùëôùë¢ùëëùëí ( ( ‚àó, œÉ, „Äàùëùùê¥ùëû 0 „Äâ) , ( ‚àó,Œµ) ) ùëñùëõ Œ¥‚Ä≤ - To some people (normal people), this is just maths gibberish;what does this actually mean? - Remember that PDAs are also nondeterministic. Here, each guess the PDA makes, the stack ‚Äúpredicts‚Äù what transitions it‚Äôll go through in the future. If the prediction is correct, it‚Äôll pass. If the prediction is wrong, that guess will ‚Äúdie‚Äù. - In other words, at each stage, we nondeterministically guess the remainder of the computation of the automaton and then verify it. - This is just a way of encoding the non-deterministic nature of the states into the stack. - This is really hard to visualise just by reading the descriptions, so let‚Äôs go through an example. - We have a PDA here that maps out the language :{ ùëé ùëõ ùëè ùëõ | ùëõ > 0 } Computer Science / Software Engineering Notes Network - Before we pick out transitions, let‚Äôs have a look at all the possible stack symbols: „Äà0 ‚ä• 0 „Äâ „Äà0 ‚ä• 1 „Äâ „Äà0 ‚ä• 2 „Äâ „Äà1 ‚ä• 0 „Äâ „Äà1 ‚ä• 1 „Äâ „Äà1 ‚ä• 2 „Äâ „Äà2 ‚ä• 0 „Äâ „Äà2 ‚ä• 1 „Äâ „Äà2 ‚ä• 2 „Äâ „Äà0 ùëé0 „Äâ „Äà0 ùëé1 „Äâ „Äà0 ùëé2 „Äâ „Äà1 ùëé0 „Äâ „Äà1 ùëé1 „Äâ „Äà1 ùëé2 „Äâ „Äà2 ùëé0 „Äâ „Äà2 ùëé1 „Äâ „Äà2 ùëé2 „Äâ - You can think of each of these as like a possible transition that the PDA could take. - For example, could refer to the transition going from state 1 to 1, accepting„Äà1 ùëé1 „Äâ ùëé on the stack. - Yes, there are some transitions that do not exist, like or , but they could„Äà2 ùëé2 „Äâ „Äà0 ‚ä• 2 „Äâ exist. The stack doesn‚Äôt know what transitions exist, so it guesses with all possible combinations of transitions. The guesses that predict transitions that do exist will live and are more likely to predict everything correctly, and the guesses that predict transitions that do not exist end up dying. - Let‚Äôs pick out a transition from this and convert it to its single-state equivalent. - Let‚Äôs pick the transition that goes from state 0 to 0 with ‚ä• on the stack: - ( ( 0 , ùëé, ‚ä•) , ( 0 , ùëé ‚ä•) ) - Now let‚Äôs convert it: - ( ( ‚àó, ùëé, „Äà0 ‚ä• 0 „Äâ) , ( ‚àó, „Äà0 ùëé0 „Äâ„Äà0 ‚ä• 0 „Äâ) ) - ( ( ‚àó, ùëé, „Äà0 ‚ä• 0 „Äâ) , ( ‚àó, „Äà0 ùëé1 „Äâ„Äà1 ‚ä• 0 „Äâ) ) - ( ( ‚àó, ùëé, „Äà0 ‚ä• 0 „Äâ) , ( ‚àó, „Äà0 ùëé2 „Äâ„Äà2 ‚ä• 0 „Äâ) ) - ( ( ‚àó, ùëé, „Äà0 ‚ä• 1 „Äâ) , ( ‚àó, „Äà0 ùëé0 „Äâ„Äà0 ‚ä• 1 „Äâ) ) - ( ( ‚àó, ùëé, „Äà0 ‚ä• 1 „Äâ) , ( ‚àó, „Äà0 ùëé1 „Äâ„Äà1 ‚ä• 1 „Äâ) ) Computer Science / Software Engineering Notes Network - ( ( ‚àó, ùëé, „Äà0 ‚ä• 1 „Äâ) , ( ‚àó, „Äà0 ùëé2 „Äâ„Äà2 ‚ä• 1 „Äâ) ) - ( ( ‚àó, ùëé, „Äà0 ‚ä• 2 „Äâ) , ( ‚àó, „Äà0 ùëé0 „Äâ„Äà0 ‚ä• 2 „Äâ) ) - ( ( ‚àó, ùëé, „Äà0 ‚ä• 2 „Äâ) , ( ‚àó, „Äà0 ùëé1 „Äâ„Äà1 ‚ä• 2 „Äâ) ) - ( ( ‚àó, ùëé, „Äà0 ‚ä• 2 „Äâ) , ( ‚àó, „Äà0 ùëé2 „Äâ„Äà2 ‚ä• 2 „Äâ) ) - So if we compute that transition, our single-state PDA will compute 3 parallel guesses, depending on what‚Äôs on the stack. - Let‚Äôs pick out a simpler transition and convert that: - ( ( 1 , ùëè, ùëé) , ( 1 , Œµ) ) - Since this transition will only pop from the stack and not push, it‚Äôll only generate one transition relation for our single-state PDA: - ( ( ‚àó, ùëè, „Äà1 ùëé1 „Äâ) , ( ‚àó, Œµ) ) - So in our single-state PDA, if it sees on the stack, that means the guess‚Äô„Äà1 ùëé1 „Äâ prediction was correct and the guess will live. If it does not see that on the stack, the guess‚Äôprediction was wrong and will die. - Now that we‚Äôve defined these, let‚Äôs try inputting a string into this multi-state PDA, and see how it‚Äôs single-state equivalent works by comparing the two. Multi-state PD A Sin gle-state PD A guesses D escrip tio n ( 0 , ùëéùëéùëèùëè, ‚ä•) ( ‚àó, ùëéùëéùëèùëè, „Äà0 ‚ä•2 „Äâ) We haven‚Äôt really done anything yet. The initial stack symbol in a single-state PDA is always: „Äà [ ùëñùëõùëñùë°ùëñùëéùëô ùë†ùë°ùëéùë°ùëí] ‚ä• [ ùëìùëñùëõùëéùëô ùë†ùë°ùëéùë°ùëí] „Äâ This is possible because there‚Äôs only one initial state and, like what we‚Äôve defined before, only one final state. ( 0 , ùëéùëèùëè, ùëé‚ä•) ( ‚àó, ùëéùëèùëè, „Äà0 ùëé0 „Äâ„Äà0 ‚ä•2 „Äâ) ( ‚àó, ùëéùëèùëè, „Äà0 ùëé1 „Äâ„Äà1 ‚ä•2 „Äâ) ( ‚àó, ùëéùëèùëè, „Äà0 ùëé2 „Äâ„Äà2 ‚ä•2 „Äâ) We‚Äôve inputted an ‚Äòa‚Äôas input, and now our single-state PDA has started guessing! As you‚Äôve (hopefully) read above, three guesses will be made in this situation; a was read from the stack and an ‚Äòa‚Äô„Äà0 ‚ä•2 „Äâ input was read, and now the following three guesses have been established. These three guesses go like this: What if we go from state 0 to state 0 using ‚Äòa‚Äôon the stack, then go from state 0 to state 2 using floor? What if we go from state 0 to state 1 using ‚Äòa‚Äôon the stack, then go from state 1 to state 2 using floor? What if we go from state 0 to state 2 using ‚Äòa‚Äôon the stack, then go from state 2 to state 2 using floor? I admit, some of these guesses are a little (really) dumb, but can you blame them? Computer Science / Software Engineering Notes Network The stack doesn‚Äôt know what transitions exist; it doesn‚Äôt know that there isn‚Äôta transition from state 0 to state 2. So what does it do? It guesses. It guesses every single combination so that if it gets something wrong, it can fall back on another guess. If all the guesses are wrong, then there‚Äôs no way the PDA can accept the string. ( 0 , ùëèùëè, ùëéùëé‚ä•) ( ‚àó, ùëèùëè, „Äà0 ùëé0 „Äâ„Äà0 ùëé0 „Äâ„Äà0 ‚ä•2 „Äâ) ( ‚àó, ùëèùëè, „Äà0 ùëé1 „Äâ„Äà1 ùëé0 „Äâ„Äà0 ‚ä•2 „Äâ) ( ‚àó, ùëèùëè, „Äà0 ùëé2 „Äâ„Äà2 ùëé0 „Äâ„Äà0 ‚ä•2 „Äâ) ( ‚àó, ùëèùëè, „Äà0 ùëé0 „Äâ„Äà0 ùëé1 „Äâ„Äà1 ‚ä•2 „Äâ) ( ‚àó, ùëèùëè, „Äà0 ùëé1 „Äâ„Äà1 ùëé1 „Äâ„Äà1 ‚ä•2 „Äâ) ( ‚àó, ùëèùëè, „Äà0 ùëé2 „Äâ„Äà2 ùëé1 „Äâ„Äà1 ‚ä•2 „Äâ) ( ‚àó, ùëèùëè, „Äà0 ùëé0 „Äâ„Äà0 ùëé2 „Äâ„Äà2 ‚ä•2 „Äâ) ( ‚àó, ùëèùëè, „Äà0 ùëé1 „Äâ„Äà1 ùëé2 „Äâ„Äà2 ‚ä•2 „Äâ) ( ‚àó, ùëèùëè, „Äà0 ùëé2 „Äâ„Äà2 ùëé2 „Äâ„Äà2 ‚ä•2 „Äâ) Wow! Look at all those guesses! We‚Äôve inputted another ‚Äòa‚Äôinto our PDAs, and now, we‚Äôre exponentially making guesses. None of our guesses have died yet. Because we‚Äôre pushing more than we‚Äôre popping, we‚Äôre making more guesses about what we want to do next; there are more possibilities now. The transition here is slightly different, because we‚Äôre not using floor ‚ä•, but the concept is still the same. What? You want to see how this transition is converted to it‚Äôs single-state PDA equivalent? Well, alright, but only because you asked so nicely: ( ( 0 , ùëé, ùëé) , ( 0 , ùëéùëé) ) Converts to: ( ( ‚àó, ùëé, „Äà0 ùëé0 „Äâ) , ( ‚àó, „Äà0 ùëé0 „Äâ„Äà0 ùëé0 „Äâ) ) ( ( ‚àó, ùëé, „Äà0 ùëé0 „Äâ) , ( ‚àó, „Äà0 ùëé1 „Äâ„Äà1 ùëé0 „Äâ) ) ( ( ‚àó, ùëé, „Äà0 ùëé0 „Äâ) , ( ‚àó, „Äà0 ùëé2 „Äâ„Äà2 ùëé0 „Äâ) ) ( ( ‚àó, ùëé, „Äà0 ùëé1 „Äâ) , ( ‚àó, „Äà0 ùëé0 „Äâ„Äà0 ùëé1 „Äâ) ) ( ( ‚àó, ùëé, „Äà0 ùëé1 „Äâ) , ( ‚àó, „Äà0 ùëé1 „Äâ„Äà1 ùëé1 „Äâ) ) ( ( ‚àó, ùëé, „Äà0 ùëé1 „Äâ) , ( ‚àó, „Äà0 ùëé2 „Äâ„Äà2 ùëé1 „Äâ) ) ( ( ‚àó, ùëé, „Äà0 ùëé2 „Äâ) , ( ‚àó, „Äà0 ùëé0 „Äâ„Äà0 ùëé2 „Äâ) ) ( ( ‚àó, ùëé, „Äà0 ùëé2 „Äâ) , ( ‚àó, „Äà0 ùëé1 „Äâ„Äà1 ùëé2 „Äâ) ) ( ( ‚àó, ùëé, „Äà0 ùëé2 „Äâ) , ( ‚àó, „Äà0 ùëé2 „Äâ„Äà2 ùëé2 „Äâ) ) ( 1 , ùëè, ùëé‚ä•) ( ‚àó, ùëèùëè, „Äà0 ùëé0 „Äâ„Äà0 ùëé0 „Äâ„Äà0 ‚ä•2 „Äâ) ( ‚àó, ùëèùëè, „Äà0 ùëé1 „Äâ„Äà1 ùëé0 „Äâ„Äà0 ‚ä•2 „Äâ) ( ‚àó, ùëèùëè, „Äà0 ùëé2 „Äâ„Äà2 ùëé0 „Äâ„Äà0 ‚ä•2 „Äâ) ( ‚àó, ùëèùëè, „Äà0 ùëé0 „Äâ„Äà0 ùëé1 „Äâ„Äà1 ‚ä•2 „Äâ) ( ‚àó, ùëèùëè, „Äà0 ùëé1 „Äâ„Äà1 ùëé1 „Äâ„Äà1 ‚ä•2 „Äâ) ( ‚àó, ùëèùëè, „Äà0 ùëé2 „Äâ„Äà2 ùëé1 „Äâ„Äà1 ‚ä•2 „Äâ) ( ‚àó, ùëèùëè, „Äà0 ùëé0 „Äâ„Äà0 ùëé2 „Äâ„Äà2 ‚ä•2 „Äâ) ( ‚àó, ùëèùëè, „Äà0 ùëé1 „Äâ„Äà1 ùëé2 „Äâ„Äà2 ‚ä•2 „Äâ) ( ‚àó, ùëèùëè, „Äà0 ùëé2 „Äâ„Äà2 ùëé2 „Äâ„Äà2 ‚ä•2 „Äâ) Oh no! The guesses! They‚Äôre dying! We‚Äôve taken the transition: ( ( 0 , ùëè, ùëé) , ( 1 , Œµ) ) ...which converts into: ( ( ‚àó, ùëè, „Äà0 ùëé1 „Äâ) , ( ‚àó, Œµ) ) So, what the single-state PDA is doing is, it‚Äôs looking for a on the stack. If it‚Äôs„Äà0 ùëé1 „Äâ there, the guess is right, it just pops it off and doesn‚Äôt push anything else on. If it‚Äôs not there, the guess is wrong and the guess dies. Computer Science / Software Engineering Notes Network ------------------------------------- ( ‚àó, ùëè, „Äà1 ùëé0 „Äâ„Äà0 ‚ä•2 „Äâ) ( ‚àó, ùëè, „Äà1 ùëé1 „Äâ„Äà1 ‚ä•2 „Äâ) ( ‚àó, ùëè, „Äà1 ùëé2 „Äâ„Äà2 ‚ä•2 „Äâ) As you can see, 6 guesses died, leaving only 3 guesses from each coloured partition. The top guesses show which ones survived and which ones died from the previous configuration (the gothy red and black ones are the ones that died). The bottom 3 guesses shows the top 3 living guesses after their ‚Äòb‚Äôs have been inputted and stacks have been popped. ( 1 , Œµ, ‚ä•) ( ‚àó, ùëè, „Äà1 ùëé0 „Äâ„Äà0 ‚ä•2 „Äâ) ( ‚àó, ùëè, „Äà1 ùëé1 „Äâ„Äà1 ‚ä•2 „Äâ) ( ‚àó, ùëè, „Äà1 ùëé2 „Äâ„Äà2 ‚ä•2 „Äâ) ------------------------------------- ( ‚àó, Œµ, „Äà1 ‚ä•2 „Äâ) We‚Äôve taken the transition: ( ( 1 , ùëè, ùëé) , ( 1 , Œµ) ) ... which converts to: ( ( ‚àó, ùëè, „Äà1 ùëé1 „Äâ) , ( ‚àó, Œµ) ) So, like before, it looks for a on top of„Äà1 ùëé1 „Äâ the stack. If it‚Äôs there, we live. If it‚Äôs not there, we die. There‚Äôs only one guess here with a !„Äà1 ùëé1 „Äâ This guess has correctly predicted every move that the PDA has done. Congratulations, guess! So now, we pop off and continue.„Äà1 ùëé1 „Äâ The existence of this guess is enough to accept the inputted string, right? Almost. There‚Äôs one formality we need to take care of first:we need to move to state 2, the final state, to properly conclude this. Will this last-standing guess be able to conquer the final step by predicting the final transition from state 1 to state 2? Spoilers: it does ( 2 , Œµ, Œµ) ( ‚àó, Œµ, Œµ) It should be needless to say that this final transition looks for a to pop, and finds„Äà1‚ä•2 „Äâ one within the final guess. We can now accept by empty stack. This string is within the language of this PDA, and this single-state PDA is equivalent to this multi-state PDA! - If it helps to visualise it better, here‚Äôs the successful guess from start to finish: - ( ‚àó, ùëéùëéùëèùëè, „Äà0 ‚ä•2 „Äâ) Computer Science / Software Engineering Notes Network - ( ‚àó, ùëéùëèùëè, „Äà0 ùëé1 „Äâ„Äà1 ‚ä•2 „Äâ) - ( ‚àó, ùëèùëè, „Äà0 ùëé1 „Äâ„Äà1 ùëé1 „Äâ„Äà1 ‚ä•2 „Äâ) - ( ‚àó, ùëè, „Äà1 ùëé1 „Äâ„Äà1 ‚ä•2 „Äâ) - ( ‚àó, Œµ, „Äà1 ‚ä•2 „Äâ) - ( ‚àó, Œµ, Œµ ) Proving closure Union - CFLs are closed under union - This means that the language of the union of two CFGs is also going to be context-free - We are going to create a grammar that is the union of two other grammars. - We can assume that the non-terminals of our two grammars are going to be distinct, meaning that we don‚Äôt have non-terminals that appear in both grammars. - If we have, we are just going to rename them, it won‚Äôt change the grammar. - Let‚Äôs introduce a new start symbol and a new production for this new start symbol. - The new production is going to link our new start symbol to the old start symbols from our two grammars like this: ùëÜ ‚Üí ùëÜ 1 | ùëÜ 2 Where is the start symbol of the first grammar and is the start symbolùëÜ 1 ùëÜ 2 from the second grammar - As for the other non-terminals and the other productions, we are just copying them from what we have in our two other grammars. - Now we can generate everything that the first grammar is able to produce by deriving and we can also generate everything that the second grammar is able to produceùëÜ 1 by deriving ùëÜ 2 . Concatenation - CFLs are closed under concatenation - This means that the language of the concatenation of two CFGs is also going to be context-free - Proving this is exactly the same as proving the union, just that our start production is going to be different: ùëÜ ‚Üí ùëÜ 1 ùëÜ 2 Where is the start symbol of the first grammar and is the start symbol from theùëÜ 1 ùëÜ 2 second grammar Computer Science / Software Engineering Notes Network - Now we can generate everything that the first grammar is able to produce by deriving and then we can generate everything that the second grammar is able toùëÜ 1 produce by deriving ùëÜ 2 . Kleene star - CFLs are closed under kleene star - This means that the language of 0 or more repetitions of a CFG is also going to be context-free. - We are going to create a grammar that represents the kleene star of another grammar. - Let‚Äôs introduce a new start symbol and a new production for this new start symbol. - The new production is going to look like this: ùëÜ ‚Üí ùëÜùëÜ 1 | Œµ Where is the start symbol of the other grammar.ùëÜ 1 - As for the other non-terminals and the other productions, we are just copying them from what we have in the other grammar. - Now we can produce 0 or more repetitions of everything that the other grammar is able to produce by deriving or fromùëÜùëÜ 1 Œµ ùëÜ. Intersection with regular languages - CFLs are closed under the intersection with regular languages - This means that the language of a CFG intersected with a regular language is going to be context-free. - In contrast, the intersection of two CFL is not always context-free. - Idea:Product construction with PDA and DFA. - The slides don‚Äôt go into more detail than that, but I will. - Let‚Äôs give our automata names, because that makes them easier to work with. Let‚Äôs call our DFA and our PDA .ùëÄ ùê∑ ùëÄ ùëÉ - DFAs are just weak PDAs, so we can convert our DFA into a PDA. It‚ÄôsùëÄ ùê∑ basically just going to be a PDA that doesn‚Äôt use it‚Äôs stack and doesn‚Äôt use any non-deterministic features. Let‚Äôs call this , where .ùëÄ ùëÉ' ùêø( ùëÄ ùëÉ') = ùêø( ùëÄ ùê∑) - So now we have two PDAs, and . We need to perform productùëÄ ùëÉ' ùëÄ ùëÉ construction on these, so that we can construct a PDA that accepts strings accepted by bo th and (because that‚Äôs what intersection means).ùëÄ ùëÉ' ùëÄ ùëÉ Computer Science / Software Engineering Notes Network - Let‚Äôs call this product construct-ed PDA . Normally, product constructionùëÄ ùëÉ'' with PDAs don‚Äôt work, because they interfere with each other on the stack (they have to share a stack). However, this case is different. How do we know that and don‚Äôt interfere with each other on the stack?ùëÄ ùëÉ ùëÄ ùëÉ' - We know they don‚Äôt interfere because doesn‚Äôt even use the stack!ùëÄ ùëÉ' Remember, it‚Äôs just a DFA calling itself a PDA;it doesn‚Äôt even use the stack. Heck, it can‚Äôt even use any non-deterministic features, or any epsilon-moves. The stack is completely free for to use.ùëÄ ùëÉ - Because we‚Äôve defined a PDA that supports the intersection of regular languages, we‚Äôve shown that it‚Äôs closed. We can convert this PDA into a context-free grammar, showing that the language represented by this PDA is context-free, therefore showing that the intersection with regular languages is closed. Computer Science / Software Engineering Notes Network Limits of context-free languages - Are all languages context free? No! - E.g. the language is not context-free, meaning that we cannot{ ùëé ùëõ ùëè ùëõ ùëê ùëõ } construct a PDA that accepts or a CFG that produces this language. In fact, we would need a Turing machine to accept this language, which we will see later. - Assume our grammar is in CNF - Remember that we can convert any grammar to CNF if it isn‚Äôt - I‚Äôm going to use the following CNF for further explanations: - ùëÜ ‚Üí ùê¥ùê∂ | ùê¥ùêµ - ùê∂ ‚Üí ùëÜùêµ - ùê¥ ‚Üí ùëé - ùêµ ‚Üí ùëè Which represents the language { ùëé ùëõ ùëè ùëõ | ùëõ ‚â• 1 } - If we start deriving a string using our CNF, we can draw the process of deriving the string as a binary tree. - For instance, let‚Äôs derive and draw the derivations as a binary tree:ùëé 3 ùëè 3 - We can see that in the middle path of the tree, we have a long path of non-terminals. We will have this in every derivation which is long enough (we‚Äôll define what long enough means below). - We can also see that there are some non-terminals that are repeated. - If we go one step down in the tree, we are going to at most double its width - This is because our grammar is in CNF, which allows us to derive at most 2 non-terminals in a single rule. - Therefore, the derivation tree of a string of size must have a depth of at least2 ùëò ùëò - Suppose that there are non-terminals. In any derivation tree of a string of length atùëõ least there must be a path where some non-terminal appears at least twice, i.e.2 ùëõ+ 1 is repeated. Computer Science / Software Engineering Notes Network - The derivation tree of a string of size must have a depth of at least2 ùëõ+ 1 ùëõ + 1 . - However, we only have non-terminals, therefore we need to repeat at leastùëõ one of our non-terminals.ùëõ - If we see a repeated non-terminal, we can start pumping this non-terminal into the tree. - Here, we split our tree into where the tree generated by the blueùë¢ùë£ùë§ùë•ùë¶ ùëÜ covers and the tree generated by the red covers only. Everythingùë£ùë§ùë• ùëÜ ùë§ outside of the blue will be covered by andùëÜ ùë¢ ùë¶. - Now, we are copying the subtree of the blue and paste it into the position ofùëÜ the red .ùëÜ - Every time we do this, we are essentially adding another part and anotherùë£ part to our tree.ùë• - We can also replace the subtree of the blue with the subtree of the red . By doingùëÜ ùëÜ this we are taking and out of the tree completely.ùë£ ùë• - This act of ‚Äòremoving‚Äôand ‚Äòpumping in‚Äô and forms the basis for the pumpingùë£ ùë• lemma for context-free languages. Computer Science / Software Engineering Notes Network Pumping (üéÉ) Lemma for context-free languages - contrapositive form - We can use the contrapositive form of the pumping lemma for context free languages to show that a language is not context free. We cannot use the pumping lemma to show that a language is context free! - It works by splitting up the language into parts, then ‚Äúpumping‚Äù a subpart until you get a string that isn‚Äôt in the language. This is similar to what we have just done before. - The different steps of the proof can be understood as a game versus a demon. 1. The demon chooses a number such that .ùëò ùëò ‚â• 0 - We cannot choose a value for , we only know that it is greater than or equalùëò to 0. 2. We choose a string such that .ùëß ‚àà ùêø ùëß| |‚â• ùëò - We can choose any string that is within the language. However, we have toùëß make sure that, no matter what is, our string is always in the language.ùëò ùëß We do not need to cover the whole language with our string! - The length of must be at least . A way to make sure that this is always theùëß ùëò case is to have at least a part in that is equal to something to the power of .ùëß ùëò - As a general tip, try to make as trivial as possible, like in the followingùëß example: - For instance, we could let to make sure that is at least long (ùëß = ùëé ùëò ùëè ùëò ùëê ùëò ùëß ùëò are symbols from the alphabet).ùëé, ùëè, ùëê 3. The demon splits into such that , i.e. , andùëß ùë¢ùë£ùë§ùë•ùë¶ ùë£ùë•| | > 0 ùë£ùë• ‚â† Œµ |ùë£ùë§ùë•| ‚â§ ùëò. - You cannot choose how the string is going to be split! - What you do know is that the part of the string is not going to be empty.ùë£ùë• However, one of or can still be empty.ùë£ ùë• - You also know that the length of the is at most .ùë£ùë§ùë• ùëò - You can think of as a window you can slide across what you defined asùë¢ùë£ùë§ ùëß . - Therefore, we have to list all possible cases in which can be split andùë¢ùë£ùë§ùë•ùë¶ proceed with each of them to the next step. - For instance, if , we have to consider the following cases:ùëß = ùëé ùëò ùëè ùëò ùëê ùëò = ùë¢ùë£ùë§ùë•ùë¶ i. Case 1: contains only one repeated letter:Either only ‚Äôs, or onlyùë£ùë• ùëé ùëè ‚Äôs, or only ‚Äôsùëê - e.g. ùë¢ùë£ùë§ùë•ùë¶=ùëéùëéùëéùëéùëéùëèùëèùëèùëèùëèùëêùëêùëêùëêùëê ii. Case 2:either or (but not both) is a word that contains more thanùë£ ùë• one kind of symbol. - e.g. ùë¢ùë£ùë§ùë•ùë¶=ùëéùëéùëéùëéùëéùëèùëèùëèùëèùëèùëêùëêùëêùëêùëê iii. Case 3: and do not have any symbols in common.ùë£ ùë• Computer Science / Software Engineering Notes Network - e.g. ùë¢ùë£ùë§ùë•ùë¶=ùëéùëéùëéùëéùëéùëèùëèùëèùëèùëèùëêùëêùëêùëêùëê iv. It cannot be the case that contains all three letters because theùë£ùë§ùë• length of is at most .ùë£ùë§ùë• ùëò 4. We pick an such that the string If this is the case we have provenùëñ ‚â• 0 ùë¢ùë£ ùëñ ùë§ùë• ùëñ ùë¶ ‚àâ ùêø. that the language is not context-free! - We can pick any we want as long as it is equal to or greater than 0.ùëñ - Our goal is to choose an such that the resulting string is outside of theùëñ language. - We have to do this for every case we defined in the previous step. - Here is how to do it for the example cases above: i. Let ùëñ = 2 ii. Case 1: contains only one repeated letter:then is going toùë£ùë• ùë¢ùë£ 2 ùë§ùë• 2 ùë¶ have either too many of , orùëé'ùë† ùëè'ùë† ùëê'ùë† iii. Case 2:either or contains two different symbols:then isùë• ùë£ ùë¢ùë£ 2 ùë§ùë• 2 ùë¶ going to have too many of two of , or .ùëé'ùë† ùëè'ùë† ùëê'ùë† iv. Case 3: does not contain the same symbol as . then isùë£ ùë• ùë¢ùë£ 2 ùë§ùë• 2 ùë¶ going to have too many of two of , or .ùëé'ùë† ùëè'ùë† ùëê'ùë† 5. You MUST say ‚ÄúTherefore L is not context-free‚Äù, if you don‚Äôt, you will lose marks. - If this still doesn‚Äôt make any sense, look at a few examples below, and then read the general case above again. Examp le So lutio n ùêø = { ùëé ùëõ ùëè ùëõ ùëê ùëõ } 1. The demon chooses a number such that .ùëò ùëò ‚â• 0 2. We choose a string such that .ùëß ‚àà ùêø ùëß| |‚â• ùëò - Let‚Äôs choose .ùëß = ùëé ùëò ùëè ùëò ùëê ùëò - We can see that .ùëß| |‚â• ùëò 3. The demon splits into such that , i.e. ,ùëß ùë¢ùë£ùë§ùë•ùë¶ ùë£ùë•| | > 0 ùë£ùë• ‚â† Œµ and |ùë£ùë§ùë•| ‚â§ ùëò. - Let‚Äôs consider all the different cases: - Case 1: contains only one repeated letter:Eitherùë£ùë• only ‚Äôs, or only ‚Äôs, or only ‚Äôsùëé ùëè ùëê - Case 2:either or (but not both) is a word thatùë£ ùë• contains more than one kind of letter. - Case 3: and do not have any letters in common.ùë£ ùë• 4. We pick an such that the stringùëñ ‚â• 0 ùë¢ùë£ ùëñ ùë§ùë• ùëñ ùë¶ ‚àâ ùêø. - pick , thenùëñ = 2 ùë¢ùë£ 2 ùë§ùë• 2 ùë¶ ‚àâ ùêø - Case 1: Computer Science / Software Engineering Notes Network i. Our resulting word will have one letter repeated more often than the other two letters. - Case 2 i. Our resulting word is not going to be of the form a*b*c*. - Case 3: i. Our resulting word is going to have more of two of the letters but the number of occurrences of the third letter remains unchanged. 5. Therefore, L is not context-free ùêø = { ùëé 4 ùëõ ùëè ùëõ ùëé 4 ùëõ } 1. The demon chooses a number such that .ùëò ùëò > 0 2. We choose a string such that .ùëß ‚àà ùêø ùëß| |‚â• ùëò - Let‚Äôs choose .ùëß = ùëé 4 ùëò ùëè ùëò ùëé 4 ùëò - We can see that .ùëß| |‚â• ùëò 3. The demon splits into such that , i.e. ,ùëß ùë¢ùë£ùë§ùë•ùë¶ ùë£ùë•| | > 0 ùë£ùë• ‚â† Œµ and |ùë£ùë§ùë•| ‚â§ ùëò. - Let‚Äôs consider all the different cases: - Case 1: contains only one repeated letter:Eitherùë£ùë• only ‚Äôs, or only ‚Äôs.ùëé ùëè - Case 2:either or (but not both) is a word thatùë£ ùë• contains more than one kind of letter. - Case 3: and do not have any letters in common.ùë£ ùë• 4. We pick an such that the stringùëñ ‚â• 0 ùë¢ùë£ ùëñ ùë§ùë• ùëñ ùë¶ ‚àâ ùêø. - Pick , thenùëñ = 2 ùë¢ùë£ 2 ùë§ùë• 2 ùë¶ ‚àâ ùêø - Case 1: i. We are changing the number of either the ‚Äôsùëé or the ‚Äôs. Therefore, the number of ‚Äôs won‚Äôtùëè ùëé be eight times the number of ‚Äôs anymore.ùëè - Case 2 i. Our resulting word is not going to be of the form a*b*a*. - Case 3: i. We are changing the number of either the first ‚Äôs and the ‚Äôs or the ‚Äôs and the second ‚Äôs.ùëé ùëè ùëè ùëé Therefore, the number of the first ‚Äôs won‚Äôtùëé match with the number of the second ‚Äôsùëé anymore. 5. Therefore, L is not context-free ùêø = { ùëé 2 ùëõ | ùëõ ‚â• 0 } 1. The demon chooses a number such that .ùëò ùëò > 0 2. We choose a string such that .ùëß ‚àà ùêø ùëß| |‚â• ùëò a. Let‚Äôs choose .ùëß = ùëé 2 ùëò b. We can see that .ùëß| |= 2 ùëò ‚â• ùëò Computer Science / Software Engineering Notes Network 3. The demon splits into such that , i.e. ,ùëß ùë¢ùë£ùë§ùë•ùë¶ ùë£ùë•| | > 0 ùë£ùë• ‚â† Œµ and |ùë£ùë§ùë•| ‚â§ ùëò. a. This time we only have to consider one case as we only have one letter in our windowùëé ùë£ùë§ùë•. b. We know that we have at least 1 and at most ‚Äôs inùëò ùëé our window, which we are going to pump in the next step. 4. We pick an such that the stringùëñ ‚â• 0 ùë¢ùë£ ùëñ ùë§ùë• ùëñ ùë¶ ‚àâ ùêø. a. pick ùëñ = 2 b. where we|ùë¢ùë£ 2 ùë§ùë• 2 ùë¶| = |ùë¢ùë£ùë§ùë•ùë¶| + |ùë£ùë•| = 2 ùëò + ùëô define l to be |ùë£ùë•| c. Define the bounds of to beùëô 1 ‚â§ ùëô ‚â§ ùëò i. This is because and when|ùë£ùë•| > 0 |ùë£ùë§ùë•| ‚â§ ùëò ùë§ = Œµ d. I know that because its length, ,ùë¢ùë£ 2 ùë§ùë• 2 ùë¶ ‚àâ ùêø 2 ùëò + ùëô cannot be expressed as some number .2 ùëö e. This is because is going to be strictly between2 ùëò + ùëô and :2 ùëò 2 ùëò+ 1 2 ùëò < 2 ùëò + ùëô < 2 ùëò+ 1 f. If you have doubts, check the bounds of again andùëô also try to plug in and (imagine you are the demon)ùëò ùëô 5. Therefore, L is not context-free Computer Science / Software Engineering Notes Network Computability theory Turing machines - With DFAs and NFAs, we had states and transitions. - With PDAs, we had states, transitions and a stack. - Now, with Turing machines, we have states, transitions and a ‚Äútape‚Äù, which is basically a linked list storing the input string at each node. - With this new data structure at our disposal, we can do even more things than PDAs. - In fact, according to the Church-Turing thesis, Turing machines (TMs, not to be confused with Pok√©mon TMs) are just as powerful as algorithms. - However, TMs do not cover all languages. They‚Äôre not that good. See Undecidable Problems for languages not covered by TMs. - So, what exactly are TMs? I‚Äôll go through them informally and then formally. 1. Informally - They‚Äôre basically like PDAs, but instead of a stack, you get a tape, where you can move left or right on each transition. - You can think of the tape as like a doubly linked list, where you can traverse left and right. - The input string is on the tape, and we start at the far left and usually work our way to the right. - Here is an example of a tape in the middle of a TM execution: ‚ä¢ a ‚äî c ‚ä£ - The ‚ä¢symbol means the ‚Äòstart‚Äô, it‚Äôs a left marker. - The ‚äîsymbol means ‚Äòempty‚Äô, there‚Äôs nothing here. - The ‚ä£symbol means the ‚Äòend‚Äô, it‚Äôs a right marker. - The part that‚Äôs shaded in red is the current position we‚Äôre on, and the other blue parts are all the other positions. 2. Formally - Formally, a TM is a 9-tuple: - ùëÄ = ( ùëÑ, Œ£, Œì, ‚ä¢, ‚äî, Œ¥, ùë†, ùë°, ùëü) - where - is the finite set of statesùëÑ - |Q| ‚â• 3 :accept, reject and start states as well as other states - is the input alphabetŒ£ Computer Science / Software Engineering Notes Network - is the tape alphabet ( :the input alphabet is a proper subset of theŒì Œ£ ‚äÇ Œì tape alphabet) - is the left endmarker (left endmarkers are part of the tape‚ä¢ ‚àà Œì ‚àí Œ£ alphabet, but not the input alphabet) - is the blank symbol (blanks are part of the tape alphabet, but not‚äî ‚àà Œì ‚àí Œ£ the input alphabet) - is the transition functionŒ¥: ( ùëÑ ‚àí { ùë°, ùëü} ) √ó Œì ‚Üí ùëÑ √ó Œì √ó { ùêø, ùëÖ} - In English, it‚Äôs in the form whereŒ¥( ùëé, ùëè) ‚Üí( ùëê, ùëë, ùëí) - is a possible state that is n o t the accept / reject stateùëé - is a tape symbol that must be at our current position on theùëè tape - is a state to go toùëê - is a tape symbol to write to the tapeùëë - is either left or right , to traverse the tapeùëí ùêø ùëÖ - is the start stateùë† - is the accept stateùë° - is the reject stateùëü - When performing transitions, we cannot overwrite and we cannot move left if we‚Äôre‚ä¢ at the left endmarker. - We can write element in onto the tape (including ‚ä¢and ).Œì ‚äî Decidability Recursive and R.E languages - A to tal turin g machin e is a TM that halts on every input (does not loop infinitely) - A turing machine that isn‚Äôt total can hang (like Microsoft Visual Studio) - A language is recursive if there exists a total Turing machine that accepts it. - A language is recursively en umerable (r.e) if there exists a Turing machine that accepts all of the strings in that language. - Remember that all recursive languages are recursively enumerable:R ‚äÇ R.E Proof:Recursive Sets Closed under Complement - Recursive sets are clo sed un der co mp lemen t (if L is recursive, ~L is also recursive) - Remember how we proved DFAs are closed under complement? It‚Äôs the same ordeal here. - Let‚Äôs say we have a language ‚ÄòA‚Äôthat is accepted by a TM ‚ÄòM‚Äô. If we can construct a TM for ~A, then we can prove this lemma. - Just swap the accept state and the reject state. This way, ~A will accept .Œ£ * ‚àí ùê¥ - In other words, whenever A accepts something, ~A will reject it, and whenever A rejects something, ~A will accept it. That‚Äôs literally the definition of a complement! Computer Science / Software Engineering Notes Network - Lemma:If L and ~L are r.e, then L is recursive - Let‚Äôs say that the TMs ‚ÄòM1‚Äôaccepts ‚ÄòL‚Äôand ‚ÄòM2‚Äôaccepts ‚Äò~L‚Äô. - If we can construct a total TM ‚ÄòN‚Äôthat simulates both M1 and M2, then we can show that this lemma is true. - Why the existence of N proves this lemma : - M1 accepts everything in L, so it never hangs for strings in L. - M2 accepts everything in ~L, so it never hangs for strings that are not in L. - When ‚ÄòN‚Äôsimulates M1 and M2, that means if M1 accepts, N accepts, and if M2 accepts, N rejects, so that the language of N is the same as M1. - But M1 never hangs for L, and M2 never hangs for anything not in L. If ‚ÄòN‚Äôwill halt when either M1 or M2 halts, that means ‚ÄòN‚Äôwill never hang for L an d never hang for anything not in L. But that just means ‚ÄòN‚Äôwill halt on any string! - Therefore ‚ÄòN‚Äôwon‚Äôt hang on an y string, making the language L recursive. - Constructing N: - We need to create a TM ‚ÄòN‚Äôthat simulates both M1 and M2. - Remember subset construction back in Automata theory? Well, this is similar to that. - Basically, we have two tapes, stuck to each other. The top tape is M1, and the bottom tape is M2. and ~Lùëé ùëñ ‚àà ùêø ùëè ùëñ ‚àà ‚ä¢ ùëé 1 ùëé 2 ùëé 3 ùëé 4 ‚ä¢ ùëè 1 ùëè 2 ùëè 3 ùëè 4 - But how do we know what position M1 and M2 are at? Currently, we can only select and together, where is the same number for both ‚Äòa‚Äôand ‚Äòb‚Äô, like or .ùëé ùëñ ùëè ùëñ ùëñ ùëé 1 , ùëè 1 ùëé 4 , ùëè 4 - That‚Äôs why we introduce a ‚Äòhat‚Äô: ‚ä¢ ùëé 1 ùëé 2 ùëé 3 ùëé 4 ‚ä¢ ùëè 1 ùëè 2 ùëè 3 ùëè 4 - Now we know what position M1 and M2 are on! For example, if our simulation of M1 is on the tape element and our simulation for M2 is on the tape element , we canùëé 1 ùëè 4 represent that on our tape like so: ‚ä¢ ùëé 1 ùëé 2 ùëé 3 ùëé 4 ‚ä¢ ùëè 1 ùëè 2 ùëè 3 ùëè 4 Computer Science / Software Engineering Notes Network - Now that our tape is all set up, all we have to do is set the instructions for the TM to follow: 1. Scans the tape to find a symbol with a hat in the \"upper\" section of the tape. Then, according to the transitions of M1, it performs M1‚Äôs move. 2. If M1 accepts then N accepts; 3. Scans the tape to find a symbol with a hat in the \"lower\" section of the tape. Then, according to the transitions of M2 , it performs M2‚Äôs move. 4. If M2 accepts then N rejects; 5. Go back to step 1 - The states work just like subset construction;we have tuples as states, in the form: - ( , )ùë† ùëò - Where is a state in M1 and is a state in M2.ùë† ùëò - To complete this formal proof, all we need now is a short statement to show that ‚ÄòN‚Äôis total: - ‚ÄúAny is either in or : So it is accepted by either M1 or M2. Soùë• ùêø Œ£ * ‚àí ùêø ùë• ‚àà ùêø ‚ãÉ Œ£ * ‚àí ùêø N will eventually accept or reject, thus N is total and so is recursive.‚Äùùêø - Just like that, the proof is done! - Lemma:If L is r.e and not recursive, ~L is not r.e - Let‚Äôs say TM ‚ÄòM1‚Äôaccepts ‚ÄòL‚Äô. If ‚ÄòL‚Äôis r.e and not recursive, then that means ‚ÄòM1‚Äô loops on some strings that are not in L (which are instead in ~L) - Let‚Äôs try to construct a TM ‚ÄòM2‚Äôthat accepts ~L. This Turing Machine would have to accept all strings that are not in L. - However, as stated before, ‚ÄòL‚Äôis not recursive, so ‚ÄòM1‚Äôloops on some strings that are not in L. Because ~L is every string that is not in L, M2 would have to loop on some strings that are in ~L, meaning that M2 can never fully accept ~L, and no Turing Machine can ever accept ~L, making it not recursively enumerable. (Semi) Decidable properties - First of all, let‚Äôs define what a p ro p erty is. A property of a string is a predicate that tells you something about the string. It is either true or false. - A few examples are: - The string has length 2 :{w | #w = 2} - There is a letter ‚Äòg‚Äôin the string :{w | ‚Äòg‚Äô‚àà w} - There is an even number of letters in the string :{w | #w mod 2 = 0} - The string contains the substring ‚Äújojo‚Äù :{w | ‚Äújojo‚Äù ‚àà w} - A property is decidable if all strings with that property form a language that is recursive. - For example:the property that the given string is equal to ‚Äúduwang‚Äù (because all finite languages are recursive) Computer Science / Software Engineering Notes Network - A property is semi-decidable if all strings with that property form a language that is recursively enumerable. - For example:the property that the given string is an encoding for a Turing Machine that halts (you can simulate the TM and accept if it halts, but if it loops, then your simulation will loop, making this recursively enumerable but not recursive). - Remember: - semi-decidable ‚áî recursively enumerable - decidable ‚áî recursive Universal Turing machines Multiple tapes - Are TMs with multiple tapes more powerful than TMs with only one tape? - No! Remember the section ‚ÄúRecursive and R.E languages‚Äù where we constructed a dual-tape TM out of a single-tape TM? - We can apply the same logic, but with any number of tapes. - If we can make a multi-tape TM out of a single-tape TM, that means multi-tape TMs are just as powerful as single-tape TMs. Simulating Turing machines - Turing machines are so powerful that they can simulate other Turing machines! Think of it like a virtual machine, like VMware or VirtualBox. - These Turing machines are called Universal Turing machines (UTM). Weird maths lan guage Plain En glish There exists a TM such thatùëà ùêø( ùëà) = { ùëÄ#ùë• | ùë• ‚àà ùêø( ùëÄ) } Where is an encoding of the TM ‚ÄòM‚Äô,followed byùëÄ#ùë• a ‚Äò#‚Äô,followed by an encoding of ‚Äòx‚Äôin M‚Äôs input alphabet. Like all Turing machines, they have a string input. Universal Turing machines only accept strings that fit this pattern: ùëÄ#ùë• ... which is an encoding of the TM ‚ÄòM‚Äô,a separating character (in this case #), and the encoding of the input string ‚Äòx‚Äô. First of all, the UTM checks if M#x is a valid encoding. If it isn‚Äôt,it‚Äôllreject it straight away. If the TM ‚ÄòM‚Äôaccepts ‚Äòx‚Äô,then the UTM will accept M#x If the TM ‚ÄòM‚Äôrejects ‚Äòx‚Äô,then the UTM will reject M#x The UTM does this by simulating M on ‚Äòx‚Äô.If it finds that M accepts, then the UTM will accept. If it finds that M rejects, then the UTM will reject. Computer Science / Software Engineering Notes Network - We use UTMs without even thinking about it, for example interpreters (for Java, Python, Ruby etc.) and virtual machines. Encoding Turing machines - So how do you actually encode a TM and an input into M#x? - Well, the details aren‚Äôt really important, but there‚Äôs a method from the Kozen book that converts all TM parameters into numbers, and then encodes them into one big number like this: - 0 ùëõ 1 0 ùëö 1 0 ùëò 1 0 ùë† 1 0 ùë° 1 0 ùëü 1 0 ùë¢ 1 0 ùë£ - where: - is the set of states{ 0 , 1 , 2 , 3 ,..., ùëõ ‚àí 1 } - is the tape alphabet where the first k numbers are the input{ 0 , 1 , 2 , 3 ,..., ùëö ‚àí 1 } alphabet - Start, accept and reject states are , and respectivelyùë† ùë° ùëü - Blank symbol is and the endmarker isùë¢ ùë£ - So you use the number of zeroes to determine what state / alphabet character the encoding is referring to. - To encode the transitions, this encoding could be followed up by: - 0 ùëù 1 0 ùëé 1 0 ùëû 1 0 ùëè 1 0 - ... which is the encoded form of , orŒ¥( ùëù, ùëé) = ( ùëû, ùëè, ùêø) - 0 ùëù 1 0 ùëé 1 0 ùëû 1 0 ùëè 1 0 0 - ... which is the encoded form of Œ¥( ùëù, ùëé) = ( ùëû, ùëè, ùëÖ) Constructing a UTM - First of all, a UTM checks if the input string M#x is of the right encoding. - The rules for encoding could be anything;there‚Äôs lots of ways to do it. One of which is defined in the previous section. - Second, we use three tapes to store: - Description of M - Contents of M‚Äôs tape - M‚Äôs current state and position on the tape - Third, the UTM will loop through the following steps: 1. looks at M‚Äôs current state and head position (tape 3); 2. reads the tape contents at the correct position (tape 2); 3. reads the relevant transition (tape 1); 4. simulates transition, updating tape, state and head position; 5. accepts if M accepts, rejects if M rejects. Computer Science / Software Engineering Notes Network Halting problem - The Halting problem goes like this: - C an yo u co me up with a TM that takes in an en co din g M#x an d accep t if M halts o n x an d rejects if M lo o p s o n x? - Or, more formally... - Is the set recursive?ùêªùëÉ = { ùëÄ#ùë• | ùëÄ ‚Ñéùëéùëôùë°ùë† ùëúùëõ ùë• } - No. Proof by contradiction - Here‚Äôs an intuitive proof before we move onto diagonalisation. - Ever heard of the Pinocchio paradox? - What happens when Pinocchio says ‚ÄúMy nose will grow?‚Äù - If it‚Äôs a lie, it won‚Äôt grow. But if it doesn‚Äôt grow, Pinocchio will be lying, so it will grow. But then he‚Äôs telling the truth, so it won‚Äôt grow, and we‚Äôre just going around in circles. - This proof is just like that. - Let‚Äôs say we have a TM called K that takes in an encoding M#x and accepts if it halts, and rejects if it loops. Basically, K solves the HP. - Let‚Äôs create another TM called P that takes in an encoding of M, and runs K on M#M. It goes into an infinite loop if K accepts, and halts if K rejects. - What if we run P on P? Will it loop or halt? - If it loops, that means P halts. But if P halts, that means it has to loop. We‚Äôre going around in circles again;there is a contradiction! - If that‚Äôs a bit too wordy for you, here‚Äôs some pseudocode showing this: P o n M : c a l l K o n M # M i f K s a y s h a l t - - > g o i n t o i n f i n i t e l o o p i f K s a y s d o e s n ' t h a l t - - > h a l t P ( P ) = ? - Really good computerphile video explaining it via contradiction: https://www.youtube.com/watch?v=macM_MtS_w4 Proof by diagonalisation - We can also show how P is going to behave via diagonalisation - We can define the output of our TM K, which is supposed to decide the HP, by constructing a table - If K exists then we will be able to list the halting behaviour of all TMs in this table Computer Science / Software Engineering Notes Network Œµ 0 1 00 01 10 11 ... ùëÄ Œµ H L L H L H L ùëÄ 0 L L H H L H L ùëÄ 1 H L L L L L L ùëÄ 0 0 ... L H H L H L H - Where the left column is all the possible Turing machines and the top row is all the possible inputs. - We can create the TM P by taking a diagonal snippet of this table: Œµ 0 1 00 01 10 11 ... ùëÄ Œµ H L L H L H L ùëÄ 0 L L H H L H L ùëÄ 1 H L L L L L L ùëÄ 0 0 ... L H H L H L H - Then, we flip all of the cells. Our TM P behaves like this: Œµ 0 1 00 01 10 11 ... ùëÉ L H H H H L H - This new TM P can‚Äôt fit anywhere on our original table - The TM K cannot exist because the TM P wasn‚Äôt anywhere on our table - Examples on how this table entry is equal to P: P on ( ):ùëÄ Œµ Call K on #ùëÄ Œµ œµ According to the table K returns H Therefore we will go into an infinite loop P on ( ):ùëÄ 0 Computer Science / Software Engineering Notes Network Call K on #ùëÄ 0 0 According to the table K returns L Therefore we will halt - So we‚Äôve proved that there‚Äôs no total Turing machine for this. However, the set HP is recursively enumerable. - Why? Because if the TM simulates M#x and it halts, the TM will accept this encoding. On all input strings that the TM accepts, the TM will accept it and not loop (because that‚Äôs the definition of an accepting string;it won‚Äôt loop). - So HP is recursively enumerable, but not recursive. That also means ~HP is not recursively enumerable (see proof in Recursive and R.E languages). - If ~HP is not recursively enumerable, there is no way of knowing if a Turing machine will loop on an input string or not. Decidable / Undecidable problems - A decidable problem is a decision problem for which there exists a total TM that decides it. - The total TM will accept for all yes/true instances and reject for all no/false instances of the problem. - Therefore, it will never loop for any input. - An un decidable problem is a decision problem for which there does not exist a total TM that decides it. - However, there might exist a TM that accepts yes/true instances and loops or rejects on no/false instances of the problem, making it semi-decidable. Computer Science / Software Engineering Notes Network - Ever heard of the membership problem? It goes like this: - ùëÄùëÉ = { ùëÄ#ùë• | ùë• ‚àà ùêø( ùëÄ) } - Basically, can you make a TM that decides if a TM M will accept an input x? - Sounds simple, right? Well, it‚Äôs actually impossible. It‚Äôs an undecidable problem. - Why is the membership problem undecidable? - Because if it was decidable, you‚Äôd be able to solve the Halting problem, which we know cannot be solved because of our proof from before! If we had a TM K that solved the membership problem, we could create a TM N that would solve the Halting problem. - Let‚Äôs construct a new TM N with input M#x: - Constructs a new TM M‚Äôwhich will change our existing machine M:All reject states become accept states, and all other states stay the same as before. Basically, M‚Äôwill accept iff M halts on x. - Simulates K on M‚Äô#x. If K accepts, then make N accept. If K rejects, then make N reject. - Here, N solves the Halting problem because it‚Äôll accept if M halts on x and reject if M loops on x. - We know that the Halting problem is undecidable, so that means the membership problem must be undecidable. Computer Science / Software Engineering Notes Network - By doing this, we‚Äôve shown that the membership problem is just as hard as the Halting problem, because we can use the membership problem to solve the Halting problem. - This is called a reduction, at which we will take a closer look soon. Reductions - ‚ÄúReduction‚Äù is an operation between two languages. - It is used to show the decidability of a language. - For example, in the previous section we ‚Äúreduced‚Äù the Halting problem to the membership problem, thus showing that the membership problem is undecidable (because we know the Halting problem is undecidable). - To represent this, we say that HP ‚â§ MP and, for our previous example, HP ‚â§ A. - Informally, a reduction is where you map one language to another language, so if you solve the second language with a TM, you can use that solution to solve the first language. - Like what we did with MP and HP;we reduced HP to MP, so if we solve MP, we can solve HP. - Formally, a function is computable when there exists a total TM ‚ÄòK‚Äôthatùëì: Œ£ * ‚Üí ‚àÜ * when started with on its tape, eventually halts with on its tape.ùë• ‚àà Œ£ * ùëì( ùë•) ‚àà ‚àÜ * - A reduction of to is a computable function s.t.ùê¥ ‚äÜ Œ£ * ùêµ ‚äÜ ‚àÜ * ùëì: Œ£ * ‚Üí ‚àÜ * ùë• ‚àà ùê¥ ‚áî ùëì( ùë•) ‚àà ùêµ - So a reduction function maps the inputs of one TM to another TM. - For example, remember the previous section when we showed how to solve the Halting problem if we had a TM K that could solve the membership problem by creating a TM N that could solve the Halting problem? - Here‚Äôs a diagram of what the TM N actually does: Computer Science / Software Engineering Notes Network - What N actually does is it takes in a Halting problem input, and uses the reduction function to turn it into a membership problem input. - That‚Äôs all reduction is! It‚Äôs just a function converting input of one problem into an equivalent other. - Let‚Äôs pluck out that reduction function and take a further look: - Let‚Äôs say we have our TM for the Halting problem N and our TM for the membership problem K again. - If we run N on M#x, it should yield the same result as running K on M‚Äô#x. - In summary, just think this: - If you see A ‚â§ B, then you can convert the problem A into the problem B. - Let‚Äôs look at some more examples Computer Science / Software Engineering Notes Network State Entry Problem (SEP) Decide whether a TM M‚Äôenters a given state q on input x Assume that we already have a TM K that decides the SEP. Create a TM N which decides the HP using a reduction from the HP to the SEP. N on inputs M and x (e.g. as an encoding M#x): 1. Construct a new TM M‚Äôfrom M a. Add a new state q which is not in M b. From all halting states add a new transition to q c. Make all halting states non-halting states 2. Simulate K on inputs M', q, x (e.g. as an encoding M‚Äô#q#x) 3. Accept if K accepts, reject if K rejects Since we know that the HP is undecidable, the SEP must also be undecidable Blank Tape Halting Problem (BTHP) Decide whether a TM M‚Äôhalts on the blank tape (no input). Decide whether a TM M‚Äôhalts on input epsilon. Assume that we already have a TM K that decides the BTHP. Create a TM N which decides the HP using a reduction from the HP to the BTHP. N on inputs M and x (e.g. as an encoding M#x): 1. Construct a new TM M‚Äôfrom M a. Ignore any input b. Write x on the blank tape and reset the tape head Computer Science / Software Engineering Notes Network c. Execute M with x on the tape and return the result 2. Simulate K on input M‚Äô 3. Accept if K accepts, reject if K rejects If you are confused about M‚Äô: ‚óè M‚Äôis a special version of M ‚óè M‚Äôhas the same instructions as M, however, it has some instructions prepended to the other instructions ‚óã We will ignore any input given to M‚Äô ‚óã We need to write x on the tape and reset the tape head to the start ‚óè So all in all we have a TM M‚Äôwhich has x hard coded in its instructions Since we know that the HP is undecidable, the BTHP must also be undecidable Emptiness Problem (EP) Semi-decide whether the language of a TM M‚Äôis the empty set Assume that we already have a TM K that semi-decides the EP. Create a TM N which semi-decides the LP (complement of HP) using a reduction from the LP to the EP. Computer Science / Software Engineering Notes Network N on inputs M and x (e.g. as an encoding M#x): 1. Construct a new TM M‚Äôfrom M a. Ignore any input b. Write x on the blank tape and reset the tape head c. Execute M with x on the tape d. Accept if the execution ends 2. Simulate K on input M‚Äô 3. Accept if K accepts If you are confused about M‚Äô: ‚óè Similarly to the last example M‚Äôwill ignore any input and write x to the tape, so again our TM M‚Äôcomes with the x hard-coded ‚óè Now, if M loops on x, then M‚Äôwill also loop and never accept. Therefore, L(M‚Äô) is the empty set. ‚óè If M doesn‚Äôt loop on x, then M‚Äôwill accept and its language is clearly not equal to the empty set Since we know that the LP is not semi-decidable, the EP cannot be semi-decidable as well. Same Language Problem (SLP) Decide whether TMs M1 and M2 accept the same language. Assume that we already have a TM K that decides the SLP. Create a TM N which decides the HP using a reduction from HP to SLP. N on inputs M and x (e.g. as an encoding M#x): Computer Science / Software Engineering Notes Network 1. Construct a new TM M1: a. Simulate M on x b. If simulation halts accept (no matter what the input is) 2. Construct a new TM M2: a. Accept (no matter what the input is) 3. Simulate K on inputs M1 and M2 4. Accept if K accepts, reject if K rejects This works because ‚óè M2 always accepts everything, so its language is Œ£ * ‚óè M1 either accepts nothing or everything ‚óã If the simulation halts, i.e. if M halts on x, it will accept everything, so its language is Œ£ * ‚óã If the simulation doesn‚Äôt halt, then it will loop and run forever. Therefore its language is the empty set. ‚óè We can see that the language of M1 and M2 is the same if and only if M halts on x ‚óè So when we ask K if M1 and M2 have the same language it will accept if and only if M halts on x and reject otherwise ‚óè We can use this answer to solve the HP, which is a contradiction because we know that the HP is undecidable Since we know that the HP is not decidable, the SLP must be undecidable as well. Properties of reductions - If A ‚â§ B and B is r.e. then so is A. Equivalently, if A is not r.e. then B is not r.e. - An example of this reduction rule is MP ‚â§ HP. - If A ‚â§ B, then there‚Äôs a reduction function from A to B:ùëì: ùê¥ ‚Üí ùêµ - If B is r.e, then there exists a TM ‚ÄòM‚Äôthat accepts B. - To prove A is r.e, we just need to define a TM that accepts A. - This is that TM ‚ÄòN‚Äô: - On an input ‚Äòx‚Äô, compute f(x) - Run ‚ÄòM‚Äôon f(x) - If that accepts, make N accept - If that rejects, make N reject - If A is not r.e, then there is no TM that accepts it. - Let‚Äôs just say a TM exists for B, called ‚ÄòM‚Äô. - Using the same TM we defined before (N), we can now define a TM to accept A, if the TM ‚ÄòM‚Äôactually exists. - This is a contradiction, so a TM for B cannot exist if A is not r.e., and therefore B is not r.e. Computer Science / Software Engineering Notes Network - If A ‚â§ B and B is recursive then so is A. Equivalently, if A isn‚Äôt recursive then neither is B - It‚Äôs the same proof as before, except now, the TM ‚ÄòM‚Äôhalts on all inputs. - If we follow through the same steps as before, our TM ‚ÄòN‚Äôwill not halt on any inputs either, because it uses ‚ÄòM‚Äô. This means that A is recursive when B is. - The same goes for B not being recursive if A isn‚Äôt. - If A is not recursive, then it‚Äôs either r.e or not r.e. We‚Äôve already proved the case for when A is not r.e, so let‚Äôs prove the case for when A is r.e. - Let‚Äôs say that B is recursive and has a TM ‚ÄòM‚Äôthat halts on all inputs. - If we have ‚ÄòM‚Äô, we can create a total TM ‚ÄòN‚Äôthat halts on all inputs and determines A. - Therefore, B cannot be recursive if A is not recursive. Rice‚Äôs theorem - Does Theory of Computing depress you? - Well, this theorem is about to make it worse. - Rice‚Äôs theorem states that every non-trivial property of r.e sets is undecidable. - So, what does this actually mean? - Every language with a non-trivial property is constructed by a Turing Machine which loops. - A r.e set is actually the same as a TM, but we‚Äôre just referring to a TM by its language. By saying r.e set instead of TM, we ignore things like the TM‚Äôs states, tape etc. and we only focus on the language it recognises. - A property of an r.e set is a property of the TM‚Äôs language. It‚Äôs a predicate that tells you about what the TM recognises. - A non-trivial property is a property that isn‚Äôt always true or always false. - So what Rice‚Äôs theorem means is that if you partition the set of all r.e sets into two using some condition, both partitions will be undecidable. - Let‚Äôs visualise this. We have the set of all r.e sets: Computer Science / Software Engineering Notes Network - What if I were to split this set into two, using some property? - Let‚Äôs say the property is this:‚Äúthe r.e set must contain the empty string‚Äù. - Now we know our sets aren‚Äôt recursive anymore! This is due to Rice‚Äôs theorem. - Why are they not recursive? - Remember the ‚ÄúDecidable / Undecidable problems‚Äù section where we proved that it‚Äôs impossible to have a total TM that tells if M accepts the empty string? - It doesn‚Äôt stop at accepting the empty string. Any predicate you can think of that splits the set of all r.e sets are undecidable: - Accepts any string at all? - Accepts every string? - Accepts a given finite language? - Accepts a given regular language? - Accepts a context-free language? - Accepts a recursive language? - Accepts a language with the word ‚Äúdavidtyoember‚Äù (üòç) in it? - You may be thinking ‚ÄúWhy keep using the term ‚Äòr.e set‚Äô? Why not just say any non-trivial property of a Turing machine is undecidable?‚Äù - There‚Äôs a reason why it‚Äôs only a property of a TM‚Äôs language and not a property of the TM itself. Computer Science / Software Engineering Notes Network - The following are properties of TMs, but not r.e sets: - M has less than 400 states (this isn‚Äôt a property of an r.e set because 1. it queries nothing about the language and 2. you could find two TMs that recognise the same set, but one having less than 400 states and one having more than or equal to 400 states) - M halts on all inputs (this isn‚Äôt a property of an r.e set because 1. it, again, queries nothing about the language and 2. you could have two TMs that recognise the same set, one halting on all inputs and one which doesn‚Äôt) - So if the concept of r.e sets is a little weird to you, then don‚Äôt worry;just think about it in terms of TMs and their languages. Instead of a property of a r.e set, think of a property of a TM‚Äôs language. - Sure, because of Rice‚Äôs theorem, there are lots of properties that are undecidable, like: - membership problem for TMs:does a given TM accept a given string? - emptiness problem for TMs:does a given TM accept any strings at all? - equivalence problem for TMs:given two TMs, do they accept the same language? - ... but there are properties that are decidable: - membership problem for DFAs/NFAs:does a given DFA/NFA accept a given string? - emptiness problem for DFAs/NFAs: does a given DFA/NFA accept any strings at all? - equivalence problem for DFAs:given two DFAs, do they accept the same language? - membership problem for CFGs - emptiness problem for CFGs - They‚Äôre all decidable because simulations of NFAs, DFAs and CFGs are all decidable;you can‚Äôt loop with any of those because with each transition, a bit of the string is being spent. - If Rice‚Äôs theorem depressed you, don‚Äôt worry. You‚Äôve come this far, and there‚Äôs only one topic left to go. You can do it! I believe in you! Computer Science / Software Engineering Notes Network Complexity theory - We know that Turing machines and algorithms are equivalent. However, how do we measure and compare the complexity of algorithms? - Complexity theory is concerned with measuring how the time/space required by an algorithm/problem increases as the input gets larger - You should remember Big-O notation from Algorithmics (I hope). - In this module, we use Big-O and Big-œ¥, and we use the classes P and NP to categorise problems. Big-O and Big-œ¥ - To define complexity in an algorithm or a problem, we use Big-O and Big-œ¥ notation. - The complexity of a problem is the complexity of the best algorithm that currently exists for this problem. Big-œ¥ - In fo rmally ( En glish) : - If an algorithm is for some equation , that means that theùëì( ùëõ) Œò( ùëî( ùëõ) ) ùëî( ùëõ) algorithm‚Äôs complexity scales with and can only scale by , it can doùëî( ùëõ) ùëî( ùëõ) no better than that. - For example, the average-case complexity of quick sort is .Œò( ùëõ ùëôùëúùëî( ùëõ) ) - If a problem is for some equation , that means there existsùëì( ùëõ) Œò( ùëî( ùëõ) ) ùëî( ùëõ) no algorithm that can solve the problem at a complexity better than .ùëì( ùëõ) ùëî( ùëõ) - In other words, it means is the complexity of the best knownŒò( ùëî( ùëõ) ) algorithm for .ùëì( ùëõ) - For example, the sorting problem has the complexity because noŒò( ùëõ ùëôùëúùëî ùëõ) sorting algorithm exists that does better than (except sleepsort, butùëõ ùëôùëúùëî ùëõ that doesn‚Äôt count). - Fo rmally ( weird maths lan guage) : - We say that is for some if there exist reals:ùëì( ùëõ) Œò( ùëî( ùëõ) ) ùëî( ùëõ) - c > 0 - d > 0 - integer M > 0 - with - for all .ùëëùëî( ùëõ) ‚â§ ùëì( ùëõ) ‚â§ ùëêùëî( ùëõ) ùëõ ‚â• ùëÄ - We say that and have the same rate of growth.ùëì( ùëõ) ùëî( ùëõ) Big-O - In fo rmally ( En glish) : Computer Science / Software Engineering Notes Network - If an algorithm is for some equation , that means that theùëì( ùëõ) ùëÇ( ùëî( ùëõ) ) ùëî( ùëõ) algorithm‚Äôs complexity scales, at worst, with , but it could do better inùëî( ùëõ) certain cases. - For example, the worst-case complexity of bubble sort is .ùëÇ( ùëõ 2 ) - If a problem is for some equation , that means our bestùëì( ùëõ) ùëÇ( ùëî( ùëõ) ) ùëî( ùëõ) algorithm can solve this problem with complexity . There might exist anùëî( ùëõ) algorithm that does better, but we haven‚Äôt discovered it yet. - In other words, it means is the complexity of the best knownùëÇ( ùëî( ùëõ) ) algorithm for .ùëì( ùëõ) - For example, if we had an algorithm that had a worst-case of , thenùëÇ( ùëõ ùëôùëúùëî ùëõ) that means the algorithm will, at worst, perform , but may performùëõ ùëôùëúùëî ùëõ better on average-case or best-case. - Fo rmally ( weird maths lan guage) : - We say that is for another function if there exist reals:ùëì( ùëõ) ùëÇ( ùëî( ùëõ) ) ùëî( ùëõ) - c > 0 - integer M > 0 - with - for all .ùëì( ùëõ) ‚â§ ùëêùëî( ùëõ) ùëõ > ùëÄ - We say that g(n) is an asymptotic upper bound for f(n) The class P ‚óè The class P is the set of all decision problems that can be solved by a deterministic Turing machine in polynomial time. ‚óã Decision problem ‚Üí For all inputs we receive a ‚Äúyes‚Äù or ‚Äúno‚Äù answer ‚óã Deterministic Turing machine ‚Üí A Turing machine that cannot make any choices in terms of the next move ‚ñ† This is the model of a Turing machine that we have seen so far ‚ñ† We will see a non-deterministic Turing machine later ‚óã Solved in polynomial time ‚Üí The problem is feasible ‚óè Some examples that are in P are ‚óã Searching an unordered list ‚ñ† Use sequential search, which is ùëÇ( ùëõ) ‚óã Searching an ordered list ‚ñ† Use binary search, which is ùëÇ( ùëôùëúùëî( ùëõ) ) ‚óã Testing whether a list is sorted ‚ñ† Go through the list sequentially and compare each element with the element before, which is Œò( ùëõ) ‚óè An example that is not in P is:Given a first-order statement about non-negative integer variables (with only symbols 0, 1, +, = and logical operators allowed), is it true? Computer Science / Software Engineering Notes Network ‚óã We are going to look at some equation with non-negative integer variables, i.e. variables that can be assigned natural numbers ‚óã On the left and right hand side of the equation we can only ‚ñ† use the variables ‚ñ† use the ‚Äú+‚Äù operation ‚ñ† use the numbers ‚Äú0‚Äù, ‚Äú1‚Äù ‚óã We will use quantifiers to form the first-order logic statement, which is going to be either true or false ‚ñ† We can use the quantifiers ‚Äúfor all‚Äù and/or ‚Äúthere exists‚Äù ‚ñ† We must define one quantifier for each variable ‚óã Problem instances are: ‚ñ† ‚àÄùë•‚àÉùë¶( ùë• + ùë¶ = ùë• + 1 ) ‚óè For all x there exists y such that the equation holds ‚ñ† ‚àÉùë•‚àÄùë¶‚àÉùëß( ùë• + ùëß = ùë• + ùë¶ + ùëß) ‚óè There exists x then for all y there exists z such that the equation holds ‚óã This problem is known to be decidable, but infeasible ‚ñ† This means that we can always say whether this equation holds or not ‚ñ† However, this cannot be done in polynomial time with a deterministic machine Feasible and infeasible problems ‚óè A problem is said to be feasible if it has an algorithm with time complexity some‚â§ polynomial f(n). ‚óã Examples: , , ,Œò( ùëõ) Œò( ùëõ ùëôùëúùëî( ùëõ) ) Œò( ùëõ) Œò( ùëõ 6 ) ‚óã These are problems with polynomial time complexity ‚óè Otherwise, a problem that can be solved in finite time but has no polynomial time algorithm is said to be infeasible ‚óã Examples: , ,Œò( 2 ùëõ ) Œò( 1 . 3 ùëõ ) Œò( ùëõ!) ‚óã These are problems with complexity greater than polynomial time (exponential and factorial time complexity) Decision problems ‚óè A computational problem is called a decision problem if the output for any problem instance is either ‚Äúyes‚Äù or ‚Äúno‚Äù. ‚óã A problem instance is a specific input for a problem ‚óã For example, the numbers ‚Äú1‚Äù, ‚Äú4‚Äù, ‚Äú5‚Äù, ‚Äú8‚Äù are problem instances for an algorithm that determines whether a number is an even number or not ‚óã This algorithm is a decision problem because given a number this algorithm can say ‚Äúyes this number is even‚Äù or ‚Äúno this number is not even‚Äù ‚óè We can classify the problem instances into positive/‚Äùyes‚Äù instances and negative/‚Äùno‚Äù instances Computer Science / Software Engineering Notes Network ‚óã For example, ‚Äú4‚Äù and ‚Äú8‚Äù are positive instances and ‚Äú1‚Äù and ‚Äú5‚Äù are negative instances of the ‚Äúis this number even‚Äù problem. ‚óè The ‚Äúyes‚Äù instances are forming a language. Therefore, solving the decision problem is the same as deciding this language ‚óã For example, the positive instances of the ‚Äúis this number even‚Äù problem form the language of all even numbers. ‚óã ùêø ùëíùë£ùëíùëõ ùëõùë¢ùëöùëèùëíùëüùë† = { ..., ‚àí 4 , ‚àí 2 , 0 , 2 , 4 , ...} The PATH problem ‚óè Let PATH be the following decision problem:Given a directed graph, does there exist a directed path connecting two given nodes? ‚óè For example, given the following graph: ‚óè Does there exist a path from 1 to 6? ‚óã Yes, 1 ‚Üí 2 ‚Üí 4 ‚Üí 6 ‚óè Does there exist a path from 3 to 4? ‚óã Yes, 3 ‚Üí 5 ‚Üí 4 ‚óè Does there exist a path from 5 to 1? ‚óã No, from 5 we can only reach 4 and 6 ‚óè Does there exist a path from 1 to 3? ‚óã No, from 1 we can reach all nodes but 3 ‚óè A polynomial time algorithm for PATH is the following: ‚óã On input (G, s, t), where G is the graph, s is the start node and t is the goal node ‚óã Place a mark on node s ‚óã Repeat the following until no additional nodes are marked ‚ñ† For each edge from node a to b of G, if a is marked then also mark b Computer Science / Software Engineering Notes Network ‚óã If t is marked then accept, otherwise reject ‚óè This algorithm runs in polynomial time ‚óã The graph has n nodes and m edges ‚óã For each node n we have to mark and check at most m other nodes which are directly connected (via an edge) to n ‚óã Therefore, this algorithm runs in timeùëÇ( ùëõ * ùëö) The HAMPATH problem ‚óè Let HAMPATH be the following decision problem:Given a directed graph, does there exist a directed path connecting two given nodes that goes through each node exactly once? ‚óè This is an extension of PATH:We do not only have to find a path from one node to another node - the path also needs to go through each node exactly once. ‚óè The best known algorithm for this problem is exponential, however, we do not know if there exists a polynomial time algorithm. ‚óè Given a candidate for a HAMPATH, we can verify it in polynomial time. Regular and context-free languages ‚óè Every regular language is in P ‚óã If a language is regular then there exists a DFA that accepts the language ‚óã A Turing machine can simulate a DFA ‚óã It will have the input string and a symbol that marks the end of the string (end marker) on the tape ‚óã It will always move right after consuming a symbol and change state in the same way as the DFA would change state ‚óã When it reaches the end marker and it is in a state that corresponds to the accept state of the DFA it will accept, otherwise it will reject ‚óã Therefore, the Turing machine will execute exactly n steps (where n is the length of the input string) so it‚Äôs time complexity is Œò( ùëõ) ‚óè Every context-free language is in P ‚óã For every context-free language there exists a corresponding context-free grammar. ‚óã For every context-free grammar, there exists another grammar which accepts the same language in Chomsky normal form. ‚óã Grammars in Chomsky can be parsed using the CYK (Cocke-Younger-Kasami) algorithm (citation), which parses in cubic time, which is polynomial. ‚óã One could create a Turing machine which applies the CYK algorithm to a given context-free grammar, and that Turing machine would accept said context-free language in cubic time. Computer Science / Software Engineering Notes Network The class NP - The class NP is the set of all decision problems that can be solved by a non-deterministic Turing machine in polynomial time - NP stands for non-deterministic polynomial - Anything in P is also in NP. If a problem can be solved in polynomial time by a deterministic machine, then also by a non-deterministic one. - Let‚Äôs look at some NP problems which are believed not to be in P Non-deterministic Turing machine - A non-deterministic TM is of the same form as a deterministic TM: - ùëÄ = ( ùëÑ, Œ£, Œì, ‚ä¢, ‚äî, Œ¥, ùë†, ùë°, ùëü) - However, the transition function is defined differently - is the transition functionŒ¥: ( ùëÑ ‚àí { ùë°, ùëü} ) √ó Œì ‚ÜíùëÉ( ùëÑ √ó Œì √ó { ùêø, ùëÖ} ) - Note that the output of the function is now a power set of configurations - This means that given a configuration, there are many possible other configurations in which the TM can be after making the transition - Therefore, the Turing machine becomes non-deterministic. - We can think of the non-deterministic TM as a TM that makes all possible transitions from a given configuration in parallel - Therefore, the computation of a non-deterministic TM is a tree, whose branches are all traversed in parallel - In contrast, the computation of a deterministic TM is a linear path, as there is exactly one configuration after making a transition. - Non-deterministic TMs have the same expressibility as deterministic TMs. We can simulate a non-deterministic TM with a multi-tape deterministic TM. - The deterministic TM has four tapes: - One to remember the input. - One to simulate the current state of the branch. - One to remember the branch being simulated on. - One to remember the branches simulated. - The deterministic TM accepts an input when one of the branches accepts, and rejects otherwise. - A non-deterministic TM is a decider when all its branches halt on all inputs, similar to a total TM. Computer Science / Software Engineering Notes Network - Since we now have a tree of configurations, we need to re-think the condition when the non-deterministic TM accepts/rejects. - Reminder:A deterministic TM - accepts/rejects as soon as it reaches a accept/reject configuration - loops if it never reaches such a configuration - A non-deterministic TM - accepts if so me branch of the computation leads to the accept state - rejects if all branches of the computation lead to the reject state - loops if none of those two conditions are ever met - For example, the tree can be infinite and without any accept state - If all branches halt on all inputs, i.e. if the computation tree is finite, the non-deterministic TM is called a decider - This is similar to a deterministic total TM, which always halts on any input - The decider accepts an input if there exists a sequence of choices, where at least one ends in the accepting state. - Otherwise all choices will end in the reject state and the decider will reject the input - Non-deterministic TMs are n o t mo re p o werful than deterministic TMs as we are going to see shortly - For any non-deterministic TM there exists a deterministic TM accepting the same language - A non-deterministic TM N can be simulated by a 3-tape deterministic TM D - D will try all branches of N‚Äôs computation using breadth first search - If we use depth first search our simulation can get stuck in an infinite loop in case of an infinite tree - There might exist an accept state on another branch which we are unable to reach because of the infinite loop - In order to avoid this we have to use breadth first search - The 3 tapes are used as follows Computer Science / Software Engineering Notes Network - One tape stores the input - One tape used to simulate a branch up to a given depth - One tape used to remember the branch being simulated - If D ever finds the accept state in the tree it will accept. Otherwise D will loop, or reject if all branches evaluate to a reject state. - For any non-deterministic TM that halts on all branches (= decider) there exists a total TM deciding the same language - We can modify the proof from above such that if N halts on all branches then D halts - Therefore, we will introduce a fourth tape where we remember the branches that halt. We are not going to explore these branches again - If there is no branch left to explore, reject - Therefore, we can conclude that any non-deterministic TM has an equivalent deterministic TM Time complexity of Turing machines - Let‚Äôs think about the time complexity of Turing machines - First, we will define the following: - The size of a problem instance = the number of symbols on the input tape - The algorithm cost (measure of time taken) = number of steps the Turing machine takes - The time complexity of a decider is a function f(n), where f(n) is the maximum number of steps the machine takes on any branch of its computation, on any input of length n. - In other words, to determine the time complexity of a decider, we are going to take a look at the computation tree for some input of length n Computer Science / Software Engineering Notes Network - The time complexity is equal to the depth of this tree - Every time multi-tape deterministic TM has an equivalent timeùë°( ùëõ) ùëÇ( ùë° 2 ( ùëõ) ) single-tape deterministic TM - If a multi-tape TM runs in time, it can only use tape cells on eachùë°( ùëõ) ùë°( ùëõ) tape - We can construct a single-tape TM that simulates the multi-tape TM - Before simulating a single step of the multi-tape TM we need to find the position of the tape heads. These positions will be marked using special symbols on the tape. - Therefore, we are going to scan the tape from left to right, which takes an extra steps. The tape heads might be anywhere on the tape butùëÇ( ùë°( ùëõ) ) cannot be beyond the tape cells, which is why we use big O notationùë°( ùëõ) here. - All in all, we have steps to simulate, and for each step we can find theùë°( ùëõ) tape heads in time, so all in all we require time for theùëÇ( ùë°( ùëõ) ) ùëÇ( ùë° 2 ( ùëõ) ) whole simulation. - The following is an example of a single-tape TM simulating a 3-tape TM. The position of the heads is marked with a ‚Äú^‚Äù symbol: ‚ä¢ ‚ä¢ a bÃÇ c d e ‚ä¢ h i j kÃÇ l ‚ä¢ vÃÇ w x y z - Every time non-deterministic Turing machine has an equivalent timeùë°( ùëõ) 2 ùëÇ( ùë°( ùëõ) ) deterministic Turing machine - Each branch of a time non-deterministic TM N has length of at most .ùë°( ùëõ) ùë°( ùëõ) Computer Science / Software Engineering Notes Network - Remember:the time complexity of a non-deterministic TM is defined as the depth of the computation tree - Therefore, the length of the longest branch is equal to the time complexity - Each node in the computation tree of N can have up to children.ùëè - This is also known as the branching factor of the tree. - Therefore, there are at most leaves, and nodes in theùëè ùë°( ùëõ) ùëÇ( ùëè ùë°( ùëõ) ) computation tree of the non-deterministic TM N - A tree with branching factor and depth cannot have more thanùëè ùëë ùëè ùëë nodes - A tree with branching factor and depth cannot have more thanùëè ùëë leaves. Furthermore, it also cannot have more than leaves,ùëè ùëë‚àí 1 ùëè ùëë which is a less restrictive statement. - We can construct a multi tape deterministic TM to simulate N. This will take time.ùëÇ( ùë°( ùëõ) *ùëè ùë°( ùëõ) ) - We need to simulate the path from the root to each of the leaves. Since we have at most leaves we need to simulate at mostùëè ùë°( ùëõ) paths.ùëè ùë°( ùëõ) - Each of the paths we are going to simulate is no longer than ùë°( ùëõ) - Therefore the simulation will take no longer than timeùë°( ùëõ) *ùëè ùë°( ùëõ) - is (see tutorial 8 question 2)ùë°( ùëõ) * ùëè ùë°( ùëõ) 2 ùëÇ( ùë°( ùëõ) ) - The big O notation is an upper bound and hides a constant ,ùëê therefore we have to show that there exists some andùëê > 0 ùëÄ ‚àà ‚Ñï such that for allùë°( ùëõ) * ùëè ùë°( ùëõ) ‚â§ 2 ùëê*( ùë°( ùëõ) ) ùëõ ‚â• ùëÄ - The proof for this is just below: Pro o f fro m the tuto rial that I do n ‚Äôt un derstan d ùë°( ùëõ) ‚â§ 2 ùë°( ùëõ) ùë°( ùëõ) * ùëè ùë°( ùëõ) ‚â§ 2 ùë°( ùëõ) * ùëè ùë°( ùëõ) = ( 2 ùëè) ùë°( ùëõ) ‚â§ ( 2 ùëè ) ùë°( ùëõ) = 2 ùëè*ùë°( ùëõ) For all , therefore andùëõ ‚â• 1 ùëê = ùëè ùëÄ = 1 My p ro o f that I fully un derstan d Computer Science / Software Engineering Notes Network ùë°( ùëõ) ‚â§ 2 ùë°( ùëõ) ùë°( ùëõ) * ùëè ùë°( ùëõ) ‚â§ 2 ùë°( ùëõ) * ùëè ùë°( ùëõ) ùë°( ùëõ) * ùëè ùë°( ùëõ) ‚â§ 2 ùë°( ùëõ) * ( 2 ùëôùëúùëî 2 ( ùëè) ) ùë°( ùëõ) ùë°( ùëõ) * ùëè ùë°( ùëõ) ‚â§ 2 ùë°( ùëõ) * 2 ùëôùëúùëî 2 ( ùëè) √óùë°( ùëõ) ùë°( ùëõ) * ùëè ùë°( ùëõ) ‚â§ 2 ùëôùëúùëî 2 ( ùëè) √óùë°( ùëõ) + ùë°( ùëõ) ùë°( ùëõ) * ùëè ùë°( ùëõ) ‚â§ 2 ( ùëôùëúùëî 2 ( ùëè) + 1 ) √ó ùë°( ùëõ) ùë°( ùëõ) * ùëè ùë°( ùëõ) = 2 ùëÇ( ùë°( ùëõ) ) For all , therefore andùëõ ‚â• 1 ùëê = ùëôùëúùëî 2 ( ùëè) + 1 ùëÄ = 1 The SAT problem - SAT:Boolean satisfiability - Given a boolean expression, does there exist an assignment of true and false (or 0s and 1s) to all variables such that the formula is satisfied? - Example:( ùë• ‚à® ùë¶ ‚à® ¬¨ùëß) ‚àß ( ùë§ ‚à® ¬¨ùëß) ‚àß ( ¬¨ùë§ ‚à® ùë•) - Does there exist an assignment for the variables such that theùë§, ùë•, ùë¶, ùëß formula is satisfied? - SAT is in NP:We can non-deterministically generate all possible assignments to the variables and then check if the formula is satisfied. - For each variable, we have two options:It can be either true or false - If we want to solve this problem in a deterministic way, we have to try out either true or false for each of the variables - Therefore, it will take time where is the number of variables2 ùëõ ùëõ - However, a non-deterministic machine has the power to always guess the right assignment for each of the variable - For instance, if we have three variables there are 8 differentùë•, ùë¶, ùëß assignments for these variables - The non-deterministic machine will always pick the right assignment for each of the variables before moving on to the next variable Computer Science / Software Engineering Notes Network - We can visualise this in a computation tree. The non-deterministic machine will instantly pick the right path from the root to the leaf which makes the formula true (if such an assignment exists) - Therefore, it can solve the problem in linear time (linear in the number of variables) - - We don‚Äôt know if SAT is in P because we currently do not have any polynomial time algorithm for it. However, no one has been able to prove that there isn‚Äôt one. The HAMPATH problem - HAMPATH:Given a directed graph, does there exist a directed path connecting two given nodes that goes through each node exactly once? - We can non-deterministically generate all sequences of nodes of length equal to the size of the graph, and then check the following: - No repetitions are found in the sequence - The start and end of the sequence coincide with the required nodes - The sequences defines a directed path through the graph - We don‚Äôt know if HAMPATH is in P The TSP(D) problem - TSP(D) refers to the Travelling Salesperson Problem. Computer Science / Software Engineering Notes Network - For this problem, you have a graph with weighted edges and an input D. - Is there a route leading all around the graph and back to the start with a total distance at most D? - This problem is in NP because the TM would have to ‚Äòguess‚Äôthe order of cities to check in, then add up the distances to see if it‚Äôs at most D. - We don‚Äôt know if TSP(D) is in P. The 3COL problem - 3COL:3-colourability - Given a graph G, is it possible to colour all the vertices with one of three available colours such that no two adjacent vertices are the same colour? - Here is an example of a solution: - This problem is in NP because we can non-deterministically guess the colour of each vertex;our computation splits into 3 branches of ‚Äúis this node red?‚Äù, ‚Äúis this node blue?‚Äù, or ‚Äúis this node green?‚Äù. - We don‚Äôt know if 3COL is in P. NP = P? - This is one of the biggest problems in computer science. Is NP equal for P? What if every problem in NP has a P algorithm, but we just haven‚Äôt discovered them all yet? - I don‚Äôt know. - But if P does equal NP, that means: - P = NP = NP-complete - To prove that P = NP-complete, we need to show that all problems in NP can reduce to all problems in P in polynomial time. - So we‚Äôll have some arbitrary problem X in P and some arbitrary problem Y in NP. - We will then reduce Y to X. When we do that, we‚Äôll have proved that all NP problems reduce to all P problems and that P = NP-complete, hence P = NP = NP-complete. - If Y is in NP, that means it‚Äôs in P also (because P = NP). Computer Science / Software Engineering Notes Network - This proof only works if the language of X is non-trivial, meaning it‚Äôs not the empty set or sigma star! - If X is not trivial, that means there exists an input such that X will accept it,ùëñ 1 and an input such that X will reject it.ùëñ 2 - Our reduction formula will remember this, and simulate an input y on Y. If Y accepts, then the formula returns . If Y rejects, then the formula returns .ùëñ 1 ùëñ 2 - This is computable in polynomial time and maps yes/no instances of Y to yes/no instances of X, hence proving that if P = NP, then P = NP = NP-complete. - P ‚äÇ NP-hard - Following from the P = NP = NP-complete rule we proved earlier... - Some NP-hard problems are NP-complete. - If P = NP-complete, that means some NP-hard problems are also in P. - Therefore, P is a strict subset of NP-hard. - Here is what the problem sets will look like if P != NP and P = NP (just remember that trivial problems are in P and NP, just not NP-complete!): Presburger arithmetic - Here‚Äôs a problem that‚Äôs so hard that it‚Äôs not even in NP. However, it is decidable (possible to solve). - It goes like this: - You have a set of variables, each with either a ‚Äòfor all‚Äôfor ‚Äòthere exists‚Äô. - There is also a formula that links up all the variables together. - Is the formula true? - If that explanation didn‚Äôt make much sense, the problems look like this: Computer Science / Software Engineering Notes Network - The question is:do these formulae hold? - This is so hard that this is at least doubly exponential, which is !ùëé( ùëè ùë•) NP-Completeness Polynomial time reduction - Remember reduction with Turing machines? - We can do the same here;we can reduce a problem to another problem. - If we can reduce problem A to problem B, then any polynomial algorithm for B also applies for A, right? - Almost! The reduction needs to be in polynomial time as well. This is called a polynomial time reduction. - So to solve problem A, we need to reduce it to B in polynomial time, then solve B in polynomial time. Polynomial + polynomial = polynomial, so solving A would also be in polynomial time. - If you‚Äôre a visual learner, maybe this diagram will help (it goes from left to right): - Polynomial time reduction is written like this: - ùê¥ ‚â§ ùëÉ ùêµ - More formally, it‚Äôs defined like this: - A function is polynomial time computable if there exists a polynomial timeùëì: Œ£ * ‚Üí ‚àÜ * deterministic Turing machine that halts on each input with just on itsùë§ ‚àà Œ£ * ùëì( ùë§) tape. - From this, we can conclude that if A reduces to B in polynomial time, and B is in P, then A is in P. - Additionally, if A reduces to B in polynomial time, and A is not in P, then B is not in P. 3COL to SAT - We can reduce 3COL (3-colourability) to SAT (boolean satisfiability). Computer Science / Software Engineering Notes Network - We can do this by: - for each node ‚Äòx‚Äôin 3COL... - ... create 3 variables in SAT, rx (is ‚Äòx‚Äôred?), gx (is ‚Äòx‚Äôgreen?), and bx (is ‚Äòx‚Äô blue?). - After we‚Äôve created our variables, we need to define three expressions: 1. For each vertex ‚Äòx‚Äô, the expression: ( r x O R g x O R b x ) must be true (each vertex must be assigned a colour) 2. For each vertex ‚Äòx‚Äô, the expression: ( ! ( r x A N D g x ) A N D ! ( r x A N D b x ) A N D ! ( b x A N D g x ) ) must be true (each vertex may only have ONE colour) 3. For each edge ‚Äòx y‚Äô, the expression:‚Üí ! ( r x A N D r y ) A N D ! ( g x A N D g y ) A N D ! ( b x A N D b y ) must be true (no two adjacent vertices should have the same colour) - All these expressions are ‚ÄòAND‚Äôed together, and that forms the final expression for SAT. - Here‚Äôs a basic example: - So our 3COL problem is just two nodes with one edge joining them. - The first block in the SAT expression makes sure that each node has a colour. - The second block in the SAT expression makes sure each node has only ONE colour. - The third block in the SAT expression makes sure that nodes 1 and 2 don‚Äôt share the same colour. - Great, but is it in polynomial time? - The number of characters in the output SAT problem is: - 7 ùëö + 2 0 ùëö + 2 0 ùëô + ( 2 ùëö + ùëô ‚àí 1 ) - Where and . I don‚Äôt know about you, but that looks likeùëö = #ùë£ùëíùëüùë°ùëñùëêùëíùë† ùëô = #ùëíùëëùëîùëíùë† a polynomial to me. - By applying this method, we can convert any 3COL problem to SAT. - That means if we solve SAT in polynomial time, we can solve 3COL in polynomial time. - Conversely, if we find that 3COL is not in P, then SAT cannot be in P. Computer Science / Software Engineering Notes Network NP-hard - What‚Äôs NP-hard? - NP-hard is a set of problems where any NP problem can reduce to any NP-hard problem in polynomial time. - This shows that NP-hard problems are, in a sense, hard, because every NP problem can reduce to it. The Cook-Levin theorem - The Cook-Levin theorem states that any NP problem can reduce to SAT in polynomial time. - That means that SAT is an NP-hard problem, because every NP problem can reduce to it. - This also means that if we can solve SAT in polynomial time, then every NP problem will be solvable in polynomial time, and NP will be equal to P. - To convert an NP problem X into SAT, you need to ‚Äòencode‚Äôthe parameters of X into boolean variables and construct an expression for SAT. - There‚Äôs a proof for it, but it‚Äôs not examinable. Basically, it‚Äôs about converting a Turing machine into a boolean expression. What is NP-completeness - An NP-complete problem is a problem in NP and NP-hard. - SAT is an example of an NP-complete problem, because it can be solved by a non-deterministic Turing machine and every other NP problem can be reduced to it in polynomial time. - To find another NP-complete problem, you just need to have a problem X that is in NP, then find a reduction function from SAT to X. - Just remember:if you solve an NP-complete problem in polynomial time, you‚Äôve solved all NP problems in polynomial time, too, proving P = NP. Computer Science / Software Engineering Notes Network Space complexity Space complexity - First of all, what is space complexity? - The space complexity of a decider is the function where is theùëì: ùëÅ ‚Üí ùëÅ ùëì( ùëõ) maximum number of tape cells the machine scans on any branch of its computation, on any input of length n. - Basically, what‚Äôs the maximum number of tape cells we need to solve this problem? - Here‚Äôs a theorem for you: - Assume . If a decider runs in space, then it runs in time.ùëì( ùëõ) ‚â• ùëõ ùëì( ùëõ) 2 ùëÇ( ùëì( ùëõ) ) - Why? - Well, think of all the different possible combinations the Turing tape could be: 1 5 8 3 6 ... 8 3 2 9 5 ... 2 7 3 8 0 ... Computer Science / Software Engineering Notes Network - There‚Äôs lots of possibilities the tape could be! - What are all the possible combinations of the tape? - Well, first of all, we need to know how long the tape is. We already know that! It‚Äôs the space complexity of the algorithm, which is f(n). That‚Äôs how many tape cells we need to solve the problem. - Let‚Äôs just say that our decider has to run through every possible tape configuration to solve the problem. - We need a bit of combinatorics from Foundations here;what are all the possible combinations of this tape? - For each position on the tape, there are ‚Äòm‚Äôpossibilities, where ‚Äòm‚Äôis the number of symbols available to put on the tape. - So, we multiply for each tape cell, m * m * m * m ... f(n) times. This yields us: - ùëöùëì( ùëõ) - We still have a ways to go! - We have our base ‚Äòm‚Äô. However, with a little mathsy magic, we can generalise this further and make our base ‚Äò2‚Äô: - What‚Äôs the opposite of exponential? That‚Äôs right;it‚Äôs logarithms! - We can simply take the logarithm of ‚Äòm‚Äôand convert the base to a ‚Äò2‚Äô! - ( 2 ùëôùëúùëî 2 ( ùëö) ) ùëì( ùëõ) - Still remember your GCSE maths? When you have a power to the power, you multiply the powers. - 2 ùëôùëúùëî 2 ( ùëö) √ó ùëì( ùëõ) - Wait a minute... is just a constant. It could be anything, depending on whatùëôùëúùëî 2 ( ùëö) ‚Äòm‚Äôis! Look familiar? That‚Äôs the constant ‚Äòc‚Äôfound in Big-O notation! Therefore, we can introduce Big-O notation to generalise that constant. - 2 ùëÇ( ùëì( ùëõ) ) - As you can see, we have resulted in , thereby proving the link between time2 ùëÇ( ùëì( ùëõ) ) and space complexity. - What does this mean? - It means the time complexity is 2 to the power of space complexity .ùëÇ( ) - Remember our assumption:the decider checks all possible combinations of tape. Therefore, this is simply an ‚Äúupper bound‚Äù. In other words, a decider of space complexity linear or above will have at worst exponential time complexity. PSPACE - PSPACE is the set of all decision problems that can be solved by a deterministic Turing machine in polynomial space. Computer Science / Software Engineering Notes Network NPSPACE - NPSPACE is the set of all decision problems that can be solved by a non-deterministic Turing machine in polynomial space. - Anything in PSPACE is in NPSPACE, and anything in NPSPACE is in PSPACE (see Savitch‚Äôs Theorem, which is literally just below) Savitch‚Äôs Theorem - Here‚Äôs another theorem, called Savitch‚Äôs theorem: - For , every space non-deterministic Turing machine has an equivalentùëì( ùëõ) ‚â• ùëõ ùëì( ùëõ) space deterministic Turing machine.ùëì( ùëõ) 2 - This means that PSPA C E = NPSPA C E. - There‚Äôs a proof for this, but it‚Äôs not examinable. EXPTIME - The class EXPTIME is the set of all decision problems that can be solved by a deterministic Turing machine in time for some .ùëÇ( 2 ùëõ ùëò) ùëò ‚àà ùëÅ Relationships between complexity classes - P ‚äÜ PSPACE:a machine that runs in polynomial time can only use polynomial space - NP ‚äÜ NPSPACE:same reason - Hence, using Savitch‚Äôs theorem, NP ‚äÜ PSPACE - PSPACE ‚äÜ EXPTIME: - If a decider runs in f(n) space, then it runs in time.2 ùëÇ( ùëì( ùëõ) ) - We don‚Äôt know which inclusion is strict. - All we know is P EXPTIME.‚äÇ - No te:One can also define EXPSPACE. We know that - EXPTIME ‚äÜ EXPSPACE - PSPACE EXPSPACE‚äÇ PSPACE-hard - A problem X is PSPACE-hard if every problem A in PSPACE is polynomial-time reducible to X. - Examples of PSPACE-hard problems are Chess and Go. - Why not space-reducible? - We defined it like that because we want reductions to be easy compared to problems in NP! Computer Science / Software Engineering Notes Network - If we used polynomial space reduction from A to B, then found an easy solution for B, it could potentially be factorial time complexity for A! - However, because we use time-reducible, it has to be both polynomial time an d polynomial space (because P ‚äÜ PSPACE). PSPACE-completeness - PSPACE-complete simply means that a problem is both PSPACE and PSPACE-hard. - An example of a PSPACE-complete problem is TQBF. - Let TQBF be the problem of deciding whether a fully quantified boolean formula is true. - Examples of fully quantified boolean formulas: - ‚àÄx ‚àÄy ( x ‚à® y ) - ‚àÄx ‚àÉy ( ( x ‚à® y ) ‚àß ( ¬¨ x ‚à® ¬¨ y ) ) - Are there formulas true for all cases? Yes or no? That is the TQBF problem. TL;DR - Can‚Äôt be bothered to read all these notes? - Need a bite-sized form of these notes? - The TL;DR section has your back! Automata theory:Regular languages - A lp habet:a set of symbols - Lan guage:any string that can be made with an alphabet - DFAs start at the initial state, then goes through transitions (each character in the string) until it reaches an accept state. - DFAs cannot guess;they must discretely be in only one state at a time, and each state must have all possible types of transitions from it - DFAs either accept a string or reject a string - DFAs are deterministic, NFAs are non-deterministic - NFAs can make guesses Computer Science / Software Engineering Notes Network - NFAs and DFAs have the same power - The set of all strings that a DFA / NFA can accept is called it‚Äôs language - ŒµNFAs have epsilon-moves, which are free moves that do not cost any symbols in the string - A language accepted by some DFA or NFA is called ‚Äòregular‚Äô - Regular expressions have the same power as DFAs and NFAs - ‚Äúa*‚Äù means 0 or more repetitions of a - ‚Äúa + b‚Äù means a or b - ‚Äúab‚Äù means a followed by b - You can always convert an NFA/DFA to regex or vice versa - You can prove a language is regular by constructing a DFA / NFA / regex - You can prove a language is not regular by using the pumping lemma Automata theory:Context free languages - A language is context free if it can be accepted by a PDA or CFG - Pushdown automata (PDA) are like DFAs and NFAs, but you get a stack. Computer Science / Software Engineering Notes Network - Each transition, an element is popped or pushed onto the stack - PDAs accept by final state or by empty stack - Context free grammars are just as powerful as PDAs - There are two forms of CFGs: - Chomsky normal form - - Greibach normal form - - You can always convert a CFG to either Chomsky or Greibach - You can always convert a CFG to PDA or vice versa - You can prove a language isn‚Äôt context-free using the pumping lemma Computability theory - A Turing machine is like a PDA, but instead of a stack you get tape. You can move left or right on the tape, write to the tape and read from the tape. Computer Science / Software Engineering Notes Network - They are the closest mathematical abstraction of an actual computer. - A language is recursively enumerable (r.e) if it can be accepted by a Turing machine. - A language is recursive if a Turing machine can accept and reject strings from that language without looping. - Multi-tape TMs are just as powerful as single-tape TMs - A Universal Turing machine can simulate a Turing machine with a given input - The Halting problem:Is there a Turing machine that can accept if an input halts on a TM and reject if an input loops on a TM? - It‚Äôs impossible. There is a diagonalisation proof for this. - The Halting problem is ‚Äòundecidable‚Äô. - The membership problem is also ‚Äòundecidable‚Äô, because if we had a TM to solve the membership problem, we could use that to solve the Halting problem. - Reductio n :a computable function that maps inputs of one problem to another. - Rice‚Äôs theorem states that any property about a Turing machine‚Äôs language is undecidable: - You can‚Äôt tell if a TM accepts the empty string - You can‚Äôt tell if a TM accepts any string - You can‚Äôt tell if a TM accepts all the strings - etc. Computer Science / Software Engineering Notes Network Complexity theory - Big-O represents the best algorithm we currently have;we could do better but this is the best we have - Big-Œò represents that an algorithm can scale no better than this - Time complexity is the number of steps it takes for a Turing machine to solve a problem. - The class P is the set of all decision problems that can be solved by a deterministic Turing machine in polynomial time - The class NP is the set of all decision problems that can be solved by a non-deterministic Turing machine in polynomial time. - The class NP-hard is the set of all problems such that all the NP problems can reduce into any NP-hard problem in polynomial time. - The class NP-complete is the set of all problems such that they are in both NP and NP-hard. - If you find a (deterministic) polynomial algorithm for an NP-complete problem, then P = NP. - If P = NP, then: - P = NP = NP-complete - P ‚äÇ NP-hard - Space complexity is the minimum number of tape cells required for a Turing machine to solve a problem. - PSPACE is the set of all decision problems that can be solved by a deterministic Turing machine in polynomial space. - NPSPACE is the set of all decision problems that can be solved by a non-deterministic Turing machine in polynomial space. - Savitch‚Äôs Theorem states that for , every space non-deterministicùëì( ùëõ) ‚â• ùëõ ùëì( ùëõ) Turing machine has an equivalent space deterministic Turing machine.ùëì( ùëõ) 2 - Therefore, PSPACE = NPSPACE. - EXPTIME is the set of all decision problems that can be solved by a deterministic Turing machine in time for some .ùëÇ( 2 ùëõ ùëò) ùëò ‚àà ùëÅ Computer Science / Software Engineering Notes Network - PSPACE = NPSPACE - NP ‚äÜ PSPACE - PSPACE ‚äÜ EXPTIME - P ‚äÇ EXPTIME - PSPACE-hard is the set of all problems such that all the PSPACE problems can reduce into any PSPACE-hard problems in polynomial time. - PSPACE-complete is the set of all problems that are in PSPACE and PSPACE-hard.","libVersion":"0.3.2","langs":""}