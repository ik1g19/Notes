{"path":"Git Ignore/Heavy Stuff/Matthew Barnes Notes/Theory of Computing Notes.pdf","text":"Computer Science / Software Engineering Notes Network Theory of Computing Matthew Barnes, Mathias Ritter B o o ks 4 A uto mata theo ry: Regular lan guages 5 Deterministic Finite Automata 5 Alphabets and strings 5 Languages 6 Deterministic finite automata (DFAs) 6 Product construction 9 Regular languages 10 Nondeterminism, subset construction and Ïµ-moves 15 Nondeterminism 15 Subset construction 18 Ïµ-moves 21 Regular expressions and Kleeneâ€™s theorem 23 Defining regular expressions 23 Atomic patterns 23 Compound patterns 24 Examples 24 Kleeneâ€™s theorem 24 Reg exp to ÎµNFA 25 ÎµNFA to reg exp 26 Limitations of regular languages 29 Pumping (ğŸƒ) Lemma for regular languages - contrapositive form 30 A uto mata theo ry: C o n text free lan guages 3 4 Pushdown Automata (PDA) 34 Transition relation 34 Configuration 35 Acceptance 35 By final state 36 By empty stack 36 Example PDA accepting palindromes 36 Context free grammars 38 Chomsky Normal Form 41 Greibach Normal Form 42 Removing epsilon and unit productions 42 Removing left-recursive productions 42 Converting between CFG, CNF and GNF 44 Computer Science / Software Engineering Notes Network Converting a CFG to CNF 44 Converting a CFG to GNF 46 PDA and CFG conversions 49 CFG to PDA 49 PDA to CFG 51 Proving closure 58 Union 58 Concatenation 58 Kleene star 59 Intersection with regular languages 59 Limits of context-free languages 60 Pumping (ğŸƒ) Lemma for context-free languages - contrapositive form 63 C o mp utability theo ry 6 7 Turing machines 67 Decidability 68 Recursive and R.E languages 68 Proof:Recursive Sets Closed under Complement 68 (Semi) Decidable properties 70 Universal Turing machines 71 Multiple tapes 71 Simulating Turing machines 71 Encoding Turing machines 71 Constructing a UTM 72 Halting problem 72 Proof by contradiction 72 Proof by diagonalisation 73 Decidable / Undecidable problems 74 Reductions 77 Properties of reductions 82 Riceâ€™s theorem 83 C o mp lexity theo ry 8 5 Big-O and Big-Ï´ 86 Big-Ï´ 86 Big-O 86 The class P 87 Feasible and infeasible problems 87 Decision problems 87 Definition 88 The PATH problem 89 The HAMPATH problem 90 Regular and context-free languages 90 Computer Science / Software Engineering Notes Network The class NP 91 Non-deterministic Turing machine 91 Time complexity of Turing machines 92 Definition 95 The SAT problem 95 The HAMPATH problem 96 The TSP(D) problem 97 The 3COL problem 97 NP = P? 97 Presburger arithmetic 98 NP-Completeness 99 Polynomial time reduction 99 3COL to SAT 100 NP-hard 101 The Cook-Levin theorem 101 What is NP-completeness 101 Space complexity 101 Space complexity 101 PSPACE 103 NPSPACE 103 Savitchâ€™s Theorem 104 EXPTIME 104 Relationships between complexity classes 104 PSPACE-hard 104 PSPACE-completeness 105 TL; D R 1 0 5 Automata theory:Regular languages 105 Automata theory:Context free languages 106 Computability theory 107 Complexity theory 108 Computer Science / Software Engineering Notes Network Books - There are two main books for this module. Iâ€™ve added PDF links to both of them. - Dexter C. Kozen, Automata and Computabilty, Springer, 1999 (Kozen) - Sipser M, Introduction to the Theory of Computation, PWS, 1997 (Sipser) Computer Science / Software Engineering Notes Network Automata theory:Regular languages - Automata relates to machines with finite memory. - Unlike maths, where we can have infinite of something, we cannot have infinite of something in an automata because itâ€™ll run out of memory. - Automata also relates to pattern matching, modelling, verification of hardware etc. Deterministic Finite Automata Alphabets and strings - An alp habet is a finite set of elements. It is denoted with capital sigma, Î£. - Examples: - Î£ = {0, 1} - Î£ = {a, b, c} - Î£ â‰  {1, 2, 3, 4, ...} - A strin g â€˜sâ€™over Î£ is a finite sequence of elements of Î£. - Two strings â€˜sâ€™and â€˜tâ€™are equal when they have the same elements of the same order. - Examples: - Î£ = {0, 1}, s = â€œ0100110â€ - Î£ = {a, b}, s = â€œabbabaâ€ - The set o f all strin gs is denoted with sigma star, Î£*. - It will always be infinite, unless the alphabet is empty. - In every alphabet, including an empty alphabet, the set contains the emp ty strin g â€˜Ïµâ€™. - More names for Î£* are â€œfree monoid on Î£â€, or â€œKleene star of Î£â€. - Examples: - Î£ = {}, Î£* = { Ïµ } - Î£ = {a}, Î£* = { Ïµ, a, aa, aaa, aaaa ... } - Î£ = {0, 1}, Î£* = { Ïµ, 0, 1, 10, 11, 100, 001, 000 ...} - We can clean up our notation by not including Î£, but just replacing it with its definition: - {}* = { Ïµ } - {a}* = { Ïµ, a, aa, aaa, aaaa ... } - {0, 1}* = { Ïµ, 0, 1, 10, 11, 100, 001, 000 ...} - The len gth # of a string is its number of elements. - Examples: - #(abba) = 4 - #(00101) = 5 Computer Science / Software Engineering Notes Network - #(joestar) = 7 - The emp ty strin g is usually denoted with a lunate epsilon character, Ïµ. - Laws: - Ïµ = â€œâ€ - #(Ïµ) = 0 - ÏµÏµ = Ïµ - You can co n caten ate two strings, â€˜sâ€™and â€˜tâ€™, like this:â€˜stâ€™. - Example: - s = â€œabâ€, t = â€œbaâ€, st = â€œabbaâ€ - s = 011, t = 101, st = 011101 - s = â€œzaâ€, t = â€œwarudoâ€, st = â€œzawarudoâ€ - s = Ïµ, t = Ïµ, st = Ïµ - Ïµs = sÏµ = s Languages - A lan guage L over an alphabet Î£ is some subset of strings in Î£*. - Examples: - Î£ = {a, b, c} - L1 = {Ïµ, a, bb, cba} - L2 = {bbb, aaa} - L3 = {cccccacccccc} - L4 = Ã˜ = {} - Two languages are equal when they contain the same strings (in terms of sets, they are equal). - If the language should also contain the empty string Ïµ it must be explicitly added to the language as an element of the set. Deterministic finite automata (DFAs) - A fin ite auto mata is a mathematical model of a system with a finite number of states and a finite amount of memory space. - A state is a description of a system at some point in time. - A tran sitio n allows the DFA to go from one state to the other. - Think of DFAs like flow-charts;you go from one state to the next until you reach the goal state. - There are three kinds of finite automata: - Deterministic - Nondeterministic - Nondeterministic with Ïµ-moves - Right now, weâ€™ll focus on deterministic finite automata. - A DFA (deterministic finite automata) has 5 properties: Pro p erty Symbo l D escrip tio n Computer Science / Software Engineering Notes Network States Q Possible states that the automata can be in. Alphabet Î£ The alphabet that the transition names depend on. Transitions Î´ A function that allows the automata to go from one state to the other by consuming a symbol. This takes an element of Î£ and a state from Q, and outputs the next state from Q to transition to. Start state s The state that the automata starts at. Final states (accept states) F Set of states at which, if the automata ends at them, it accepts the string that was entered into it. - To define a DFA mathematically, use the properties above into a tuple: - Example, given that M is a DFA: - M = (Q, Î£, Î´, s, F) - An automata takes in a string that contains letters from the alphabet and reads it from left to right, with each letter being an action (or transition) that changes the state of the automata. - All states must have all possible transitions, i.e. each state must have exactly one transition for every element of the alphabet - If the automata en ds o n a fin al state, itâ€™ll accep t the string. - If the automata do es n o t en d o n a fin al state, itâ€™ll reject the string. - You can also represent DFAs as graphs (pictures), similar to state-machine diagrams: Computer Science / Software Engineering Notes Network - This small arrow pointing to the â€˜0â€™state coming from nowhere means that â€˜0â€™ is the initial state. - The states that are not filled in are not final states. - The states that are filled in are final states. - The arrows represent the transitions between states, which are triggered by the input character shown - This DFA accepts strings like abbab and babbbab, but not abba or Ïµ. - To say that a string â€˜sâ€™takes the DFA from state 0 to state 1, you would write that as: - - Where: - Left-hand side = beginning state - Right-hand side = ending state - Text on the top = string transition - More examples: - - - Computer Science / Software Engineering Notes Network Product construction - Product construction is where you merge two DFAs together, so that the combined DFA is actually the two component DFAs running in parallel. - The states arenâ€™t just single string / character names. The states are referenced in a tuple (or pair), with each element being a state name from one of the component DFAs. - Letâ€™s define the DFAs of L1 and L2 as this, respectively: - Now, if we found the product of the DFA of L1 and the DFA of L2, then the states of that product would be: - (0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2), (3, 0), (3, 1), (3, 2) - The product transition would need a pair state and a transition name. For example, you could go from (2,0) to (3,1) by using â€˜aâ€™, or you could go from (0,0) to (1,0) by using â€˜bâ€™. - The set of final states F is F1 â¨¯ F2, where F1 is the set of final states of L1 and F2 is the set of final states of L2. Therefore, with normal, unedited product construction, for the DFA to accept the string, we need to be in a final state for both component DFAs. - This can be changed, however, to just â€œat least one DFA to be on a final stateâ€ if we define F to be (Q1 â¨¯ F2) âˆª (F1 â¨¯ Q2), where Qx is the set of states for a DFA. - Therefore, the language expressed by the product of and is .ğ¿ 1 ğ¿ 2 ğ¿ 1 âˆ© ğ¿ 2 - Itâ€™s best to view this as a table, where you can see the DFAs of L1 and L2 simultaneously: L1 â€™s D FA state L2 â€™s D FA state Pro duct state Tran sitio n Step 0 0 (0,0) None (yet) 0 1 1 (1,1) a 1 2 1 (2,1) b 2 Computer Science / Software Engineering Notes Network 3 2 (3,2) a 3 - To view this more simply, you can just follow two DFAs at the same time, and put oneâ€™s state on the left of the tuple and the otherâ€™s state on the right of the tuple. Itâ€™s nothing more than running two DFAs at the same time, inputting the same word into both of them. - If youâ€™re confused check this helpful video out. Regular languages - When you have a DFA called M, then L(M) is the language of all accepted strings. - For example, in the previous DFA, L(M) = {b, ab, aab, bb, abb ...} and it will not include elements like â€˜aâ€™, â€˜Ïµâ€™, â€˜baâ€™or â€˜bbaâ€™because they all will not be accepted by that DFA. - A regular lan guage L is when there exists some DFA M such that L(M) exists. - More informally, a language L is regular if you can come up with some DFA where itâ€™ll accept allthe words in L and only those words in L. - For example, the language { ab, ba, aa, bb } is regular because I can construct a DFA that accepts only those words: - All finite languages are regular, because we could (in theory) just build a control flow tree of constant size (you can visualize it as a bunch of nested if-statements that examine one digit after the other) (citation). - The empty language Ã˜ is regular, because you can create a DFA that canâ€™t accept anything (for example, a DFA with no final states), not even the empty string. If a DFA canâ€™t accept any strings, then the L(M) of that DFA would be the empty set Ã˜, making Ã˜ regular. - The set of all strings Î£* is regular, because you can set up a DFA consisting of a single final state that transitions to itself for any symbol. This accepts any element from the alphabet Î£, like this one when Î£ = {a, b, c} and Î£* = {Ïµ, a, b, c, ab, bc, abc, cba ...}: Computer Science / Software Engineering Notes Network - If L is regular, then the complement (Î£* - L, or ~L) is always regular. - For example, letâ€™s take the language L = {ab, ba, aa, bb} from before because we know thatâ€™s regular (therefore there must be a DFA whose L(M) is L). The alphabet that itâ€™s from is Î£ = {a, b}. The complement of L, ~L, will be the set of all strings from Î£* except for the ones in L. - If we take the DFA whose L(M) is L from before and flip all the final states to non-final states and vice versa, we can create a new DFA whose L(M) is ~L (citation). - This works on any language. Weâ€™re simply getting the â€œinverseâ€ of this DFA. - If L1 and L2 are regular, then the union, L1 â‹ƒ L2, is regular. - If we want to prove that L1 â‹ƒ L2 is regular, we need to show a DFA exists for L1 â‹ƒ L2. - We can use product construction for L1 and L2 , then we can modify it a bit to suit what we need. - First of all, letâ€™s define the result of the product of L1 â‹ƒ L2 to be M. - Now, we change the set of final states F of M to be â€œat least one DFA must be on a final state to accept the stringâ€, so we define F to be (Q1 â¨¯ F2) âˆª (F1 â¨¯ Q2), where Qx is the set of states for a DFA. - By doing that, we have now defined a DFA where L(M) is L1 â‹ƒ L2. - If L1 and L2 are regular, then the intersection, L1 âˆ© L2, is regular. - This oneâ€™s even easier than the union one. - Basically, we use product construction for the DFAs L1 and L2. - Thatâ€™s it. We donâ€™t even need to change the set of final states. This is because, by default, the product of two DFAs require both DFAs to be on a final state for the aggregate DFA to accept the string, which is the intersection. - If L1 and L2 are regular then L1 L2 = { xy | x âˆˆ L1, y âˆˆ L2 } is regular. - This proof requires NFAs (nondeterministic finite automata), which are covered in more detail later, but basically itâ€™s the same as DFA except you can have multiple transitions in NFAs, and you can take multiple paths at the same time. Think of it like two threads running in parallel, or two trains travelling on different paths in parallel. Computer Science / Software Engineering Notes Network Itâ€™s similar to a fork node in an activity diagram in UML and how it models concurrency in a system. - First, we define two DFAs for L1 and L2: - M1 = (Q1, Î£, Î´1, s1, F1) - M2 = (Q2, Î£, Î´2, s2, F2) - Now, weâ€™re going to create an NFA from these two DFAs: - M3 = (Q1 âˆª Q2, Î£, Î´1 âˆª Î´2, s1, F2) - and for each state q âˆˆ F1, Î´(q, Ïµ) = s2 (what this means is, for each final state of the first DFA, make a transition that goes from that final state to the starting state of the second DFA). The transition has the name â€˜Ïµâ€™, which means that we can take this transition without using up any characters in the string, itâ€™s basically a free move, but more on that in a later topic. See â€˜Ïµ-movesâ€™). - What this NFA really means is that we start off in terms of M1, but we need to finish off in terms of M2. - For example, take the two example DFAs for a second: - If we define a new NFA, like we did above, for these two example DFAs, itâ€™ll look something like the illustration below. Iâ€™ve created two illustrations of the same NFA: one without annotations, and one with annotations. The p ro p er o n e Computer Science / Software Engineering Notes Network The illustrative o n e - First of all, the top half of this NFA is basically M1. However, when we reach M1â€™s final state, thereâ€™s actually an epsilon move taking the NFA to its bottom half. If we donâ€™t reach that epsilon move, we canâ€™t move onto the bottom half of the NFA. When we reach that epsilon move, the string (up to this point) should be one of M1â€™s accepted strings. - Second, the bottom half of the NFA is M2. Once weâ€™ve reached the bottom half, weâ€™ve found an M1 string, now we just need an M2 string. Once weâ€™ve got an M2 string, weâ€™ll be on a final node and the string will be accepted. - By reaching the final node, we know that the input string is made up of an M1 accepted string as the first half, and an M2 accepted string as the second half. This is literally the definition of L1 L2, so we can safely say that the L(M) of this NFA is L1 L2. - This NFA should accept any concatenated string from L1 and L2. Therefore, L1 L2 is regular. Computer Science / Software Engineering Notes Network - If L is regular then L* = { x1 ... xk | k âˆˆ N, xi âˆˆ L } is regular. - L* is basically the set of every possible word you can make by concatenating the words of L onto themselves. - So if L had â€œaddâ€ and â€œdadâ€, L* would have words like â€œadddadâ€, â€œdadadddadâ€, â€œdaddaddadâ€ etc. and it would go on infinitely. - The operator * is called â€œKleene starâ€, and weâ€™ve been using it already (when we write Î£* to refer to the set of all words of that alphabet). - Yet again, weâ€™ll need NFAs to prove this. - Letâ€™s use my â€œadd dadâ€ example above, and construct a DFA, M, where L(M) is L: - The red nodes are â€œerror nodesâ€, where the DFA goes when we know the string will be rejected. - This accepts â€œaddâ€ and â€œdadâ€, but we need it to accept words like â€œadddadâ€ as well. - Luckily, epsilon-moves allow us to very easily construct an NFA that does this: Computer Science / Software Engineering Notes Network - Now, when we complete the word â€œaddâ€ or â€œdadâ€, we can move straight back to the start node and search for â€œaddâ€ or â€œdadâ€ again. Remember, epsilon moves donâ€™t require any characters to use, so we can go straight from the end of â€œaddâ€ to the start of â€œdadâ€, for example. - The reason why we create a new final start state that immediately goes to the old start state is because Kleene star supports the empty string (in the picture, itâ€™s state 8) - To more generalise this proof, letâ€™s define a general DFA: - M = (Q, Î£, Î´, sâ€™, F âˆª sâ€™) - Now, we set epsilon moves branching from all the final states to the new final starting state: - âˆ€q âˆˆ F, Î´(q, Ïµ) = sâ€™ - (For all states q in the set of final states F, there is a transition function where when the NFA is in state q, and the empty epsilon move Ïµ is input, the state transitioned to is the new final start state sâ€™.) - Thatâ€™s all there is to this proof. Nondeterminism, subset construction and Ïµ-moves Nondeterminism - With a DFA, there is always a next state to go to when you input a letter. - However, what if there are cases where there isnâ€™t always a next state to go to? What if thereâ€™s multiple states we can go to? - Thatâ€™s what an NFA is (nondeterministic finite automata), itâ€™s basically a DFA that can either branch off to multiple states, or fail if there are no states to go to. In other words, it guesses where itâ€™s supposed to go. If the guesses are wrong, they â€œdieâ€. Computer Science / Software Engineering Notes Network - In other words, a state no longer has |Î£| transitions, where each transition is every letter of the automataâ€™s alphabet. - The whole gimmick of an NFA is that we can go through different â€œpathsâ€ simultaneously. Some paths can die, some paths can survive and reach final states. We only need one path to be on a final state to accept the string. - \"It is helpful to think about this process in terms of guessing and verifying. On a given input, imagine the automaton guessing a successful computation or proof that the input is a \"yes\" instance of the decision problem, then verifying that its guess was indeed correct.\" Source:Kozen textbook - Example: - As you can see, itâ€™s slightly different from a DFA: - There are two â€˜bâ€™transitions in state â€˜0â€™ - There are no transitions in state â€˜1â€™ - Letâ€™s walk through this NFA to get a feel for how NFAs work: Step D escrip tio n Strin g so far Illustratio n 1 So far, we havenâ€™t gone anywhere. The arrow that seems to come from nowhere indicates where we are initially, so we start at state â€˜0â€™. The smiley faces indicate different â€œpathsâ€that the NFA is going through. A different coloured face is a different path, and their journey is displayed on the right, for example the green path has just started on 0, so a green â€˜0â€™is shown on the right. Îµ 0 2 Letâ€™s try inputting â€˜aâ€™and see where that leads us. Thereâ€™s only one transition we can go down if we input â€˜aâ€™,so no new simultaneous paths are created; we just stick with our original one. The â€˜aâ€™path just goes from 0 to 0, so our green path goes from â€˜0â€™to â€˜0â€™. ğ‘ 0 â†’ 0 Computer Science / Software Engineering Notes Network 3 Letâ€™s try inputting a â€˜bâ€™and see where that leads us. There are two paths that â€˜bâ€™can take us, from 0 to 0 or from 0 to 1. Here, our green path splits into two, one red and one blue . The red one picks the path that stays on 0, and the blue path picks the one that goes to 1. Right now, there exists a path that is on a final state: the blue one. Therefore, if we left the string as just , this NFA will accept that string.ğ‘ğ‘ ğ‘ğ‘ 0 â†’ 0 â†’ 0 0 â†’ 0 â†’ 1 4 Letâ€™s try inputting another â€˜bâ€™and see where that leads us. The red and blue paths will both need to go through a â€˜bâ€™transition. Since the blue path doesnâ€™t have a blue transition where it is, itâ€™llâ€˜dieâ€™. The red path needs to go down a â€˜bâ€™ transition, too. There are two transitions that the red path can go down, the one that goes from 0 to 0 and the one that goes from 0 to 1. Like last time, the red path splits into two different paths: a yellow path and purple path. The yellow path takes the transition from 0 to 0, therefore the yellow path is still on 0. The purple path takes the transition from 0 to 1, therefore the purple path is now on 1. The NFA should accept this string too, since the purple path is on a final state. ğ‘ğ‘ğ‘ 0 â†’ 0 â†’ 0 â†’ 0 0 â†’ 0 â†’ 0 â†’ 1 - Now, letâ€™s formally construct an NFA: - ğ‘€ = ( ğ‘„, Î£, âˆ†, ğ‘ , ğ¹) - where: - is the set of all statesğ‘„ - is an alphabetÎ£ - is the transition function , which basically means input a stateâˆ† ğ‘„ Ã— Î£ â†’ 2 ğ‘„ and a letter from the alphabet and get a set of all states we could be in (see â€˜Subset constructionâ€™) - is the start stateğ‘  - is the set of final statesğ¹ - Letâ€™s formally construct the NFA as shown above: Computer Science / Software Engineering Notes Network ğ‘€ = ( ğ‘„, Î£, âˆ†, ğ‘ , ğ¹) ğ‘„ = { 0 , 1 } Î£ = { ğ‘, ğ‘} âˆ†( 0 , ğ‘) = { 0 } âˆ†( 0 , ğ‘) = { 0 , 1 } âˆ†( 1 , ğ‘) = âˆ… âˆ†( 1 , ğ‘) = âˆ… ğ‘  = 0 ğ¹ = { 1 } - There is some notation that is worth noting: - When you see something like: - This means that the NFA will go from 0 to 2 if you input â€˜aâ€™, and then â€˜bâ€™. There should be some intermediate state, either â€˜0â€™, â€˜2â€™, or even â€˜1â€™, that you enter when you input â€˜aâ€™and leave when you input â€˜bâ€™. Subset construction - Itâ€™s easy to convert DFAs into NFAs, because DFAs are a subset of NFAs. - But how do you convert NFAs to DFAs? - You use subset construction. Basically, each state is a subset of states that we couldâ€™ve gone to in our NFA counterpart. - For example, in our NFA, if weâ€™re in state 0 and by inputting â€˜bâ€™we can either go to 0 or go to 1, in the DFA weâ€™ll actually go to the state {0,1} because we can go to either 0 or 1 in the NFA. - Letâ€™s define an NFA , then letâ€™s create a DFA which is based on :ğ‘€ ğ‘ ğ‘€ ğ· ğ‘€ ğ‘ - ğ‘€ ğ‘ = ( ğ‘„, Î£, âˆ†, ğ‘ , ğ¹) - ğ‘€ ğ· = ( ğ‘„', Î£, Î´, ğ‘ , ğ¹') - ğ‘„' = 2 ğ‘„ - Î´( ğ‘‹, Ïƒ) = ğ‘âˆˆğ‘‹ â‹ƒ âˆ†( ğ‘, Ïƒ) - ğ¹' = { ğ‘‹ | âˆƒğ‘“ âˆˆ ğ¹. ğ‘“ âˆˆ ğ‘‹, ğ‘‹ âˆˆ ğ‘„'} - This may look like an alien language to you now, but Iâ€™ll go through each line and explain it in plain English, then Iâ€™ll apply subset construction to the example above. - First things first, whatâ€™s going on up there? Lin e in weird maths lan guage Lin e in p lain En glish ğ‘€ ğ‘ = ( ğ‘„, Î£, âˆ†, ğ‘ , ğ¹) Here, we create an NFA with the parameters , , , and .ğ‘„ Î£ âˆ† ğ‘  ğ¹ Computer Science / Software Engineering Notes Network ğ‘€ ğ· = ( ğ‘„', Î£, Î´, ğ‘ , ğ¹') Here, we create a DFA with the parameters , , , and . Theğ‘„' Î£ Î´ ğ‘  ğ¹' parameters , and are all dependent on the parameters forğ‘„' Î´ ğ¹' the NFA .ğ‘€ğ‘ ğ‘„' = 2 ğ‘„ is the set of all states, like . However , is the powerset ofğ‘„ { 0 , 1 } 2 ğ‘„ , so itâ€™s the set of all subsets of , so for example,ğ‘„ ğ‘„ { âˆ…, { 0 } , { 1 } , { 0 , 1 } } Because of this, the states in the DFA is all the subsets of , soğ‘„ you could have a state , a state or even a state .{ 0 } { 0 , 1 } âˆ… Î´( ğ‘‹, Ïƒ) = ğ‘âˆˆğ‘‹ â‹ƒ âˆ†( ğ‘, Ïƒ) From before, we know that is a transition function that definesÎ´ how we go from one state to the other. Therefore, the inputs must be a state and a letter. is our state input. Itâ€™s actually a set, which makes sense, becauseğ‘‹ the states in our DFA are all subsets of .ğ‘„ is our letter input. Nothing strange here; itâ€™s just a letter within theÏƒ alphabet .Î£ Donâ€™t be too confused with the that comes after. This simply ğ‘âˆˆğ‘‹ â‹ƒ means that, for each NFA state in our input , weâ€™re going to applyğ‘‹ the NFA transition function on that state with our input letter andÏƒ put the result in our state output. More formally, is a bit like the sum in maths , except ğ‘âˆˆğ‘‹ â‹ƒ ğ‘–=0 ğ‘˜ âˆ‘ ğ‘“( ğ‘˜) instead of adding all the terms, it unions all the terms. Remember that the transition function also outputs a state. Since the states of our DFA are subsets of , the DFA transition functionğ‘„ also outputs a subset of .Î´ ğ‘„ For example, letâ€™s say we input . The output will beÎ´( { 0 , 1 } , ğ‘) . Iâ€™llgo over this in more detail in our exampleâˆ†( 0 , ğ‘) âˆª âˆ†( 1 , ğ‘) below , but the point is that this transition function just transitions all the states in and unions them all together into one big output.ğ‘‹ ğ¹' = { ğ‘‹ | âˆƒğ‘“ âˆˆ ğ¹. ğ‘“ âˆˆ ğ‘‹, ğ‘‹ âˆˆ ğ‘„'} The set of final states is a subset of .ğ¹' ğ‘„' For a DFA state to be a final state, it needs to contain an NFA state that is in .ğ¹ For example, if 0 is a non-final state and if 1 is a final state in the NFA, then in the DFA, {0} would not be a final state, but {0,1} and {1} would be final states. Thatâ€™s basically what the left expression gets; a subset of whereğ‘„' all elements contain at least one final state from .ğ¹ - Now that weâ€™ve got the formalities out the way, we can work on an example. Letâ€™s convert the NFA above into a DFA. - As said above, weâ€™ll define our DFA as and our NFA asğ‘€ ğ· = ( ğ‘„', Î£, Î´, ğ‘ , ğ¹') , so weâ€™ll go through this step-by-step by explaining howğ‘€ ğ‘ = ( { 0 , 1 } , { ğ‘, ğ‘} , âˆ†, 0 , { 1 } ) we get each parameter for the DFA :ğ‘€ ğ· Computer Science / Software Engineering Notes Network What weâ€™re defining How we did it ğ‘„' The value of is , so we just need to get the powerset of , or the â€˜setofğ‘„ { 0 , 1 } { 0 , 1 } subsetsâ€™. This is: ğ‘„' = { âˆ…, { 0 } , { 1 } , { 0 , 1 } } Î£ This is just the same as before, nothing new here: Î£ = { ğ‘, ğ‘} Î´ First of all, letâ€™s create a transition table. This is a table where the input letters go on the top, the states go on the left, and you can look up transition results by looking up a state and a letter: ğ‘ ğ‘ âˆ… { 0 } { 1 } { 0 , 1 } Now we work through this table from top to bottom. First of all, thereâ€™s the empty set state. You canâ€™t go from any state from the empty set state; itâ€™s practically a death state. So just input all empty set states here. ğ‘ ğ‘ âˆ… âˆ… âˆ… { 0 } { 1 } { 0 , 1 } Now weâ€™re moving onto the singleton states. For and , just have a look at the{ 0 } ğ‘ NFA and see what states youâ€™d end up at if you were at 0 and you took the paths labelled â€˜aâ€™.As you can see, youâ€™d just end up back at 0, so we just input there.{ 0 } As for and , you can see that you can go to 0 or 1 using a â€˜bâ€™path on 0, so we{ 0 } ğ‘ can input there. Continue this until weâ€™re done with all the singleton states.{ 0 , 1 } ğ‘ ğ‘ âˆ… âˆ… âˆ… { 0 } { 0 } { 0 , 1 } { 1 } âˆ… âˆ… Computer Science / Software Engineering Notes Network { 0 , 1 } Now weâ€™re faced with a state with more than one element! Remember the definition from before: we need to perform the transition function on all the elements, then union the results together . For example, on and , we need to union the{ 0 , 1 } ğ‘ results of doing and , and and . Just above the and cell, we can{ 0 } ğ‘ { 1 } ğ‘ { 0 , 1 } ğ‘ see the results of those. We just need to union those together , by which I mean, union and together . When we do that, we get , so in this transition table,{ 0 } âˆ… { 0 } when you input on the state , you get . Repeat this for all the states andğ‘ { 0 , 1 } { 0 } inputs until you finish the table. ğ‘ ğ‘ âˆ… âˆ… âˆ… { 0 } { 0 } { 0 , 1 } { 1 } âˆ… âˆ… { 0 , 1 } { 0 } { 0 , 1 } Once youâ€™re done, thatâ€™s pretty much it! This transition table is your new transition function for your DFA. This video goes into more detail and I strongly suggest it if you still struggle with this. ğ‘  Itâ€™s pretty much the same as the original, but you encapsulate it in a set: ğ‘  = { 0 } ğ¹' Get all the elements of :ğ‘„' { , , , }âˆ… { 0 } { 1 } { 0 , 1 } Now get rid of the ones that do not have final states in them: { , , , }âˆ… { 0 } { 1 } { 0 , 1 } So therefore, your new is:ğ¹' { , }ğ¹' = { 1 } { 0 , 1 } Ïµ-moves - An epsilon-move (Ïµ-move) is a type of transition that you can use without needing to â€œspendâ€ or â€œconsumeâ€ any symbols. - Itâ€™s basically a free move. - An NFA that uses epsilon-moves are called ÏµNFAs. - Theyâ€™re formally defined like this: - ğ‘€ Ïµ = ( ğ‘„, Î£, Î¸, ğ‘ , ğ¹) - where - Î¸: ğ‘„ Ã— ( Î£ + { Ïµ} ) â†’ 2 ğ‘„ - This is basically the same as an NFA, except transitions now support epsilon-moves. Computer Science / Software Engineering Notes Network - Here is an example of an ÏµNFA: - From the starting state, you can go to the left-most state and the right-most final state, all without consuming any symbols. - You can also convert ÏµNFAs to NFAs. Donâ€™t worry! Itâ€™s not as long as subset construction. - You only need to edit the transition function and the set of final states. - With an ÏµNFA we can create an NFA like so:ğ‘€ Ïµ ğ‘€ ğ‘ - ğ‘€ Ïµ = ( ğ‘„, Î£, Î¸, ğ‘ , ğ¹) - ğ‘€ ğ‘ = ( ğ‘„, Î£, âˆ†, ğ‘ , ğ¹') - âˆ†( ğ‘, Ïƒ) = - ğ¹' = - Your next line will be â€œIs this going to be translated into plain English again?â€ - Please see below for a translation into plain English. Lin e in weird maths lan guage Lin e in p lain En glish ğ‘€ Ïµ = ( ğ‘„, Î£, Î¸, ğ‘ , ğ¹) Weâ€™re just defining an ÏµNFA with these parameters. ğ‘€ ğ‘ = ( ğ‘„, Î£, âˆ†, ğ‘ , ğ¹') Weâ€™re just defining an NFA with these parameters. These parameters will be based off of the parameters for .ğ‘€Ïµ âˆ†( ğ‘, Ïƒ) = When you input a state and a symbol, the output will be all the possible states it can reach using epsilon-moves and that symbol. ğ¹' = The new set of final states is a superset of the old set of final states, meaning we still keep the final states the same, but we add more. We add the states that can epsilon-move towards a final state. - Now Iâ€™ll go over an example, by converting that ÏµNFA above into an NFA: Computer Science / Software Engineering Notes Network What weâ€™re defining How we did it âˆ† First, letâ€™s create that transition table again. Just for exampleâ€™s sake, Iâ€™mcalling the initial state 0, the left-most state 1 and the final state 2: ğ‘ ğ‘ 0 1 2 If you were at state 0 and had an input â€˜aâ€™,what states could you get to? Well, you could go down the left epsilon-move to get to state 1 and spend the â€˜aâ€™on going back to state 1. Thatâ€™s pretty much it, so here, weâ€™d input just state 1. If you were at state 0 and had an input â€˜bâ€™,what states could you get to? You could go down the left epsilon-move and use â€˜bâ€™to go to state 1 or use your â€˜bâ€™to get to state 2. If you went down the right epsilon-move, you wouldnâ€™t be able to use â€˜bâ€™,so you can ignore it. Seems like you can get to states 1 and 2, so we put that in the transition table. We keep going like this until we fill out the transition table: ğ‘ ğ‘ 0 { 1 } { 1 , 2 } 1 { 1 } { 1 , 2 } 2 âˆ… âˆ… This transition table is our new transition function! ğ¹' For this one, you could look at the final states in the graph, and work your way back up the epsilon-moves, looking for non-final states that can epsilon-move to the final state. As you can see in the graph above, if you start at state 2 (the final state) and work your way up the epsilon-move, youâ€™llfind yourself at state 0. Therefore, we can make state 0 a final state. However , you cannot go up to state 1 from state 2, so state 1 cannot be a new final state. Obviously, we keep the old final states from the ÏµNFA: ğ¹' = { 0 , 2 } Regular expressions and Kleeneâ€™s theorem Defining regular expressions - A string s matches a regular expression wheneverÎ± ğ‘  âˆˆ ğ¿( Î±) - Regular expressions can be defined using atomic and compound patterns Computer Science / Software Engineering Notes Network Atomic patterns - There exist the following atomic patterns, which do not need to be broken down further: Pattern Matched by â€¦ ğ¿( Ïƒ) = { Ïƒ} â€¦ the single symbol from the alphabet:Ïƒ Î£ ğ¿( Îµ) = { Îµ} â€¦ the empty string ğ¿( âŠ˜) = { } â€¦ nothing ğ¿( #) = Î£ â€¦ any single symbol from the alphabet Î£ ğ¿( @) = ğ¿( #* ) = Î£* â€¦ any string formed by the symbols in (including the emptyÎ£ string), i.e. any string in Î£* Compound patterns - Compound patterns are defined recursively, based on the atomic patterns. Pattern A Strin g will match if ... ğ¿( Î± + Î²) = ğ¿( Î±) âˆª ğ¿( Î² â€¦ it matches orÎ± Î² ğ¿( Î± âˆ© Î²) = ğ¿( Î±) âˆ© ğ¿( Î² â€¦ it matches both andÎ± Î² ğ¿( Î±Î²) = ğ¿( Î±) ğ¿( Î²) â€¦ it can be broken down into two parts such that the first part matches and the second part matchesÎ± Î² ğ¿( âˆ¼ Î±) =âˆ¼ ğ¿( Î±) â€¦ it does not match Î± ğ¿( Î±* ) = ğ¿( Î±) * â€¦ it matches 0 or more repetitions of .Î± ğ¿( Î±+ ) = ğ¿( Î±) + â€¦ it matches 1 or more repetitions of .Î± Examples - Î£ = { ğ‘, ğ‘, ğ‘–, ğ‘¡, ğ‘£} All strings that end in â€œvitaâ€: or more elegant:( ğ‘ + ğ‘ + ğ‘– + ğ‘¡ + ğ‘£) * ğ‘£ğ‘–ğ‘¡ğ‘ @ğ‘£ğ‘–ğ‘¡ğ‘ - Î£ = { ğ‘, ğ‘} All strings with an even number of aâ€™s:ğ‘ * ( ğ‘ğ‘ * ğ‘ğ‘ * ) * - Î£ = { ğ‘, ğ‘} All strings with an odd number of aâ€™s:ğ‘ * ( ğ‘ğ‘ * ğ‘ğ‘ * ) * ğ‘ğ‘ * Kleeneâ€™s theorem - If is a regular expression then is a regular language.Î± ğ¿( Î±) Computer Science / Software Engineering Notes Network - All strings that match a regular expression form a language. This language is regular. - If L is a regular language then for some regular expression .ğ¿ = ğ¿( Î±) Î± - If a language is regular, then there exists a regular expression that matches all strings in that language (and not more/less). - Therefore, we can conclude that finite automata and regular expressions describe the same languages;they are equally powerful. - In order to prove this theorem, we need to show that we can convert a regular expression to a finite automaton and vice versa. Reg exp to ÎµNFA - We will convert a regular expression to a Îµğ‘ğ¹ğ´ - Basically, weâ€™re going to split our regular expression into â€œbuilding blocksâ€, then weâ€™re going to convert those â€œbuilding blocksâ€ into automata individually. - With each regex â€œbuilding blockâ€, we need to show that we can build an automata out of it. In other words, for each possible regex â€œbuilding blockâ€, we need to show that itâ€™s language is regular. - Once weâ€™ve shown that all our building blocks are regular, we can use said building blocks to build an automata out of any regex expression. - We can prove we can convert by induction, as regular expressions are built inductively. - This means that we can build any regular expression by combining our atomic patterns, which results in a compound pattern. Think of the atomic patterns as our basic building blocks: - First we check if our basic building blocks are regular. - Then we assume that the blocks we use to build compound patterns are regular. - Then we check if the compound patterns are regular. - If they are regular we have completed the proof. - Letâ€™s start with checking the base cases, these are our basic building blocks, represented by atomic regular expressions: - is regular:ğ¿( Ïƒ) - is regular:ğ¿( Îµ) Computer Science / Software Engineering Notes Network - is regular:ğ¿( âŠ˜) - These are all atomic regular expressions we have to check, as # and @ are redundant, meaning that they can also be represented by compound patterns. - Now, assume that the building blocks we use to build compound patterns are regular. Then we will check if the compound patterns are regular: - ğ¿( Î± + Î²) = ğ¿( Î±) âˆª ğ¿( Î²) - We have already proved above that the union of two regular languages is regular. - ğ¿( Î±Î²) = ğ¿( Î±) ğ¿( Î²) - It was also proved above that the concatenation of two languages are regular. - ğ¿( Î±* ) = ğ¿( Î±) * - Again, we have proved above that kleene star is regular. - These are all compound regular expressions we have to check as all other compound regular expressions are redundant, meaning that they can also be represented by other compound patterns. - Now we have completed the proof that from any regular expression we can construct an automaton. ÎµNFA to reg exp - First of all, letâ€™s simply state what we want to do. We want to prove that there is always a way to convert an ÎµNFA to a regular expression. - We will construct an NFA ğ‘€ = ( ğ‘„, Î£, âˆ†, ğ‘ , ğ¹) - is the set of statesğ‘„ - is the alphabetÎ£ - is the transition functionâˆ† - is the start stateğ‘  - is the set of final statesğ¹ - This is what we want:the regular expression which describes all possible pathsÎ±ğ‘¢,ğ‘£ ğ‘‹ - starting at the state u - ending at the state v - passing through 0 or more intermediary states, which are in the set X. - Itâ€™s important to note that we do not need to pass through any intermediate states in X, but we have the opportunity to pass through as many as we want. Computer Science / Software Engineering Notes Network - If we can define the regex mathematically, then weâ€™ve shown that we canÎ±ğ‘¢,ğ‘£ ğ‘‹ convert an ÎµNFA to a regex, thereby finishing our proof. - We shall prove this by induction! In case youâ€™ve forgotten, proof by induction goes like this: 1. Base case 2. Inductive step - Yes, there will be some weird maths language, but donâ€™t worry;Iâ€™ll translate it for you. It sounds scary at first, but once you see the proof, itâ€™s not that bad: Step Weird maths lan guage No rmal En glish + p retty p ictures Base case Let ğ‘ 1 , ğ‘ 2 , ğ‘ 3 ... be all symbols such that Î´( ğ‘¢, ğ‘ ğ‘–) = ğ‘£ for 1 â‰¤ ğ‘– â‰¤ ğ‘˜ 1 . ğ‘–ğ‘“ ğ‘¢ â‰  ğ‘£ ğ‘ğ‘›ğ‘‘ ğ‘˜ > 0 Î± ğ‘¢,ğ‘£ Ã˜ = ğ‘ 1 + ğ‘ 2 + ğ‘ 3 + ...{ } 2 . ğ‘–ğ‘“ ğ‘¢ â‰  ğ‘£ ğ‘ğ‘›ğ‘‘ ğ‘˜ = 0 Î± ğ‘¢,ğ‘£ Ã˜ = Ã˜ 3 . ğ‘–ğ‘“ ğ‘¢ = ğ‘£ ğ‘ğ‘›ğ‘‘ ğ‘˜ > 0 Î± ğ‘¢,ğ‘£ Ã˜ = Îµ + ğ‘ 1 + ğ‘ 2 + ... + Îµ{ } 4 . ğ‘–ğ‘“ ğ‘¢ = ğ‘£ ğ‘ğ‘›ğ‘‘ ğ‘˜ = 0 Î± ğ‘¢,ğ‘£ Ã˜ = Îµ{ } Firstly, our base case. The simplest case is going from the initial state to the final state without going through any intermediate states. This is what weâ€™re defining on the left here; from top to bottom, weâ€™re defining 1. If the initial state isnâ€™tthe same as the final state and there are transitions from initial state to final state 2. If the initial state isnâ€™tthe same as the final state and there are no transitions from initial state to final state 3. If the initial state is the final state and there are transitions from the initial state to the final state 4. If the initial state is the final state and there are no transitions from the initial state to the final state All those symbols are allğ‘1 , ğ‘2 , ğ‘3 ... transitions that go straight from the initial state to the final state. Inductive step Î± ğ‘¢,ğ‘£ ğ‘‹+ { ğ‘} = Î± ğ‘¢,ğ‘£ ğ‘‹ + Î± ğ‘¢,ğ‘ ğ‘‹ ( Î± ğ‘,ğ‘ ğ‘‹ ) * Î± ğ‘,ğ‘£ ğ‘‹ First, we have a proposition (assumption). We propose that exists and works.Î± ğ‘¢,ğ‘£ ğ‘‹ Then, we define a out of .Î± ğ‘¢,ğ‘£ ğ‘‹+ { ğ‘} Î± ğ‘¢,ğ‘£ ğ‘‹ Once we do that, weâ€™ve defined our inductive step. By doing this, we show that if there exists a regex from u to v through intermediate states X, there also exists a regex from u to v with Computer Science / Software Engineering Notes Network intermediate states X + {q}, where â€˜qâ€™is any other state in the automata. This means we can keep adding on states from our base case until weâ€™ve filled inÎ± ğ‘¢,ğ‘£ Ã˜ all the states in our automata. - As you can see from the proof, we can just keep adding on new states to our . Thatğ‘‹ means we can add our initial state and final state to this regular expression, and then append all the intermediate states onto and itâ€™ll work.ğ‘‹ - Thatâ€™s great, but how do you actually convert an ÎµNFA to a regular expression? Weâ€™ve proved that we can do it, so how do we actually do it? - Below youâ€™ll see an example of how to actually convert an ÎµNFA into a regular expression. It involves breaking down the regex you need by taking out intermediate states, until you get something trivial, then working your way back up again. - EXAMPLE: - Given the following NFA - We need to find a regular expression that starts at state A, ends at state C and passes through any of A,B,C zero or more times. - Therefore, we are looking for Î±ğ´,ğ¶ { ğ´,ğµ,ğ¶} - The starting state u is going to be A - The ending state v is going to be C - The set of states which we can pass through X is equal to Q - Now, we are going to rewrite this regular expression using the formula above - We are going to pull out one of the states from X - It is best to choose a state that reduces the paths we can go a lot - Iâ€™m going to pull out B. This gives: Î± ğ´,ğ¶ { ğ´,ğµ,ğ¶} = Î± ğ´,ğ¶ { ğ´,ğ¶} + { ğµ} =Î± ğ´,ğ¶ { ğ´,ğ¶} + Î± ğ´,ğµ { ğ´,ğ¶} ( Î± ğµ,ğµ { ğ´,ğ¶} ) * Î± ğµ,ğ¶ { ğ´,ğ¶} Computer Science / Software Engineering Notes Network - We can decompose this further into Î±ğ´,ğ¶ { ğ´,ğ¶} = Î±ğ´,ğ¶ { ğ´} + { ğ¶} = Î±ğ´,ğ¶ { ğ´} + Î±ğ´,ğ¶ { ğ´} ( Î±ğ¶,ğ¶ { ğ´} ) * Î±ğ¶,ğ¶ { ğ´} Î±ğ´,ğµ { ğ´,ğ¶} = Î±ğ´,ğµ { ğ¶} + { ğ´} = Î±ğ´,ğµ { ğ¶} + Î±ğ´,ğ´ { ğ¶} ( Î±ğ´,ğ´ { ğ¶} ) * Î±ğ´,ğµ { ğ¶} Î±ğµ,ğ¶ { ğ´,ğ¶} = Î±ğµ,ğ¶ { ğ´} + { ğ¶} = Î±ğµ,ğ¶ { ğ´} + Î±ğµ,ğ¶ { ğ´} ( Î±ğ¶,ğ¶ { ğ´} ) * Î±ğ¶,ğ¶ { ğ´} - It is up to you how far you decompose. - If you are able to see what the regular expression is right away, you donâ€™t need to decompose. However, if you barely decompose, the chances that you miss a path are high. - We could decompose what we have got now even further, but I donâ€™t think that it is necessary to do so as the regular expressions for these are fairly easy to find. - Letâ€™s take a look at the first decomposed regular expression: b + b(a+b)*(a+b) = b(a+b)*Î±ğ´,ğ¶ { ğ´,ğ¶} = - Any string that starts with b or that starts with b followed by one or more mixed aâ€™s and/or bâ€™s will be matched. This can be simplified into a string starting with b followed by zero or more mixed aâ€™s and/or bâ€™s. - Letâ€™s take a look at the second decomposed regular expression: a + Îµ(Îµ)*a = a + a = aÎ±ğ´,ğµ { ğ´,ğ¶} = - Any string that contains exactly one a will be matched. - Letâ€™s take a look at the third decomposed regular expression: a + a(a+b)*(a+b) = a(a+b)*Î±ğµ,ğ¶ { ğ´,ğ¶} = - This is very similar to the first one. It will match a string starting with a followed by zero or more mixed aâ€™s and/or bâ€™s. - As you might have noticed, I didnâ€™t decompose the blue part. The reason for that is that the blue regular expression starts and ends in the same state, meaning that it can only take transitions to the state itself (if exists): - bÎ± ğµ,ğµ { ğ´,ğ¶} = - Any string that contains exactly one b will be matched. - Now, letâ€™s put together the regular expressions from the coloured parts: Computer Science / Software Engineering Notes Network - b(a+b)* + ab*a(a+b)*Î± ğ´,ğ¶ { ğ´,ğµ,ğ¶} = - This is the regular expression that is represented by this NFA - we are done! - Often, there is more than one regular expression that is represented by an automaton, meaning that there is no single correct solution. For example, the regular expression (ab*a + b)(a + b)* is correct as well. Limitations of regular languages - Is every language regular? No! - For example, look at the language { ğ‘ ğ‘› ğ‘ ğ‘› | ğ‘› âˆˆ â„•} - Our automaton has finitely many states. - Itâ€™s going to scan the string from the left to the right, starting with the aâ€™s. - Then, when itâ€™s going to scan the bâ€™s, it has to remember how many aâ€™s there were previously. - Since n can be infinitely big, there is no way to do this with our finite number of states! - We are going to prove by contradiction that the language is not{ ğ‘ ğ‘› ğ‘ ğ‘› | ğ‘› âˆˆ â„•} regular. - Suppose we have an automaton that accepts this language. Since theğ‘€ number of states it has is finite, we are going to say that it has states.ğ‘˜ - Next, we are going to choose such that . We can always find an thatğ‘› ğ‘› > ğ‘˜ ğ‘› is greater than because is not bounded, i.e. can be infinitely large.ğ‘˜ ğ‘› - Now, our automaton is going to start to scan the â€™s from the left to the right.ğ‘› ğ‘ Since we have less states than the number of aâ€™s, there must be a state we are going to enter at least twice (pigeonhole principle)! We are going to call this state . Between the first time we enter and the second time we enterğ‘ ğ‘ ğ‘ we are going to scan â€™s. After the second time we entered our automatonğ‘™ ğ‘ ğ‘ is going to continue to the final state. - When the automaton enters state for the first time, it goes on a path thatğ‘ leads it to again. Then, after arriving at for the second time, it goes on ağ‘ ğ‘ path that leads it to the final state. - Here is the problem:Why arrive at , and then take a path that leads toğ‘ ğ‘ again? Why not take the path that goes to the final state upon arriving at forğ‘ the first time? This means that our automaton would accept a string with Computer Science / Software Engineering Notes Network number of â€™s. However, now the number of â€™s is not anymore equal toğ‘› âˆ’ ğ‘™ ğ‘ ğ‘ the number of â€™s and here we have our contradiction!ğ‘ Pumping (ğŸƒ) Lemma for regular languages - contrapositive form - We can use the contrapositive form of the pumping lemma for regular languages to show that a language is not regular. We cannot use the pumping lemma to show that a language is regular! - It works by splitting up the language into parts, then â€œpumpingâ€ a subpart until you get a string that isnâ€™t in the language. This is similar to what we have just done before. - The different steps of the proof can be understood as a game versus a demon. 1. The demon chooses a number such that .ğ‘˜ ğ‘˜ > 0 - We cannot choose a value for k, we only know that it is greater than 0. 2. We choose a string such that .ğ‘¥ğ‘¦ğ‘§ âˆˆ ğ¿ ğ‘¦| |â‰¥ ğ‘˜ - We can choose any string that is within the language. However, we haveğ‘¥ğ‘¦ğ‘§ to make sure that, no matter what k is, our string is always in theğ‘¥ğ‘¦ğ‘§ language. We do not need to cover the whole language with our string! - and can be empty, there is no restriction concerning them.ğ‘¥ ğ‘§ - The length of the part must be at least . A way to make sure that this isğ‘¦ ğ‘˜ always the case is to let the part be equal to something to the power of .ğ‘¦ ğ‘˜ - due to the lower bound of k.|ğ‘¦| ï¹¥0 - As a general tip, try to make as trivial as possible, like in the followingğ‘¦ example: - For instance, we could let to make sure that is at least long ( is ağ‘¦ = ğ‘ ğ‘˜ ğ‘¦ ğ‘˜ ğ‘ symbol from the alphabet). 3. The demon splits the part of the string into such that , i.e. Theğ‘¦ ğ‘¢ğ‘£ğ‘¤ ğ‘£| | > 0 ğ‘£ â‰  Îµ. whole string would be .ğ‘¥( ğ‘¢ğ‘£ğ‘¤) ğ‘§ - You cannot choose how the string is going to be split! All you know is that the part of the string is not going to be empty.ğ‘£ - Therefore, you have to do a general case and define such that every wayğ‘¢ğ‘£ğ‘¤ of splitting the string is possible and we do not introduce any restrictions. - and can be empty, there is no restriction concerning them.ğ‘¢ ğ‘¤ - For instance, if , then and because v cannot beğ‘¦ = ğ‘ ğ‘˜ ğ‘£ = ğ‘ ğ‘™ 1 â‰¤ ğ‘™ â‰¤ ğ‘˜ empty. Furthermore, the remaining part . If we add the two parts,ğ‘¢ğ‘¤ =ğ‘ ğ‘˜âˆ’ ğ‘™ we are going to get back to . Also, we havenâ€™t made any assumptionsğ‘¦ = ğ‘ ğ‘˜ about how the string is going to be split. 4. We pick an such that the string If this is the case we have provenğ‘– â‰¥ 0 ğ‘¥ğ‘¢ğ‘£ ğ‘– ğ‘¤ğ‘§ âˆ‰ ğ¿. that the language is not regular! - We can pick any we want as long as it is equal to or greater than 0.ğ‘– Computer Science / Software Engineering Notes Network - Our goal is to choose an such that the resulting string is outside of theğ‘– language. - For instance, and . If we now choose , we are goingğ‘£ = ğ‘ ğ‘™ ğ‘¢ğ‘¤ =ğ‘ ğ‘˜âˆ’ ğ‘™ ğ‘– = 0 to get . We have now removed â€™s compared to what we hadğ‘¢ğ‘£ 0 ğ‘¤ = ğ‘ ğ‘˜âˆ’ ğ‘™ ğ‘™ ğ‘ as in the step before, which was . Also we know that ,ğ‘¢ğ‘£ğ‘¤ ğ‘¢ğ‘£ğ‘¤ = ğ‘¦ =ğ‘ ğ‘˜ 1 â‰¤ ğ‘™ meaning that we removed at least one !ğ‘ 5. You MUST say â€œTherefore L is not regularâ€, if you donâ€™t, you will lose marks. - If this still doesnâ€™t make any sense, look at a few examples below, and then read the general case above again. Examp le D escrip tio n { ğ‘ ğ‘› ğ‘ ğ‘› | ğ‘› âˆˆ â„•} 1. The demon chooses such thatğ‘˜ ğ‘˜ > 0 2. Now choose a string and .ğ‘¥ğ‘¦ğ‘§ âˆˆ ğ¿ ğ‘¦| |â‰¥ ğ‘˜ - Iâ€™ll do it like , so and( Îµ) ( ğ‘ ğ‘˜ ) ( ğ‘ ğ‘˜ ) ğ‘¥ = Îµ, ğ‘¦ = ğ‘ ğ‘˜ , ğ‘§ = ğ‘ ğ‘˜ .ğ‘¥ğ‘¦ğ‘§ âˆˆ ğ¿ - For every value of I will get a specific string which isğ‘˜ in the language of .ğ‘ ğ‘› ğ‘ ğ‘› - It is ok that I cannot get the empty string ( which isğ‘ 0 ğ‘ 0 in the language) because I do not need to cover the whole language. 3. The demon splits your into a such thatğ‘¦ ğ‘¢ğ‘£ğ‘¤ ğ‘£ â‰  Îµ. - Now, we have to do the splitting in a general case. - Since cannot be empty, then and .ğ‘£ ğ‘£ = ğ‘ ğ‘™ 1 â‰¤ ğ‘™ â‰¤ ğ‘˜ - Since , then .ğ‘¢ğ‘£ğ‘¤ = ğ‘¦ =ğ‘ ğ‘˜ ğ‘¢ğ‘¤ =ğ‘ ğ‘˜âˆ’ ğ‘™ 4. We pick an such that the stringğ‘– â‰¥ 0 ğ‘¥ğ‘¢ğ‘£ ğ‘– ğ‘¤ğ‘§ âˆ‰ ğ¿. - Now for this example, choose ğ‘– = 0 . - Then as the number of bâ€™s will beğ‘¥ğ‘¢ğ‘£ 0 ğ‘¤ğ‘§ = ğ‘ ğ‘˜âˆ’ ğ‘™ ğ‘ ğ‘˜ âˆ‰ ğ¿ bigger than the number of aâ€™s, no matter what value k is. 5. Therefore L is not regular { ğ‘ ğ‘›! | ğ‘› âˆˆ â„•} 1. The demon chooses such thatğ‘˜ ğ‘˜ > 0 2. Now choose a string and .ğ‘¥ğ‘¦ğ‘§ âˆˆ ğ¿ ğ‘¦| |â‰¥ ğ‘˜ - Iâ€™m going to choose , soğ‘¥ = ğ‘ ( ğ‘˜+ 1 ) !âˆ’ ğ‘˜ , ğ‘¦ = ğ‘ ğ‘˜ , ğ‘§ = Îµ ğ‘¥ğ‘¦ğ‘§ = ( ğ‘ ( ğ‘˜+ 1 ) !âˆ’ ğ‘˜ ) ( ğ‘ ğ‘˜ ) ( Îµ) = ğ‘ ( ğ‘˜+ 1 ) ! âˆˆ ğ¿. 3. The demon splits your into a such thatğ‘¦ ğ‘¢ğ‘£ğ‘¤ ğ‘£ â‰  Îµ. - , as it cannot be empty we have .ğ‘£ = ğ‘ ğ‘™ 1 â‰¤ ğ‘™ â‰¤ ğ‘˜ - The remaining part becauseğ‘¢ğ‘¤ = ğ‘ ğ‘˜âˆ’ ğ‘™ ğ‘¢ğ‘£ğ‘¤ = ğ‘¦ = ğ‘ ğ‘˜ Computer Science / Software Engineering Notes Network 4. We pick an such that the stringğ‘– â‰¥ 0 ğ‘¥ğ‘¢ğ‘£ ğ‘– ğ‘¤ğ‘§ âˆ‰ ğ¿. - We pick ğ‘– = 2 . - Then ğ‘¥ğ‘¢ğ‘£ 2 ğ‘¤ğ‘§ = ğ‘ ( ğ‘˜+ 1 ) !âˆ’ ğ‘˜ ğ‘ ğ‘˜âˆ’ ğ‘™ ğ‘ 2 ğ‘™ = ğ‘ ( ğ‘˜+ 1 ) !+ ğ‘™ =âˆ‰ ğ¿ because the power we have got here is not going to be a factorial! - Let me prove why this is not going to be a factorial: - is going to be some factorial .( ğ‘˜ + 1 ) ! â‰¥ 2 ! - The next higher factorial is going to be .( ğ‘˜ + 2 ) ! - However, our power is going to be( ğ‘˜ + 1 ) ! + ğ‘™ in the middle of these two factorials: Therefore,( ğ‘˜ + 1 ) ! < ( ğ‘˜ + 1 ) ! + ğ‘™ < ( ğ‘˜ + 2 ) !. it cannot be a factorial! - If you still have some doubts, try it out with the smallest k we could have, . Then chooseğ‘˜ = 1 the largest l we can choose, . So we haveğ‘™ = 1 which holds. For any choice of2 ! < 2 ! + 1 < 3 ! the next higher factorial is going to growğ‘˜ > 1 even faster, therefore this will always hold. 5. Therefore L is not regular { ğ‘ ğ‘› | ğ‘› ğ‘–ğ‘  ğ‘ğ‘Ÿğ‘–ğ‘šğ‘’} 1. The demon chooses such thatğ‘˜ ğ‘˜ > 0 2. Now choose a string and .ğ‘¥ğ‘¦ğ‘§ âˆˆ ğ¿ ğ‘¦| |â‰¥ ğ‘˜ - Iâ€™m going to choose where isğ‘¥ = Îµ, ğ‘¦ = ğ‘ ğ‘ , ğ‘§ = Îµ ğ‘ going to be the next prime number . Since theâ‰¥ ğ‘˜ number of primes is infinite this will always work, no matter how large is.ğ‘˜ - Therefore, ğ‘¥ğ‘¦ğ‘§ = ğ‘ ğ‘ âˆˆ ğ¿. 3. The demon splits your into a such thatğ‘¦ ğ‘¢ğ‘£ğ‘¤ ğ‘£ â‰  Îµ. - The length of is going to be , soğ‘¢ğ‘£ğ‘¤ ğ‘ |ğ‘¢ğ‘£ğ‘¤| = ğ‘. - Since we haveğ‘¥ = ğ‘§ = Îµ |ğ‘¥ğ‘¢ğ‘£ğ‘¤ğ‘§| = ğ‘. - Thatâ€™s all info we need to continue our proof, you will see why in the next step. 4. We pick an such that the stringğ‘– â‰¥ 0 ğ‘¥ğ‘¢ğ‘£ ğ‘– ğ‘¤ğ‘§ âˆ‰ ğ¿. - We will pick ğ‘– = ğ‘ + 1 . - Iâ€™m going to show that the length of is notğ‘¥ğ‘¢ğ‘£ ğ‘+ 1 ğ‘¤ğ‘§ going to be equal to a prime number, therefore it is outside of the language. - |ğ‘¥ğ‘¢ğ‘£ ğ‘– ğ‘¤ğ‘§| = |ğ‘¥ğ‘¢ğ‘£ ğ‘+ 1 ğ‘¤ğ‘§| = |ğ‘¥ğ‘¢ğ‘£ 1 ğ‘¤ğ‘§| + |ğ‘£ ğ‘ | = ğ‘ + |ğ‘£ ğ‘ | = , which is not going to be a prime= ğ‘ * ( 1 + |ğ‘£|) number since we also have a factor here but( 1 + |ğ‘£|) prime numbers should only be divisible by 1 or itself (p). - Therefore, ğ‘¥ğ‘¢ğ‘£ ğ‘+ 1 ğ‘¤ğ‘§ âˆ‰ ğ¿. Computer Science / Software Engineering Notes Network 5. Therefore L is not regular { ğ‘šğ‘š ğ‘… | ğ‘š âˆˆ Î£ * , ğ‘š ğ‘… ğ‘–ğ‘  ğ‘–ğ‘¡ğ‘  ğ‘Ÿğ‘’ğ‘£ğ‘’ğ‘Ÿğ‘ ğ‘’} and |Î£| â‰¥ 2 1. The demon chooses such thatğ‘˜ ğ‘˜ > 0 2. Now choose a string and .ğ‘¥ğ‘¦ğ‘§ âˆˆ ğ¿ ğ‘¦| |â‰¥ ğ‘˜ - Iâ€™m going to choose whereğ‘¥ = Îµ, ğ‘¦ = ğ‘’ ğ‘˜ , ğ‘§ = ğ‘‘ğ‘‘ğ‘’ ğ‘˜ andğ‘‘, ğ‘’ âˆˆ Î£ ğ‘‘ â‰  ğ‘’ - ğ‘¥ğ‘¦ğ‘§ = ğ‘’ ğ‘˜ ğ‘‘ğ‘‘ğ‘’ ğ‘˜ âˆˆ ğ¿ - The demon splits your into a such thatğ‘¦ ğ‘¢ğ‘£ğ‘¤ ğ‘£ â‰  Îµ. - ğ‘£ = ğ‘’ ğ‘™ - ğ‘¢ğ‘¤ = ğ‘’ ğ‘˜âˆ’ ğ‘™ - 1 â‰¤ ğ‘™ â‰¤ ğ‘˜ 4. We pick an such that the stringğ‘– â‰¥ 0 ğ‘¥ğ‘¢ğ‘£ ğ‘– ğ‘¤ğ‘§ âˆ‰ ğ¿. - Pick ğ‘– = 0 - Now and because weğ‘¥ğ‘¢ğ‘£ 0 ğ‘¤ğ‘§ = ğ‘’ ğ‘š ğ‘‘ğ‘‘ğ‘’ ğ‘˜ ğ‘š â‰  ğ‘˜ deleted at least one by letting .ğ‘’ ğ‘– = 0 - Therefore ğ‘¥ğ‘¢ğ‘£ 0 ğ‘¤ğ‘§ âˆ‰ ğ¿ 5. Therefore L is not regular Automata theory:Context free languages Pushdown Automata (PDA) - Pushdown automata are an extension to the automata we have seen before. - We will take an and add a stack to the control unit.Îµğ‘ğ¹ğ´ - The stack does not have a size limit, i.e. is infinitely big. - More formally, a PDA is a 7 tuple ğ‘€ = ( ğ‘„, Î£, Î“, Î´, ğ‘ , âŠ¥, ğ¹) - is the set of statesğ‘„ - is the input alphabetÎ£ - is the stack alphabet (the set of things we can put on the stack)Î“ - is the transition relation (more detail see below)Î´ - is the start stateğ‘  âˆˆ ğ‘„ - is the initial stack symbolâŠ¥ - is the set of final statesğ¹ âŠ† ğ‘„ Transition relation - Now, letâ€™s take a closer look at the transition relation :Î´ Î´ âŠ† ( ğ‘„Ã— ( Î£ âˆª { Îµ} ) Ã—Î“) Ã— ( ğ‘„Ã—Î“ * ) - is the state the PDA is currently in.ğ‘„ Computer Science / Software Engineering Notes Network - is the symbol we are currently reading. This symbol could be anyÎ£ âˆª { Îµ} symbol from our alphabet or epsilon, which means that we can do epsilon moves by reading nothing! - is the symbol which is currently on top of the stack. When we make aÎ“ transition we are going to pop (remove) this symbol from the top of the stack. - is the resulting state after we have made the transition.ğ‘„ - is going to be 0 or more symbols from our stack alphabet that we are goingÎ“ * to push on the stack when we make the transition. - Letâ€™s look at how one tuple of our transition relation looks like: Î´ âˆ‹ ( ( ğ‘,Ïƒ,Î³) , ( ğ‘ ' ,Î³ 1 Î³ 2 ... Î³ ğ‘˜) ) Here, we are in the state , we will read the symbol , and we see on top of theğ‘ Ïƒ Î³ stack. We will then pop (remove) off the stack, go to the next state and pushÎ³ ğ‘ ' (add) on the stack. We will start pushing with and end with , such thatÎ³ 1 Î³ 2 ... Î³ ğ‘˜ Î³ ğ‘˜ Î³ 1 we now have on top of the stack.Î³ 1 - Keep in mind that if is not on the top of the stack, we cannot perform this transition.Î³ Think of it as like a â€œsecond inputâ€. - Graphically, the transition looks like this: Configuration - A configuration is a complete description of our PDA at a certain point in time. It is represented as an element of: Configurations âŠ† ( ğ‘„Ã—Î£ * Ã—Î“ * ) - is the current state.ğ‘„ - is the whole part of the input we still have left to scan/read. Note that thisÎ£ * is not only the next symbol. - is the whole stack content. Note that this is not only the symbol on top ofÎ“ * the stack;itâ€™s the entire thing. - Therefore, every configuration will be of the form Configurations âˆ‹ ( ğ‘,Ïƒ 1 Ïƒ 2 ... Ïƒ ğ‘˜,Î³ 1 Î³ 2 ... Î³ ğ‘˜ âŠ¥) Computer Science / Software Engineering Notes Network - We can define relations between those configurations, which tell us how to go from one configuration to the next configuration. We have to distinguish between two cases:The case when we consume a symbol from the input, and the case where we donâ€™t consume any symbol and take an epsilon move. - Case 1:We consume a symbol. We write the relation as: ( ğ‘,Ïƒğ‘ ,Î³ğ‘”) â†’( ğ‘ ' ,ğ‘ ,â„ğ‘”) when there exists such an element in Î´ ( ( ğ‘,Ïƒ,Î³) , ( ğ‘ ' ,â„) ) âˆˆ Î´ - Case 2:We donâ€™t consume a symbol and take an epsilon move. We write the relation as: ( ğ‘,ğ‘ ,Î³ğ‘”) â†’( ğ‘ ' ,ğ‘ ,â„ğ‘”) when there exists such an element in Î´ ( ( ğ‘,Îµ,Î³) , ( ğ‘ ' ,â„) ) âˆˆ Î´ Acceptance - A PDA can accept a string either by empty stack or by final state. - We can turn a PDA that accepts by final state into a PDA that accepts by empty stack and vice versa. By final state - A PDA will accept a string by final state if we can go from the start configuration to a final configuration which contains a final state and where we donâ€™t have any string left to scan/consume. Between those two configurations there can be 0 or more other intermediary configurations which we pass through. - Formally, this is written as: ( ğ‘ ,ğ‘¥,âŠ¥) â‡’( ğ‘“,Îµ,ğ‘”) - We will start at state s with the whole input string x still remaining to scan, and our stack contains the initial stack symbol only. - We will go through as many intermediary states as we want to. - We will end in a state f where we donâ€™t have anything remaining to scan, and our stack content is g. - Therefore, the language accepted by the PDA is ğ¿( ğ‘€) = { ğ‘¥ | âˆƒğ‘“âˆˆ ğ¹ . ( ğ‘ ,ğ‘¥,âŠ¥) â‡’( ğ‘“,Îµ,ğ‘”) } By empty stack - A PDA will accept a string by empty stack if we can go from the start configuration to a final configuration where the stack is completely empty and where we donâ€™t have any string left to scan/consume. Between those two configurations there can be 0 or Computer Science / Software Engineering Notes Network more other intermediary configurations which we pass through. - Formally, this is written as: ( ğ‘ ,ğ‘¥,âŠ¥) â‡’( ğ‘,Îµ,Îµ) - We will start at state s with the whole input string x still remaining to scan, and our stack contains the initial stack symbol only. - We will go through as many intermediary states as we want to. - We will end in a state q where we donâ€™t have anything remaining to scan, and our stack is empty. - â€œStack is emptyâ€ means that we do n o t have or any other symbol on theâŠ¥ stack - Therefore, the language accepted by the PDA is ğ¿( ğ‘€) = { ğ‘¥ | âˆƒğ‘âˆˆ ğ‘„ . ( ğ‘ ,ğ‘¥,âŠ¥) â‡’( ğ‘,Îµ,Îµ) } Example PDA accepting palindromes - A Palindrome is a string where the reverse of that string is equal to the original string. - Examples:abba, abdba, aaaa - A PDA that will accept all palindromes by final state (and also empty stack) looks like this: where , i.e. is any symbol from our alphabet .Ïƒ âˆˆ Î£ Ïƒ Î£ - Letâ€™s start from scratch and build a PDA that looks like this. - We are going to differentiate between palindromes with an even number of symbols and those with an odd number of symbols - Our strategy for constructing the PDA that accepts palindromes with an even number of symbols will be the following: - We scan the word until we reach the middle of it. - Then we scan the second half of the word, expecting the symbols from the first half of the word in reverse order. - If this is the case, our word is a palindrome. - Now, we can assign a state for every step of our strategy Computer Science / Software Engineering Notes Network - We will be in state 1 when we scan the first half of the word. - We will be in state 2 when we scan the second half of the word. - We will be in the final state when we have finished scanning the whole word and the reverse of the first half is equal to the second half of the word. - Letâ€™s think about our transitions for each of our states: - When we are in state 1 - We will stay in state 1 and keep adding the current symbol to the stack if we havenâ€™t reached the middle of the word. - We will make a transition to state 2 when we have reached the middle of the word, without changing the stack. - When we are in state 2 - We will stay in state 2 and keep popping the current symbol from the stack as long as the current symbol is equal to the symbol at the top of the stack. - We will make a transition to the final state if our stack contains only the initial stack symbol, and remove the initial stack symbol. - However, there is still one problem:Palindromes with an odd number of symbols, such as â€œabdbaâ€. How to deal with them? We can throw away the symbol in the middle! For this example, it means that we throw away â€œdâ€ and we will check the remaining string â€œabbaâ€. We have already defined a PDA for checking palindromes with an even number of symbols above. - In order to integrate the â€œthrow away the middle symbolâ€ action into our existing PDA we will add one transition from state 1 to 2 where we consume a symbol but donâ€™t change the stack contents. - Some questions you might ask yourself are: - How does the PDA know when it has reached the middle of the word? - How does the PDA know that it has arrived at the middle symbol of an odd string, which can be thrown away? - The answer is that the PDA is going to guess. The PDA can do this because it is non-deterministic, similar to NFAs we have seen before. In other words, the PDA can take any of the transitions that are possible. - If we have a palindrome as a string and we process this palindrome, there will be one combination of transitions where the PDA will go into the final state at the end. - Letâ€™s simulate our PDA on the string â€œabcbaâ€, which is a palindrome: ( 0 ,ğ‘ğ‘ğ‘ğ‘ğ‘, âŠ¥) â†’( 0 , ğ‘ğ‘ğ‘ğ‘, ğ‘ âŠ¥) â†’( 0 , ğ‘ğ‘ğ‘,ğ‘ğ‘ âŠ¥) â†’( 1 , ğ‘ğ‘,ğ‘ğ‘ âŠ¥) â†’( 1 , ğ‘, ğ‘ âŠ¥) â†’( 1 , Îµ, âŠ¥) Computer Science / Software Engineering Notes Network â†’( 2 , Îµ, Îµ) The PDA has reached state 2 and will therefore accept. - Letâ€™s simulate our PDA on the string â€œabcdeâ€, which is not a palindrome: ( 0 ,ğ‘ğ‘ğ‘ğ‘‘ğ‘’, âŠ¥) â†’( 0 , ğ‘ğ‘ğ‘‘ğ‘’, ğ‘ âŠ¥) â†’( 0 , ğ‘ğ‘‘ğ‘’,ğ‘ğ‘ âŠ¥) â†’( 1 , ğ‘‘ğ‘’,ğ‘ğ‘ âŠ¥) X at this point our computation dies because there is no transition we could take (dâ†’ â‰  b). Therefore the PDA will reject. Context free grammars - A CFG, consisting of terminal and non-terminal symbols, is used to generate strings (sentences) by following its production rules. - The terminal symbols are the symbols which will form the string we are going to generate. - The non-terminal symbols are going to be replaced by other symbols. These other symbols can be terminals, non-terminals or a mix of both. - There exist so called â€œproductionsâ€ which tell us how to replace the non-terminal symbols. - We have to keep replacing non-terminal symbols until we arrive at a string that consists solely of terminal symbols. This process is called â€œderivationâ€. - The final string is also called a sentence. - Formally, a CFG is a quadruple ( ğ‘, Î£, ğ‘ƒ, ğ‘†) - is a finite set of nonterminal symbolsğ‘ - is a finite set of terminal symbolsÎ£ - are the productionsğ‘ƒ âŠ† ğ‘ Ã— ( ğ‘ + Î£) * - is the start nonterminalğ‘† âˆˆ ğ‘ - To define production rules â€¦ - we will use the shorthand ğ´ â†’ Î± to mean ( ğ´, Î±) âˆˆ ğ‘ƒ - we will use the shorthand ğ´ â†’ Î± 1 |Î± 2 |... |Î± ğ‘˜ to mean ğ´ â†’ Î± 1 , ğ´ â†’ Î± 2 ,..., ğ´ â†’ Î± ğ‘˜ - To express that is derivable from we will write orÎ² Î± Î± â‡’ Î² - Without :This means that given the string , we have applied someğ‘˜ Î± production rules and arrived at string Î². - With :This means that given the string , we have applied exactlyğ‘˜ Î± ğ‘˜ production rules and arrived at string Î². - The language generated by a CFG G is the set of all its sentences, i.e. the set of all strings that can be generated by using its production rules. Computer Science / Software Engineering Notes Network - ğ¿( ğº) = { ğ‘¥ âˆˆ Î£ * | ğ‘† â‡’ ğ‘¥} - The language generated is going to be equal to the set of all strings x that are derivable from the start non-terminal. - We can apply as many production rules as we want, as long as we end with a string (sentence) that solely consists of terminals. - This language L(G), generated by some CFG G, is called context-free (CFL). - If itâ€™s all still a bit too confusing for you, look at the table below, where we convert context-free languages into context-free grammars: Lan guage C o n vertin g it to a grammar { ğ‘ ğ‘› ğ‘ ğ‘› | ğ‘› âˆˆ â„•} - Every string with the same number of aâ€™s followed by the same number of bâ€™s will be in the language. - We have shown that this language is not regular, however, it is context free as we can come up with a CFG for it. - The CFG is ğ‘† â†’ ğ‘ğ‘†ğ‘ | Îµ - We can produce 0 aâ€™s and bâ€™s, i.e. the empty string, by applying only the second production rule: ğ‘† â‡’ Îµ - We can produce 1 a and 1 b by applying the first production rule once and the second production rule last: ğ‘† â‡’ ğ‘ğ‘†ğ‘ â‡’ ğ‘ğ‘ - We can produce 2 aâ€™s and 2 bâ€™s by applying the first production rule 2 times and the second production rule last: ğ‘† â‡’ ğ‘ğ‘†ğ‘ â‡’ ğ‘ğ‘ğ‘†ğ‘ğ‘â‡’ ğ‘ğ‘ğ‘ğ‘ - Therefore, we can produce aâ€™s and bâ€™s by applyingğ‘› ğ‘› the first production rule times and the secondğ‘› production rule last. - We achieve this through pumping in the middle ofğ‘ğ‘†ğ‘ the string every time we want to add an and a .ğ‘ ğ‘ { ğ‘ ğ‘› ğ‘ ğ‘› | ğ‘› > 0 } - ğ‘† â†’ ğ‘ğ‘†ğ‘ | ğ‘ğ‘ { ğ‘ ğ‘› ğ‘ ğ‘š ğ‘ 2 ğ‘› | ğ‘›, ğ‘š > 0 } - ğ‘† â†’ ğ‘ğ‘†ğ‘ğ‘ | ğ‘ğµğ‘ğ‘ - ğµ â†’ ğ‘ğµ | ğ‘ { ğ‘ ğ‘› ğ‘ ğ‘š ğ‘ 2 ğ‘› | ğ‘›, ğ‘š â‰¥ 0 } - ğ‘† â†’ ğ‘ğ‘†ğ‘ğ‘ | ğµ - ğµ â†’ ğ‘ğµ | Îµ L(G) is the set of all palindromes over the alphabet Î£ = { ğ‘, ğ‘, ğ‘} - ğ‘† â†’ ğ‘ğ‘†ğ‘ | ğ‘ğ‘†ğ‘ | ğ‘ğ‘†ğ‘ | ğ‘ | ğ‘ | ğ‘ | Îµ Computer Science / Software Engineering Notes Network L(G) is the set of all balanced parentheses - ğ‘† â†’ ( ğ‘†) | ( ) | ğ‘†ğ‘† { ğ‘¦ğ‘ 2 ğ‘› ğ‘¥ | ğ‘› â‰¥ 0 , ğ‘¦, ğ‘¥ âˆˆ { ğ‘} * , |ğ‘¦ğ‘¥| = ğ‘›} En glish, p lease So you have a bunch of â€˜aâ€™s, then a bunch of â€˜bâ€™s, then another bunch of â€˜aâ€™s. There needs to be twice as many â€˜bâ€™s as â€˜aâ€™s. Examples: Îµ abb abbbb a bbbb aa - Simplify: ğ¿( ğº) = { ğ‘ ğ‘˜ ğ‘ 2 ( ğ‘˜+ ğ‘‘) ğ‘ ğ‘‘ | ğ‘˜ + ğ‘‘ â‰¥ 0 } - We know that and are just going to beğ‘¦ ğ‘¥ repetitions of the letter ğ‘. - We let , then we can use those for theğ‘› = ğ‘˜ + ğ‘‘ number of times we repeat the first and the lastğ‘ . We put and in the correspondingğ‘ ğ‘˜ ğ‘‘ exponents to denote these repetitions. - Simplify further: ğ¿( ğº) = { ğ‘ ğ‘˜ ğ‘ 2 ğ‘˜ ğ‘ 2 ğ‘‘ ğ‘ ğ‘‘ | ğ‘˜ â‰¥ 0 , ğ‘‘ â‰¥ 0 } - We use and to denote repetitions of theğ‘˜ ğ‘‘ letters, so they canâ€™t be negative. For example, what would mean? It doesnâ€™t make sense,ğ‘ âˆ’ 1 as we canâ€™t repeat the letter minus one times.ğ‘ - We split into . No magic here,ğ‘ 2 ( ğ‘˜+ ğ‘‘) ğ‘ 2 ğ‘˜ ğ‘ 2 ğ‘‘ just exponent rules. - We can now split this into two grammars which we will then concatenate, because CFL are closed under concatenation. - One will be for the first half:{ ğ‘ ğ‘˜ ğ‘ 2 ğ‘˜ | ğ‘˜ â‰¥ 0 } - ğ¿ â†’ ğ‘ğ¿ğ‘ğ‘ | Îµ - One will be for the second half:{ ğ‘ 2 ğ‘‘ ğ‘ ğ‘‘ | ğ‘‘ â‰¥ 0 } - ğ‘… â†’ ğ‘ğ‘ğ‘…ğ‘ | Îµ - Now, the final grammar will be the concatenation of the grammar for the left and the right part: - ğ‘† â†’ ğ¿ğ‘… - ğ¿ â†’ ğ‘ğ¿ğ‘ğ‘ | Îµ - ğ‘… â†’ ğ‘ğ‘ğ‘…ğ‘ | Îµ Chomsky Normal Form - A CFG is in Chomsky normal form (CNF) when all productions are of the form - ğ´ â†’ ğµğ¶ Two non-terminals are derivable by one non-terminal - ğ´ â†’ Î± One terminal is derivable by one non-terminal - Note that we donâ€™t have here, therefore we cannot generate the empty string.Îµ - Chomsky normal form is harder to convert into a PDA, but itâ€™s used in things like the CYK algorithm which parses context-free grammars. Computer Science / Software Engineering Notes Network Lan guage C FG in C ho msky No rmal Fo rm ğ¿( ğº) = { ğ‘ ğ‘› ğ‘ ğ‘› | ğ‘› > 0 } - ğ‘† â†’ ğ‘‹ğµ | ğ´ğµ - ğ´ â†’ ğ‘ - ğµ â†’ ğ‘ - ğ‘‹ â†’ ğ´ğ‘† ğ¿( ğº) = { ğ‘ ğ‘› ğ‘ ğ‘š ğ‘ 2 ğ‘› | ğ‘›, ğ‘š > - ğ‘† â†’ ğ‘‹ğ¶' | ğ‘Œğ¶' - ğ‘‹ â†’ ğ´ğ‘† - ğ‘Œ â†’ ğ´ğµ' - ğ´ â†’ ğ‘ - ğµ' â†’ ğµ'ğµ | ğ‘ - ğµ â†’ ğ‘ - ğ¶' â†’ ğ¶ğ¶ - ğ¶ â†’ ğ‘ Greibach Normal Form - A CFG is in Greibach normal form (GNF) when all productions are of the form - whereğ´ â†’ Î±ğµ 1 ğµ 2 ...ğµ ğ‘˜ ğ‘˜ â‰¥ 0 One terminal followed by non-terminals is derivable by one non-terminalğ‘˜ - Note that we donâ€™t have here, therefore we cannot generate the empty string.Îµ - Greibach normal form makes it easier to show that there is a PDA for every CFG, and can also be used with recursive descent parsers. Lan guage C FG in Greibach No rmal Fo rm ğ¿( ğº) = { ğ‘ ğ‘› ğ‘ ğ‘› | ğ‘› > 0 } - ğ‘† â†’ ğ‘ğ‘†ğµ | ğ‘ğµ - ğµ â†’ ğ‘ ğ¿( ğº) = { ğ‘ ğ‘› ğ‘ ğ‘š ğ‘ 2 ğ‘› | ğ‘›, ğ‘š > 0 - ğ‘† â†’ ğ‘ğ‘†ğ¶' | ğ‘ğµğ¶' - ğµ â†’ ğ‘ğµ | ğ‘ - ğ¶' â†’ ğ‘ğ¶ - ğ¶ â†’ ğ‘ Removing epsilon and unit productions - A production of the form is called an epsilon productionğ´ â†’ Îµ - Assume we have another production ğµ â†’ Î±ğ´Î² - We can get rid of the epsilon production and refine this production - Our new refined and only production will be ğµ â†’ Î±Î² Video with example: Simplification of CFG (Removal of Null Productions) - A production of the form is is a called a unit productionğ´ â†’ ğµ Computer Science / Software Engineering Notes Network - Assume we have another production ğµ â†’ Î± - We can get rid of this production and refine the unit production - Our new refined and only production will be (Instead of A B , weğ´ â†’ Î± â†’ â†’ Î± are removing the step in the middle) Helpful video with example: Simplification of CFG (Removal of Unit Productions) - Since we can remove both epsilon and unit productions, we can conclude that for every CFG there exists another CFG that accepts the same language, except that it cannot accept epsilon: ğ¿( ğº ' ) = ğ¿( ğº) âˆ’ { Îµ} Where is the grammar but without any epsilon or unit productionsğº ' ğº Removing left-recursive productions - This is o n ly req uired fo r co n versio n to GNF an d therefo re n o t examin able - A left-recursive production looks like the following: ğ´ â†’ ğ´Î± | Î² - This rule generates a string starting with exactly one and ending with one or moreÎ² Î± - It is left recursive because when we want to generate more , we are going toÎ± prepend them to the string, i.e. we are going to add them on the left side of the string. - In other words, we are generating the string from the right to the left, starting with the rightmost (last) symbol. - Every left recursive rule must have the part because it allows us to break out of| Î² our recursion, i.e. it allows us to end â€œspammingâ€ , by replacing the non-terminalÎ± ğ´ with at some point in our derivation.Î² - We want to eliminate the left recursion in ğ´ â†’ ğ´Î± | Î² - We know this rule produces whereÎ²Î± ğ‘› ğ‘› â‰¥ 1 - We can easily create with this new rule:Î± ğ‘› - ğ· â†’ Î±ğ· | Î± - Now, we need to add another rule to produce the in front:Î² - ğ¶ â†’ Î²ğ· - So in total we need these two rules to eliminate the left-recursion: - ğ¶ â†’ Î²ğ· - ğ· â†’ Î±ğ· | Î± - In general, we can have multiple alternatives that are left-recursive, and multiple alternatives to break out of our left-recursion. We have to get rid of all of them. - Our left-recursive production is in the form ğ´ â†’ ğ´Î± 1 | ğ´Î± 2 | ... | ğ´Î± ğ‘˜ | Î² 1 | Î² 2 | ... | Î² ğ‘™ - For every alpha, we need the following new rule: - ğ· â†’ Î± ğ‘˜ğ· | Î± ğ‘˜ Computer Science / Software Engineering Notes Network - For every beta, we need the following new rule: - ğ¶ â†’ Î² ğ‘™ğ· - So all in all, we need the following rules for every alpha, beta: - ğ¶ â†’ Î² ğ‘™ğ· - ğ· â†’ Î± ğ‘˜ğ· | Î± ğ‘˜ - What? You still donâ€™t understand? - No, donâ€™t feel bad! Have a look at a few examples below, they might help: With left-recursio n Witho ut left-recursio n ğ´ â†’ ğ´Î± | Î² ğ´ â†’ Î²ğ´' ğ´' â†’ Î±ğ´' | Î± ğ¸ â†’ ğ¸ + ğ‘‡ | ğ‘‡ ğ¸ â†’ ğ‘‡ğ¸' ğ¸' â†’ + ğ‘‡ğ¸' | + ğ‘‡ ğ´ â†’ ğ´ğµÎ± | ğ´ğ‘ | ğ‘ ğ´ â†’ ğ‘ğ´' ğ´' â†’ ğµÎ±ğ´' | ğ‘ğ´' | ğµÎ± | Î± ğ´ â†’ ğ´ğ¶ | ğ´ğ‘ğ‘‘ | ğ‘ğ‘ | ğ¶ ğ´ â†’ ğ‘ğ‘ğ´' | ğ¶ğ´' ğ´' â†’ ğ¶ğ´' | ğ‘ğ‘‘ğ´' | ğ¶ | ğ‘ğ‘‘ - You donâ€™t get it? Yare yare daze... itâ€™s alright. There are just some topics that are really hard to master. We wonâ€™t judge. - What better last-resort revision technique to fall back on than Indian YouTubers? - For this topic, I recommend this one. Sure, he leaves his answers with epsilon productions, but all the examples above are from this video and itâ€™s really easy to follow. Converting between CFG, CNF and GNF - For any context-free grammar, there exists a corresponding CNF and GNF that produces the same language, except epsilon. Converting a CFG to CNF 1. Remove all epsilon and unit productions like described above 2. For all add a new nonterminal to our set of non-terminalsÏƒ âˆˆ Î£ ğ‘ Ïƒ ğ‘ - We will now have a new non-terminal symbol for each of our symbols in the alphabet - We will use these later when we define some new productions Computer Science / Software Engineering Notes Network 3. In all productions, replace any terminal with the the non-terminalÏƒ ğ‘ Ïƒ - We will replace all terminal symbols in every production by the new non-terminal symbols we have generated in the step before 4. Add productions to our set of productionsğ‘ Ïƒ â†’ Ïƒ ğ‘ƒ - We will need those productions to produce the terminals, since we replaced all of them with our new non-terminals.ğ‘ Ïƒ 5. While there exists a production ... with , i.e. while thereğ´ â†’ ğµ 1 ğµ 2 ğµ ğ‘˜ ğ‘˜ > 2 exists a production that derives more than 2 non-terminals and therefore cannot be in CNF - Remove this production from ğ‘ƒ - Add a new non-terminal toğ¶ ğ‘ - It has to have a different name in every iteration of this â€œwhile-loopâ€ - Add the following two productions to ğ‘ƒ - ğ´ â†’ ğµ 1 ğ¶ - ğ¶ â†’ ğµ 2 ... ğµ ğ‘˜ - Now our grammar is in CNF. - If this is a little hard to take in, try following through the example below: Step Pro gress D escrip tio n 0 ğ‘† â†’ ğ´ğ‘†ğµ ğ´ â†’ ğ‘ğ´ğ‘† | ğ‘ | Îµ ğµ â†’ ğ‘†ğ‘ğ‘† | ğ´ | ğ‘ğ‘ We havenâ€™t done anything yet, I just wanted to show you the grammar first before we start converting it. Itâ€™s on the left. 1 Remove ğ´ â†’ Îµ ğ‘† â†’ ğ´ğ‘†ğµ | ğ‘†ğµ ğ´ â†’ ğ‘ğ´ğ‘† | ğ‘ | ğ‘ğ‘† ğµ â†’ ğ‘†ğ‘ğ‘† | ğ´ | ğ‘ğ‘ | Îµ Remove ğµ â†’ Îµ ğ‘† â†’ ğ´ğ‘†ğµ | ğ‘†ğµ | ğ´ğ‘† | ğ‘† ğ´ â†’ ğ‘ğ´ğ‘† | ğ‘ | ğ‘ğ‘† ğµ â†’ ğ‘†ğ‘ğ‘† | ğ´ | ğ‘ğ‘ Remove ğµ â†’ ğ´ ğ‘† â†’ ğ´ğ‘†ğµ | ğ‘†ğµ | ğ´ğ‘† | ğ‘† ğ´ â†’ ğ‘ğ´ğ‘† | ğ‘ | ğ‘ğ‘† ğµ â†’ ğ‘†ğ‘ğ‘† | ğ‘ğ´ğ‘† | ğ‘ | ğ‘ğ‘† | ğ‘ğ‘ Remove ğ‘† â†’ ğ‘† ğ‘† â†’ ğ´ğ‘†ğµ | ğ‘†ğµ | ğ´ğ‘† ğ´ â†’ ğ‘ğ´ğ‘† | ğ‘ | ğ‘ğ‘† In this step, weâ€™re simply removing the -productionsÎµ and the unit productions, as detailed in the previous section. First, we remove the -production in A, but then it shiftsÎµ it to B. So then, we remove the -production in B. Weâ€™ve gottenÎµ rid of all the -productions, but now weâ€™ve got to get ridÎµ of all the unit productions. We get rid of the unit productions in B and S. For the one in B, we just replace it with Aâ€™s contents, and for the one in S, we just remove it, because is trivial.ğ‘† â†’ ğ‘† Computer Science / Software Engineering Notes Network ğµ â†’ ğ‘†ğ‘ğ‘† | ğ‘ğ´ğ‘† | ğ‘ | ğ‘ğ‘† | ğ‘ğ‘ 2 ğ‘ => ğ´ 0 ğ‘ => ğµ 0 In this step, we create a non-terminal for every terminal that exists. I call these and .ğ´0 ğµ0 3 ğ‘† â†’ ğ´ğ‘†ğµ | ğ‘†ğµ | ğ´ğ‘† ğ´ â†’ ğ´ 0 ğ´ğ‘† | ğ´ 0 | ğ´ 0 ğ‘† ğµ â†’ ğ‘†ğµ 0 ğ‘† | ğ´ 0 ğ´ğ‘† | ğ´ 0 | ğ´ 0 ğ‘† | ğµ 0 ğµ 0 In this step, I convert all terminals into their respective non-terminals that Iâ€™vedefined in the last step. At first, this doesnâ€™t make much sense, until the next step... 4 ğ´ 0 â†’ ğ‘ ğµ 0 â†’ ğ‘ In this step, I set up productions such that the non-terminals can produce their respective terminals. Now the previous step makes sense! 5 ğ‘† â†’ ğ´ğ‘†ğµ ğ‘† â†’ ğ´ ğ‘‹ 0 ğ‘‹ 0 â†’ ğ‘†ğµ ğ´ â†’ ğ´ 0 ğ´ğ‘† ğ´ â†’ ğ´ 0 ğ‘‹ 1 ğ‘‹ 1 â†’ ğ´ğ‘† ğµ â†’ ğ‘†ğµ 0 ğ‘† ğµ â†’ ğ‘†ğ‘‹ 2 ğ‘‹ 2 â†’ ğµ 0 ğ‘† ğµ â†’ ğ´ 0 ğ´ğ‘† ğµ â†’ ğ´ 0 ğ‘‹ 3 ğ‘‹ 3 â†’ ğ´ğ‘† In this step, I split up productions that have more than 2 non-terminals. I create non-terminals called so I donâ€™tğ‘‹ğ‘› run out of names and so that I know that any non-terminal called is just used for shortening.ğ‘‹ Every red highlighted production is a production I need to shorten, and the blue highlighted production underneath is the shortened version. Finish ğ‘† â†’ ğ´ğ‘‹ 0 | ğ‘†ğµ | ğ´ğ‘† ğ´ â†’ ğ´ 0 ğ‘‹ 1 | ğ´ 0 ğ‘† | ğ‘ ğµ â†’ ğ‘†ğ‘‹ 2 | ğ´ 0 ğ‘‹ 3 | ğ´ 0 ğ‘† | ğµ 0 ğµ 0 | ğ‘ ğ‘‹ 0 â†’ ğ‘†ğµ ğ‘‹ 1 â†’ ğ´ğ‘† ğ‘‹ 2 â†’ ğµ 0 ğ‘† ğ‘‹ 3 â†’ ğ´ğ‘† ğ´ 0 â†’ ğ‘ ğµ 0 â†’ ğ‘ This isnâ€™treally a step. Iâ€™vejust compiled all the productions and put them into one place, so you can see the finished CNF result! This grammar accepts the same language as the one at the start, except now itâ€™s in a different form: Chomsky Normal Form. Computer Science / Software Engineering Notes Network Converting a CFG to GNF This is n o t examin able acco rdin g to Gen n aro , but still wo rth readin g to give further in sight in to co n text-free grammars. 1. Convert the CFG into CNF. 2. Re-order the rules such that the start rule is at the top, the next derivable rules are below and so on. In other words it should be the case that for every possible derivation we are going down in the list of rules we have, but never up. - This will not always be possible, but try to order them as much as possible according to this schema. - You canâ€™t do anything wrong here, the purpose of this ordering is to minimise the amount of work you will have to do. 3. Replace all non-terminals with non-terminals of the form ğ´ 1 , ğ´ 2 ,..., ğ´ ğ‘˜ where is equal to the number of all non-terminals. Start with the first rule atğ‘˜ the top and work down, otherwise we cannot benefit from the ordering we did in the last step. 4. Check if for every production , it is true that Check the rulesğ´ ğ‘˜ â†’ ğ´ ğ‘—ğ‘‹ ğ‘˜ < ğ‘—. in ascending order, i.e. start with the rule where . If we find one ruleğ‘˜ = 0 where this does not hold, we must modify this rule immediately before we continue to check other rules. We have to deal with the following two cases: - inğ‘˜ > ğ‘— ğ´ ğ‘˜ â†’ ğ´ ğ‘—ğ‘‹ - Replace with whatever produces, i.e. deriveğ´ ğ‘— ğ´ ğ‘— ğ´ ğ‘— - If for the resulting rule still , keep replacing until this is notğ‘˜ > ğ‘— the case anymore. - (left-recursive rule), soğ‘˜ = ğ‘— ğ´ ğ‘˜ â†’ ğ´ ğ‘˜ğ‘‹ - Eliminate left recursion according to description above. 5. Now, we are taking a closer look at every production starting with a non-terminal, i.e. every production which is not in GNF yet. For all of those rules it must hold that where . Starting with the rule whereğ´ ğ‘˜ â†’ ğ´ ğ‘—ğ‘‹ ğ‘˜ < ğ‘— the highest number and working in descending order, derive Theğ‘˜ = ğ´ ğ‘—. result of deriving will be either a terminal symbol or two non-terminalğ´ ğ‘— symbols: - If we get another non-terminal, repeat this step with the current rule, i.e. derive the left-most non-terminal again, check again, and so on. Computer Science / Software Engineering Notes Network - If we get a terminal symbol, our production must be in GNF, meaning that it starts with a terminal followed by some non-terminals. This means that this rule is OK, we can leave it as it is and continue to the next rule. 6. Rename all non-terminals back to their old names. 7. There might exist some rules which are unreachable from the start symbol. Remove those rules. - Now, our grammar is in GNF. Congrats if you are not confused at this point. - If you need to visualise this problem (or if youâ€™re masochistic), an example of this is provided below: Step Pro gress D escrip tio n 0 ğ‘† â†’ ğ´ğ‘ ğ´ â†’ ğ‘ğ‘† | ğ‘ Here, we havenâ€™t done anything yet! This is the grammar we want to convert to GNF. Right now, itâ€™s not in any normal form. 1 ğ‘† â†’ ğ´ğµ ğ´' â†’ ğ‘ ğ´ â†’ ğ´'ğ‘† | ğ´' ğµ â†’ ğ‘ In this step, we convert the grammar into CNF using the method described above that you should have read. 2 ğ‘† â†’ ğ´ğµ ğ´ â†’ ğ´'ğ‘† | ğ´' ğ´' â†’ ğ‘ ğµ â†’ ğ‘ In this step, we reorder the steps so that, when going through productions, you go from the top and work your way down; you donâ€™t go back up. Sometimes, this isnâ€™talways completely possible, for example the production uses , which isğ´ â†’ ğ´'ğ‘† | ğ´' ğ‘† further up. 3 ğ´ 1 â†’ ğ´ 2 ğ´ 4 ğ´ 2 â†’ ğ´ 3 ğ´ 1 | ğ´ 3 ğ´ 3 â†’ ğ‘ ğ´ 4 â†’ ğ‘ In this step, we replace all non-terminals with , whereğ´ğ‘˜ is the position of the non-terminal from the top to theğ‘˜ bottom. 4 ğ´ 1 â†’ ğ´ 2 ğ´ 4 ğ´ 2 â†’ ğ´ 1 | ğ´ 3 ğ´ 3 â†’ ğ‘ ğ´ 4 â†’ ğ‘ ---------------------------- ğ´ 1 â†’ ğ´ 2 ğ´ 4 ğ´ 2 â†’ ğ´ 2 ğ´ 4 | ğ´ 3 ğ´ 3 â†’ ğ‘ ğ´ 4 â†’ ğ‘ In this step, we look for any productions whereğ´ğ‘˜ â†’ ğ´ğ‘—ğ‘‹ .ğ‘˜ > ğ‘— There doesnâ€™t actually exist any productions in the example where this is true, so Iâ€™vecreated a sub-example to demonstrate this step. This wonâ€™t affect the example weâ€™re working on. Thatâ€™s why the text looks like that. In the first block, we notice the production where this condition is true. So weğ´ 2 â†’ ğ´ 1 | ğ´ 3 replace in that production with its derivation.ğ´1 Next, we notice that, in the production Computer Science / Software Engineering Notes Network ---------------------------- ğ´ 1 â†’ ğ´ 2 ğ´ 4 ğ´ 2 â†’ ğ´ 3 ğ´ 5 ğ´ 3 â†’ ğ‘ ğ´ 4 â†’ ğ‘ ğ´ 5 â†’ ğ´ 4 ğ´ 5 | ğ´ 4 ---------------------------- ğ´ 1 â†’ ğ´ 2 ğ´ 4 ğ´ 2 â†’ ğ´ 5 ğ´ 4 | ğ´ 3 ğ´ 3 â†’ ğ‘ ğ´ 4 â†’ ğ‘ ğ´ 5 â†’ ğ‘ | ğ‘ , , which means that we haveğ´ 2 â†’ ğ´ 2 ğ´ 4 | ğ´ 3 ğ‘˜ = ğ‘— left recursion. Therefore, we introduce another non-terminal to rectify this called .ğ´5 Finally, on the last block, we notice that inğ‘˜ > ğ‘— . Therefore, we convert bothğ´ 5 â†’ ğ´ 4 | ğ´ 3 non-terminals into their derivations, which happen to be single terminals. With this, weâ€™ve completed this step. 5 ğ´ 1 â†’ ğ´ 2 ğ´ 4 ğ´ 2 â†’ ğ´ 3 ğ´ 1 | ğ´ 3 ğ´ 3 â†’ ğ‘ ğ´ 4 â†’ ğ‘ ---------------------------- ğ´ 1 â†’ ğ´ 2 ğ´ 4 ğ´ 2 â†’ ğ‘ğ´ 1 | ğ´ 3 ğ´ 3 â†’ ğ‘ ğ´ 4 â†’ ğ‘ ---------------------------- ğ´ 1 â†’ ğ´ 2 ğ´ 4 ğ´ 2 â†’ ğ‘ğ´ 1 | ğ‘ ğ´ 3 â†’ ğ‘ ğ´ 4 â†’ ğ‘ ---------------------------- ğ´ 1 â†’ ğ‘ğ´ 1 ğ´ 4 | ğ‘ğ´ 4 ğ´ 2 â†’ ğ‘ğ´ 1 | ğ‘ ğ´ 3 â†’ ğ‘ ğ´ 4 â†’ ğ‘ In this step, we look at all the productions that are not in GNF, and we substitute productions until all the productions are in GNF. We start with the highest rule (which is the furthest down in our list) and work in descending order . For example, in the first block, is not inğ´ 2 â†’ ğ´ 3 ğ´ 1 GNF. So we substitute â€™s production into it, making theğ´3 first part â€˜aâ€™. Next, is not in GNF, so we substitute theğ´ 2 â†’ ğ´ 3 same thing in that, and we get .ğ´2 â†’ ğ‘ After that, the only production that is not in GNF is . So we substitute into that one, and weğ´ 1 â†’ ğ´ 2 ğ´ 4 ğ´2 get .ğ´ 1 â†’ ğ‘ğ´ 1 ğ´ 4 | ğ‘ğ´ 4 There are no longer any more productions that are not in GNF. Weâ€™re now in Greibach normal form! But weâ€™re not done yet; our non-terminal symbols are all . Weğ´ğ‘˜ need to change them back. 6 ğ‘† â†’ ğ‘ğ‘†ğµ | ğ‘ğµ ğ´ â†’ ğ‘ğ‘† | ğ‘ ğ´' â†’ ğ‘ ğµ â†’ ğ‘ In this step, weâ€™ve just renamed our non-terminal symbols back to normal. 7 ğ‘† â†’ ğ‘ğ‘†ğµ | ğ‘ğµ ğµ â†’ ğ‘ In this step, weâ€™re just getting rid of any productions that are unreachable / unused. Computer Science / Software Engineering Notes Network In this example, the productions for and are neverğ´ ğ´' used, so they are deleted. PDA and CFG conversions - PDAs and CFG have the same power, therefore we can convert a PDA to a CFG and vice versa. CFG to PDA - We will do this by first converting a CFG into GNF, and then converting GNF into a one state PDA. - Assume that our Grammar is in GNF. Then all productions will look like: whereğ´ â†’ Î±ğµ 1 ğµ 2 ...ğµ ğ‘˜ ğ‘˜ â‰¥ 0 One terminal followed by non-terminals is derivable by one non-terminalğ‘˜ - The PDA we are going to construct will only have one state and will accept by empty stack. - We are going to call the one and only state .* - Formally, this means that the PDA will accept the string when there exists ağ‘¥ derivation: ( *,ğ‘¥,âŠ¥) â‡’( *,Îµ,Îµ) - Therefore, the PDA we will construct is going to be of the form: ğ‘€ = ( { *} , Î£, ğ‘, Î´, *, ğ‘†, âŠ˜) rep resen tin g is defin ed as because { *} set of states a singleton set containing the state * we will only have a single state in this PDA Î£ input alphabet terminal symbols of CFG these are the symbols, produced by the grammar, which our PDA is going to scan ğ‘ stack alphabet non-terminal symbols of CFG this is what we will push on/pop off the stack Î´ transition relation see below see below * start state the state * we only have a single state, so we donâ€™t have much choice where to Computer Science / Software Engineering Notes Network start. S initial stack symbol the start production of CFG we wonâ€™t have anything on the stack when we start scanning our string âŠ˜ final states empty set our PDA will accept by empty stack, therefore we donâ€™t need any final states. - Now, we still need to define the transition relation. - We are going to add an element to the relation for every production we have in our grammar. - Therefore, for each , add a transition:ğ´â†’Ïƒğµ 1 ğµ 2 ... ğµ ğ‘˜ - Formally: ( ( *,Ïƒ,ğ´) , ( *,ğµ 1 ğµ 2 ... ğµ ğ‘˜) ) - Graphically: - Example for the grammar of the language ğ¿( ğº) = { ğ‘ ğ‘› ğ‘ ğ‘› | ğ‘› > 0 } - ğ‘†â†’ğ‘ğ‘†ğµ | ğ‘ğµ - ğµâ†’ğ‘ - The resulting PDA will have - A set of states { *} - The input alphabet { ğ‘, ğ‘} - The stack alphabet { ğ‘†, ğµ} - The start state * - The initial stack symbol ğ‘† - The transition relation as shown in the following graphic: Computer Science / Software Engineering Notes Network - If we want to test if our PDA accepts the same language as our grammar, we can try to match every derivation of our grammar with a transition in our PDA - We will do this by giving the leftmost derivation, which means that productions are only applied to the leftmost non-terminal in every step. Grammar derivatio n s PD A tran sitio n s ğ‘† ( *,ğ‘ğ‘ğ‘ğ‘, ğ‘†) â‡’ ğ‘ğ‘†ğµ â†’( *, ğ‘ğ‘ğ‘,ğ‘†ğµ) â‡’ ğ‘ğ‘ğµğµ â†’( *, ğ‘ğ‘,ğµğµ) â‡’ ğ‘ğ‘ğ‘ğµ â†’( *, ğ‘, ğµ) â‡’ ğ‘ğ‘ğ‘ğ‘ â†’ ( *, Îµ, Îµ) PDA to CFG - This proof is pretty much just the previous proof, but in reverse! - The steps we will go through are as follows: 1. Prove that one-state PDAs can be converted to a CFG 2. Prove that any PDA can be converted to a one-state PDA - As you can see, the law of transitivity show that by doing this, we will prove that any PDA can be converted into a CFG. 1. First, we will prove that one-state PDAs can be converted to a CFG. - The obvious thing to do first is to start off with a PDA: - ( { ğ‘} , Î£, Î“, Î´, ğ‘, âŠ¥, âˆ…) - Now weâ€™re going to create a grammar (in GNF) like this: - ğº = ( Î“, Î£, ğ‘ƒ, âŠ¥) - âˆ€ ( ( ğ‘, ğ‘, ğ´) , ( ğ‘, ğµ 1 . . . ğµ ğ‘˜) ) âˆˆ Î´, ğ´ â†’ ğ‘ğµ 1 . . . ğµ ğ‘˜ âˆˆ ğ‘ƒ - This is just the previous proof in reverse, so if you understood that, youâ€™ll get this. - If you donâ€™t, Iâ€™ll translate that maths language above for you: Lin e in weird maths lan guage Lin e in p lain En glish ( { ğ‘} , Î£, Î“, Î´, ğ‘, âŠ¥, âˆ…) This oneâ€™s nice and simple;Iâ€™m just defining a PDA with only one state, .ğ‘ is the alphabet that the PDA acceptsÎ£ is the set of symbols accepted onto the stackÎ“ is the transition functionÎ´ is the initial stack symbolâŠ¥ Where it says just means that there is no final state;âˆ… Computer Science / Software Engineering Notes Network this PDA will accept by empty stack. ğº = ( Î“, Î£, ğ‘ƒ, âŠ¥) Again, Iâ€™m just defining a grammar. is the set of non-terminal symbols (notice how itâ€™s theÎ“ same as the set of symbols accepted onto the PDA stack) is the set of terminal symbols (notice how itâ€™s theÎ£ same as the alphabet that the PDA accepts) is the set of productionsğ‘ƒ is the start non-terminal (notice how itâ€™s the same asâŠ¥ the initial stack symbol in the PDA) âˆ€ ( ( ğ‘, ğ‘, ğ´) , ( ğ‘, ğµ 1 . . . ğµ ğ‘˜) ) âˆˆ Î´, ğ´ â†’ ğ‘ğµ 1 . . . ğµ ğ‘˜ âˆˆ ğ‘ƒ For every transition that exists in the PDA, there is also a production in the grammar that takes in the input stack symbol, and outputs the input symbol followed by all the stack symbols put into the stack. - Just by simply reversing the previous proof, we can show that a single-state PDA can be converted to a CFG. - But not every PDA is a single-state PDA. To complete the proof, we need to convert any PDA into a single-state PDA. 2. Now, we will prove that any PDA can be converted to a single-state PDA. - To convert a PDA to a single-state PDA, we need to store the state information inside the stack (since weâ€™re not going to be moving to any state). - Before we do that, letâ€™s change the PDA a little bit. - Letâ€™s change it so that when the PDA reaches a single final state, it can clear itâ€™s entire stack. Basically, weâ€™re changing it so the PDA only has one final state. - Second, weâ€™re going to introduce a new type of stack symbol. It looks like this: - ã€ˆğ‘ğ´ğ‘ã€‰ - where andğ‘, ğ‘ âˆˆ ğ‘„ ğ´ âˆˆ Î“ - All the new stack symbols will be in a new set called Î“â€² - We do this so we can store state information on the stack. Computer Science / Software Engineering Notes Network - Weâ€™re also going to change to just , where is the name of the only state in theğ‘„ { *} * PDA. - So, basically, our PDA looks like this: - ğ‘€â€² = ( { âˆ—} , Î£, Î“â€², Î´â€² , âˆ—, ã€ˆğ‘ âŠ¥ğ‘¡ã€‰, âˆ…) - (where is the start and is the end)ğ‘  ğ‘¡ - What is ? Well, itâ€™s defined as follows:Î´â€² - ğ‘“ğ‘œğ‘Ÿ ğ‘’ğ‘ğ‘â„ ğ‘¡ğ‘Ÿğ‘ğ‘›ğ‘ ğ‘–ğ‘¡ğ‘–ğ‘œğ‘› ( ( ğ‘,Ïƒ,ğ´) , ( ğ‘ 0 ,ğµ 1 ğµ 2 ... ğµ ğ‘˜) ) âˆˆ Î´ - ğ‘–ğ‘›ğ‘ğ‘™ğ‘¢ğ‘‘ğ‘’ ( ( âˆ—, Ïƒ, ã€ˆğ‘ğ´ğ‘ ğ‘˜ã€‰) , ( âˆ—, ã€ˆğ‘ 0 ğµ 1 ğ‘ 1 ã€‰ã€ˆğ‘ 1 ğµ 2 ğ‘ 2 ã€‰... ã€ˆğ‘ ğ‘˜âˆ’ 1 ğµ ğ‘˜ğ‘ ğ‘˜ã€‰) ) ğ‘–ğ‘› Î´â€² - ğ‘“ğ‘œğ‘Ÿ ğ‘ğ‘™ğ‘™ ğ‘ğ‘œğ‘ ğ‘ ğ‘–ğ‘ğ‘™ğ‘’ ğ‘ğ‘œğ‘šğ‘ğ‘–ğ‘›ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘  ğ‘œğ‘“ ğ‘ 1 , ğ‘ 2 , ... , ğ‘ ğ‘˜âˆˆ ğ‘„ - ... and when , then:ğ‘˜ = 0 - ğ‘“ğ‘œğ‘Ÿ ğ‘’ğ‘ğ‘â„ ğ‘¡ğ‘Ÿğ‘ğ‘›ğ‘ ğ‘–ğ‘¡ğ‘–ğ‘œğ‘› ( ( ğ‘,Ïƒ,ğ´) , ( ğ‘ 0 ,Îµ) ) âˆˆ Î´ - ğ‘–ğ‘›ğ‘ğ‘™ğ‘¢ğ‘‘ğ‘’ ( ( âˆ—, Ïƒ, ã€ˆğ‘ğ´ğ‘ 0 ã€‰) , ( âˆ—,Îµ) ) ğ‘–ğ‘› Î´â€² - To some people (normal people), this is just maths gibberish;what does this actually mean? - Remember that PDAs are also nondeterministic. Here, each guess the PDA makes, the stack â€œpredictsâ€ what transitions itâ€™ll go through in the future. If the prediction is correct, itâ€™ll pass. If the prediction is wrong, that guess will â€œdieâ€. - In other words, at each stage, we nondeterministically guess the remainder of the computation of the automaton and then verify it. - This is just a way of encoding the non-deterministic nature of the states into the stack. - This is really hard to visualise just by reading the descriptions, so letâ€™s go through an example. - We have a PDA here that maps out the language :{ ğ‘ ğ‘› ğ‘ ğ‘› | ğ‘› > 0 } Computer Science / Software Engineering Notes Network - Before we pick out transitions, letâ€™s have a look at all the possible stack symbols: ã€ˆ0 âŠ¥ 0 ã€‰ ã€ˆ0 âŠ¥ 1 ã€‰ ã€ˆ0 âŠ¥ 2 ã€‰ ã€ˆ1 âŠ¥ 0 ã€‰ ã€ˆ1 âŠ¥ 1 ã€‰ ã€ˆ1 âŠ¥ 2 ã€‰ ã€ˆ2 âŠ¥ 0 ã€‰ ã€ˆ2 âŠ¥ 1 ã€‰ ã€ˆ2 âŠ¥ 2 ã€‰ ã€ˆ0 ğ‘0 ã€‰ ã€ˆ0 ğ‘1 ã€‰ ã€ˆ0 ğ‘2 ã€‰ ã€ˆ1 ğ‘0 ã€‰ ã€ˆ1 ğ‘1 ã€‰ ã€ˆ1 ğ‘2 ã€‰ ã€ˆ2 ğ‘0 ã€‰ ã€ˆ2 ğ‘1 ã€‰ ã€ˆ2 ğ‘2 ã€‰ - You can think of each of these as like a possible transition that the PDA could take. - For example, could refer to the transition going from state 1 to 1, acceptingã€ˆ1 ğ‘1 ã€‰ ğ‘ on the stack. - Yes, there are some transitions that do not exist, like or , but they couldã€ˆ2 ğ‘2 ã€‰ ã€ˆ0 âŠ¥ 2 ã€‰ exist. The stack doesnâ€™t know what transitions exist, so it guesses with all possible combinations of transitions. The guesses that predict transitions that do exist will live and are more likely to predict everything correctly, and the guesses that predict transitions that do not exist end up dying. - Letâ€™s pick out a transition from this and convert it to its single-state equivalent. - Letâ€™s pick the transition that goes from state 0 to 0 with âŠ¥ on the stack: - ( ( 0 , ğ‘, âŠ¥) , ( 0 , ğ‘ âŠ¥) ) - Now letâ€™s convert it: - ( ( âˆ—, ğ‘, ã€ˆ0 âŠ¥ 0 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘0 ã€‰ã€ˆ0 âŠ¥ 0 ã€‰) ) - ( ( âˆ—, ğ‘, ã€ˆ0 âŠ¥ 0 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘1 ã€‰ã€ˆ1 âŠ¥ 0 ã€‰) ) - ( ( âˆ—, ğ‘, ã€ˆ0 âŠ¥ 0 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘2 ã€‰ã€ˆ2 âŠ¥ 0 ã€‰) ) - ( ( âˆ—, ğ‘, ã€ˆ0 âŠ¥ 1 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘0 ã€‰ã€ˆ0 âŠ¥ 1 ã€‰) ) - ( ( âˆ—, ğ‘, ã€ˆ0 âŠ¥ 1 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘1 ã€‰ã€ˆ1 âŠ¥ 1 ã€‰) ) Computer Science / Software Engineering Notes Network - ( ( âˆ—, ğ‘, ã€ˆ0 âŠ¥ 1 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘2 ã€‰ã€ˆ2 âŠ¥ 1 ã€‰) ) - ( ( âˆ—, ğ‘, ã€ˆ0 âŠ¥ 2 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘0 ã€‰ã€ˆ0 âŠ¥ 2 ã€‰) ) - ( ( âˆ—, ğ‘, ã€ˆ0 âŠ¥ 2 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘1 ã€‰ã€ˆ1 âŠ¥ 2 ã€‰) ) - ( ( âˆ—, ğ‘, ã€ˆ0 âŠ¥ 2 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘2 ã€‰ã€ˆ2 âŠ¥ 2 ã€‰) ) - So if we compute that transition, our single-state PDA will compute 3 parallel guesses, depending on whatâ€™s on the stack. - Letâ€™s pick out a simpler transition and convert that: - ( ( 1 , ğ‘, ğ‘) , ( 1 , Îµ) ) - Since this transition will only pop from the stack and not push, itâ€™ll only generate one transition relation for our single-state PDA: - ( ( âˆ—, ğ‘, ã€ˆ1 ğ‘1 ã€‰) , ( âˆ—, Îµ) ) - So in our single-state PDA, if it sees on the stack, that means the guessâ€™ã€ˆ1 ğ‘1 ã€‰ prediction was correct and the guess will live. If it does not see that on the stack, the guessâ€™prediction was wrong and will die. - Now that weâ€™ve defined these, letâ€™s try inputting a string into this multi-state PDA, and see how itâ€™s single-state equivalent works by comparing the two. Multi-state PD A Sin gle-state PD A guesses D escrip tio n ( 0 , ğ‘ğ‘ğ‘ğ‘, âŠ¥) ( âˆ—, ğ‘ğ‘ğ‘ğ‘, ã€ˆ0 âŠ¥2 ã€‰) We havenâ€™t really done anything yet. The initial stack symbol in a single-state PDA is always: ã€ˆ [ ğ‘–ğ‘›ğ‘–ğ‘¡ğ‘–ğ‘ğ‘™ ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘’] âŠ¥ [ ğ‘“ğ‘–ğ‘›ğ‘ğ‘™ ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘’] ã€‰ This is possible because thereâ€™s only one initial state and, like what weâ€™ve defined before, only one final state. ( 0 , ğ‘ğ‘ğ‘, ğ‘âŠ¥) ( âˆ—, ğ‘ğ‘ğ‘, ã€ˆ0 ğ‘0 ã€‰ã€ˆ0 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘ğ‘, ã€ˆ0 ğ‘1 ã€‰ã€ˆ1 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘ğ‘, ã€ˆ0 ğ‘2 ã€‰ã€ˆ2 âŠ¥2 ã€‰) Weâ€™ve inputted an â€˜aâ€™as input, and now our single-state PDA has started guessing! As youâ€™ve (hopefully) read above, three guesses will be made in this situation; a was read from the stack and an â€˜aâ€™ã€ˆ0 âŠ¥2 ã€‰ input was read, and now the following three guesses have been established. These three guesses go like this: What if we go from state 0 to state 0 using â€˜aâ€™on the stack, then go from state 0 to state 2 using floor? What if we go from state 0 to state 1 using â€˜aâ€™on the stack, then go from state 1 to state 2 using floor? What if we go from state 0 to state 2 using â€˜aâ€™on the stack, then go from state 2 to state 2 using floor? I admit, some of these guesses are a little (really) dumb, but can you blame them? Computer Science / Software Engineering Notes Network The stack doesnâ€™t know what transitions exist; it doesnâ€™t know that there isnâ€™ta transition from state 0 to state 2. So what does it do? It guesses. It guesses every single combination so that if it gets something wrong, it can fall back on another guess. If all the guesses are wrong, then thereâ€™s no way the PDA can accept the string. ( 0 , ğ‘ğ‘, ğ‘ğ‘âŠ¥) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘0 ã€‰ã€ˆ0 ğ‘0 ã€‰ã€ˆ0 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘1 ã€‰ã€ˆ1 ğ‘0 ã€‰ã€ˆ0 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘2 ã€‰ã€ˆ2 ğ‘0 ã€‰ã€ˆ0 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘0 ã€‰ã€ˆ0 ğ‘1 ã€‰ã€ˆ1 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘1 ã€‰ã€ˆ1 ğ‘1 ã€‰ã€ˆ1 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘2 ã€‰ã€ˆ2 ğ‘1 ã€‰ã€ˆ1 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘0 ã€‰ã€ˆ0 ğ‘2 ã€‰ã€ˆ2 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘1 ã€‰ã€ˆ1 ğ‘2 ã€‰ã€ˆ2 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘2 ã€‰ã€ˆ2 ğ‘2 ã€‰ã€ˆ2 âŠ¥2 ã€‰) Wow! Look at all those guesses! Weâ€™ve inputted another â€˜aâ€™into our PDAs, and now, weâ€™re exponentially making guesses. None of our guesses have died yet. Because weâ€™re pushing more than weâ€™re popping, weâ€™re making more guesses about what we want to do next; there are more possibilities now. The transition here is slightly different, because weâ€™re not using floor âŠ¥, but the concept is still the same. What? You want to see how this transition is converted to itâ€™s single-state PDA equivalent? Well, alright, but only because you asked so nicely: ( ( 0 , ğ‘, ğ‘) , ( 0 , ğ‘ğ‘) ) Converts to: ( ( âˆ—, ğ‘, ã€ˆ0 ğ‘0 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘0 ã€‰ã€ˆ0 ğ‘0 ã€‰) ) ( ( âˆ—, ğ‘, ã€ˆ0 ğ‘0 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘1 ã€‰ã€ˆ1 ğ‘0 ã€‰) ) ( ( âˆ—, ğ‘, ã€ˆ0 ğ‘0 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘2 ã€‰ã€ˆ2 ğ‘0 ã€‰) ) ( ( âˆ—, ğ‘, ã€ˆ0 ğ‘1 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘0 ã€‰ã€ˆ0 ğ‘1 ã€‰) ) ( ( âˆ—, ğ‘, ã€ˆ0 ğ‘1 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘1 ã€‰ã€ˆ1 ğ‘1 ã€‰) ) ( ( âˆ—, ğ‘, ã€ˆ0 ğ‘1 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘2 ã€‰ã€ˆ2 ğ‘1 ã€‰) ) ( ( âˆ—, ğ‘, ã€ˆ0 ğ‘2 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘0 ã€‰ã€ˆ0 ğ‘2 ã€‰) ) ( ( âˆ—, ğ‘, ã€ˆ0 ğ‘2 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘1 ã€‰ã€ˆ1 ğ‘2 ã€‰) ) ( ( âˆ—, ğ‘, ã€ˆ0 ğ‘2 ã€‰) , ( âˆ—, ã€ˆ0 ğ‘2 ã€‰ã€ˆ2 ğ‘2 ã€‰) ) ( 1 , ğ‘, ğ‘âŠ¥) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘0 ã€‰ã€ˆ0 ğ‘0 ã€‰ã€ˆ0 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘1 ã€‰ã€ˆ1 ğ‘0 ã€‰ã€ˆ0 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘2 ã€‰ã€ˆ2 ğ‘0 ã€‰ã€ˆ0 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘0 ã€‰ã€ˆ0 ğ‘1 ã€‰ã€ˆ1 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘1 ã€‰ã€ˆ1 ğ‘1 ã€‰ã€ˆ1 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘2 ã€‰ã€ˆ2 ğ‘1 ã€‰ã€ˆ1 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘0 ã€‰ã€ˆ0 ğ‘2 ã€‰ã€ˆ2 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘1 ã€‰ã€ˆ1 ğ‘2 ã€‰ã€ˆ2 âŠ¥2 ã€‰) ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘2 ã€‰ã€ˆ2 ğ‘2 ã€‰ã€ˆ2 âŠ¥2 ã€‰) Oh no! The guesses! Theyâ€™re dying! Weâ€™ve taken the transition: ( ( 0 , ğ‘, ğ‘) , ( 1 , Îµ) ) ...which converts into: ( ( âˆ—, ğ‘, ã€ˆ0 ğ‘1 ã€‰) , ( âˆ—, Îµ) ) So, what the single-state PDA is doing is, itâ€™s looking for a on the stack. If itâ€™sã€ˆ0 ğ‘1 ã€‰ there, the guess is right, it just pops it off and doesnâ€™t push anything else on. If itâ€™s not there, the guess is wrong and the guess dies. Computer Science / Software Engineering Notes Network ------------------------------------- ( âˆ—, ğ‘, ã€ˆ1 ğ‘0 ã€‰ã€ˆ0 âŠ¥2 ã€‰) ( âˆ—, ğ‘, ã€ˆ1 ğ‘1 ã€‰ã€ˆ1 âŠ¥2 ã€‰) ( âˆ—, ğ‘, ã€ˆ1 ğ‘2 ã€‰ã€ˆ2 âŠ¥2 ã€‰) As you can see, 6 guesses died, leaving only 3 guesses from each coloured partition. The top guesses show which ones survived and which ones died from the previous configuration (the gothy red and black ones are the ones that died). The bottom 3 guesses shows the top 3 living guesses after their â€˜bâ€™s have been inputted and stacks have been popped. ( 1 , Îµ, âŠ¥) ( âˆ—, ğ‘, ã€ˆ1 ğ‘0 ã€‰ã€ˆ0 âŠ¥2 ã€‰) ( âˆ—, ğ‘, ã€ˆ1 ğ‘1 ã€‰ã€ˆ1 âŠ¥2 ã€‰) ( âˆ—, ğ‘, ã€ˆ1 ğ‘2 ã€‰ã€ˆ2 âŠ¥2 ã€‰) ------------------------------------- ( âˆ—, Îµ, ã€ˆ1 âŠ¥2 ã€‰) Weâ€™ve taken the transition: ( ( 1 , ğ‘, ğ‘) , ( 1 , Îµ) ) ... which converts to: ( ( âˆ—, ğ‘, ã€ˆ1 ğ‘1 ã€‰) , ( âˆ—, Îµ) ) So, like before, it looks for a on top ofã€ˆ1 ğ‘1 ã€‰ the stack. If itâ€™s there, we live. If itâ€™s not there, we die. Thereâ€™s only one guess here with a !ã€ˆ1 ğ‘1 ã€‰ This guess has correctly predicted every move that the PDA has done. Congratulations, guess! So now, we pop off and continue.ã€ˆ1 ğ‘1 ã€‰ The existence of this guess is enough to accept the inputted string, right? Almost. Thereâ€™s one formality we need to take care of first:we need to move to state 2, the final state, to properly conclude this. Will this last-standing guess be able to conquer the final step by predicting the final transition from state 1 to state 2? Spoilers: it does ( 2 , Îµ, Îµ) ( âˆ—, Îµ, Îµ) It should be needless to say that this final transition looks for a to pop, and findsã€ˆ1âŠ¥2 ã€‰ one within the final guess. We can now accept by empty stack. This string is within the language of this PDA, and this single-state PDA is equivalent to this multi-state PDA! - If it helps to visualise it better, hereâ€™s the successful guess from start to finish: - ( âˆ—, ğ‘ğ‘ğ‘ğ‘, ã€ˆ0 âŠ¥2 ã€‰) Computer Science / Software Engineering Notes Network - ( âˆ—, ğ‘ğ‘ğ‘, ã€ˆ0 ğ‘1 ã€‰ã€ˆ1 âŠ¥2 ã€‰) - ( âˆ—, ğ‘ğ‘, ã€ˆ0 ğ‘1 ã€‰ã€ˆ1 ğ‘1 ã€‰ã€ˆ1 âŠ¥2 ã€‰) - ( âˆ—, ğ‘, ã€ˆ1 ğ‘1 ã€‰ã€ˆ1 âŠ¥2 ã€‰) - ( âˆ—, Îµ, ã€ˆ1 âŠ¥2 ã€‰) - ( âˆ—, Îµ, Îµ ) Proving closure Union - CFLs are closed under union - This means that the language of the union of two CFGs is also going to be context-free - We are going to create a grammar that is the union of two other grammars. - We can assume that the non-terminals of our two grammars are going to be distinct, meaning that we donâ€™t have non-terminals that appear in both grammars. - If we have, we are just going to rename them, it wonâ€™t change the grammar. - Letâ€™s introduce a new start symbol and a new production for this new start symbol. - The new production is going to link our new start symbol to the old start symbols from our two grammars like this: ğ‘† â†’ ğ‘† 1 | ğ‘† 2 Where is the start symbol of the first grammar and is the start symbolğ‘† 1 ğ‘† 2 from the second grammar - As for the other non-terminals and the other productions, we are just copying them from what we have in our two other grammars. - Now we can generate everything that the first grammar is able to produce by deriving and we can also generate everything that the second grammar is able to produceğ‘† 1 by deriving ğ‘† 2 . Concatenation - CFLs are closed under concatenation - This means that the language of the concatenation of two CFGs is also going to be context-free - Proving this is exactly the same as proving the union, just that our start production is going to be different: ğ‘† â†’ ğ‘† 1 ğ‘† 2 Where is the start symbol of the first grammar and is the start symbol from theğ‘† 1 ğ‘† 2 second grammar Computer Science / Software Engineering Notes Network - Now we can generate everything that the first grammar is able to produce by deriving and then we can generate everything that the second grammar is able toğ‘† 1 produce by deriving ğ‘† 2 . Kleene star - CFLs are closed under kleene star - This means that the language of 0 or more repetitions of a CFG is also going to be context-free. - We are going to create a grammar that represents the kleene star of another grammar. - Letâ€™s introduce a new start symbol and a new production for this new start symbol. - The new production is going to look like this: ğ‘† â†’ ğ‘†ğ‘† 1 | Îµ Where is the start symbol of the other grammar.ğ‘† 1 - As for the other non-terminals and the other productions, we are just copying them from what we have in the other grammar. - Now we can produce 0 or more repetitions of everything that the other grammar is able to produce by deriving or fromğ‘†ğ‘† 1 Îµ ğ‘†. Intersection with regular languages - CFLs are closed under the intersection with regular languages - This means that the language of a CFG intersected with a regular language is going to be context-free. - In contrast, the intersection of two CFL is not always context-free. - Idea:Product construction with PDA and DFA. - The slides donâ€™t go into more detail than that, but I will. - Letâ€™s give our automata names, because that makes them easier to work with. Letâ€™s call our DFA and our PDA .ğ‘€ ğ· ğ‘€ ğ‘ƒ - DFAs are just weak PDAs, so we can convert our DFA into a PDA. Itâ€™sğ‘€ ğ· basically just going to be a PDA that doesnâ€™t use itâ€™s stack and doesnâ€™t use any non-deterministic features. Letâ€™s call this , where .ğ‘€ ğ‘ƒ' ğ¿( ğ‘€ ğ‘ƒ') = ğ¿( ğ‘€ ğ·) - So now we have two PDAs, and . We need to perform productğ‘€ ğ‘ƒ' ğ‘€ ğ‘ƒ construction on these, so that we can construct a PDA that accepts strings accepted by bo th and (because thatâ€™s what intersection means).ğ‘€ ğ‘ƒ' ğ‘€ ğ‘ƒ Computer Science / Software Engineering Notes Network - Letâ€™s call this product construct-ed PDA . Normally, product constructionğ‘€ ğ‘ƒ'' with PDAs donâ€™t work, because they interfere with each other on the stack (they have to share a stack). However, this case is different. How do we know that and donâ€™t interfere with each other on the stack?ğ‘€ ğ‘ƒ ğ‘€ ğ‘ƒ' - We know they donâ€™t interfere because doesnâ€™t even use the stack!ğ‘€ ğ‘ƒ' Remember, itâ€™s just a DFA calling itself a PDA;it doesnâ€™t even use the stack. Heck, it canâ€™t even use any non-deterministic features, or any epsilon-moves. The stack is completely free for to use.ğ‘€ ğ‘ƒ - Because weâ€™ve defined a PDA that supports the intersection of regular languages, weâ€™ve shown that itâ€™s closed. We can convert this PDA into a context-free grammar, showing that the language represented by this PDA is context-free, therefore showing that the intersection with regular languages is closed. Computer Science / Software Engineering Notes Network Limits of context-free languages - Are all languages context free? No! - E.g. the language is not context-free, meaning that we cannot{ ğ‘ ğ‘› ğ‘ ğ‘› ğ‘ ğ‘› } construct a PDA that accepts or a CFG that produces this language. In fact, we would need a Turing machine to accept this language, which we will see later. - Assume our grammar is in CNF - Remember that we can convert any grammar to CNF if it isnâ€™t - Iâ€™m going to use the following CNF for further explanations: - ğ‘† â†’ ğ´ğ¶ | ğ´ğµ - ğ¶ â†’ ğ‘†ğµ - ğ´ â†’ ğ‘ - ğµ â†’ ğ‘ Which represents the language { ğ‘ ğ‘› ğ‘ ğ‘› | ğ‘› â‰¥ 1 } - If we start deriving a string using our CNF, we can draw the process of deriving the string as a binary tree. - For instance, letâ€™s derive and draw the derivations as a binary tree:ğ‘ 3 ğ‘ 3 - We can see that in the middle path of the tree, we have a long path of non-terminals. We will have this in every derivation which is long enough (weâ€™ll define what long enough means below). - We can also see that there are some non-terminals that are repeated. - If we go one step down in the tree, we are going to at most double its width - This is because our grammar is in CNF, which allows us to derive at most 2 non-terminals in a single rule. - Therefore, the derivation tree of a string of size must have a depth of at least2 ğ‘˜ ğ‘˜ - Suppose that there are non-terminals. In any derivation tree of a string of length atğ‘› least there must be a path where some non-terminal appears at least twice, i.e.2 ğ‘›+ 1 is repeated. Computer Science / Software Engineering Notes Network - The derivation tree of a string of size must have a depth of at least2 ğ‘›+ 1 ğ‘› + 1 . - However, we only have non-terminals, therefore we need to repeat at leastğ‘› one of our non-terminals.ğ‘› - If we see a repeated non-terminal, we can start pumping this non-terminal into the tree. - Here, we split our tree into where the tree generated by the blueğ‘¢ğ‘£ğ‘¤ğ‘¥ğ‘¦ ğ‘† covers and the tree generated by the red covers only. Everythingğ‘£ğ‘¤ğ‘¥ ğ‘† ğ‘¤ outside of the blue will be covered by andğ‘† ğ‘¢ ğ‘¦. - Now, we are copying the subtree of the blue and paste it into the position ofğ‘† the red .ğ‘† - Every time we do this, we are essentially adding another part and anotherğ‘£ part to our tree.ğ‘¥ - We can also replace the subtree of the blue with the subtree of the red . By doingğ‘† ğ‘† this we are taking and out of the tree completely.ğ‘£ ğ‘¥ - This act of â€˜removingâ€™and â€˜pumping inâ€™ and forms the basis for the pumpingğ‘£ ğ‘¥ lemma for context-free languages. Computer Science / Software Engineering Notes Network Pumping (ğŸƒ) Lemma for context-free languages - contrapositive form - We can use the contrapositive form of the pumping lemma for context free languages to show that a language is not context free. We cannot use the pumping lemma to show that a language is context free! - It works by splitting up the language into parts, then â€œpumpingâ€ a subpart until you get a string that isnâ€™t in the language. This is similar to what we have just done before. - The different steps of the proof can be understood as a game versus a demon. 1. The demon chooses a number such that .ğ‘˜ ğ‘˜ â‰¥ 0 - We cannot choose a value for , we only know that it is greater than or equalğ‘˜ to 0. 2. We choose a string such that .ğ‘§ âˆˆ ğ¿ ğ‘§| |â‰¥ ğ‘˜ - We can choose any string that is within the language. However, we have toğ‘§ make sure that, no matter what is, our string is always in the language.ğ‘˜ ğ‘§ We do not need to cover the whole language with our string! - The length of must be at least . A way to make sure that this is always theğ‘§ ğ‘˜ case is to have at least a part in that is equal to something to the power of .ğ‘§ ğ‘˜ - As a general tip, try to make as trivial as possible, like in the followingğ‘§ example: - For instance, we could let to make sure that is at least long (ğ‘§ = ğ‘ ğ‘˜ ğ‘ ğ‘˜ ğ‘ ğ‘˜ ğ‘§ ğ‘˜ are symbols from the alphabet).ğ‘, ğ‘, ğ‘ 3. The demon splits into such that , i.e. , andğ‘§ ğ‘¢ğ‘£ğ‘¤ğ‘¥ğ‘¦ ğ‘£ğ‘¥| | > 0 ğ‘£ğ‘¥ â‰  Îµ |ğ‘£ğ‘¤ğ‘¥| â‰¤ ğ‘˜. - You cannot choose how the string is going to be split! - What you do know is that the part of the string is not going to be empty.ğ‘£ğ‘¥ However, one of or can still be empty.ğ‘£ ğ‘¥ - You also know that the length of the is at most .ğ‘£ğ‘¤ğ‘¥ ğ‘˜ - You can think of as a window you can slide across what you defined asğ‘¢ğ‘£ğ‘¤ ğ‘§ . - Therefore, we have to list all possible cases in which can be split andğ‘¢ğ‘£ğ‘¤ğ‘¥ğ‘¦ proceed with each of them to the next step. - For instance, if , we have to consider the following cases:ğ‘§ = ğ‘ ğ‘˜ ğ‘ ğ‘˜ ğ‘ ğ‘˜ = ğ‘¢ğ‘£ğ‘¤ğ‘¥ğ‘¦ i. Case 1: contains only one repeated letter:Either only â€™s, or onlyğ‘£ğ‘¥ ğ‘ ğ‘ â€™s, or only â€™sğ‘ - e.g. ğ‘¢ğ‘£ğ‘¤ğ‘¥ğ‘¦=ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ii. Case 2:either or (but not both) is a word that contains more thanğ‘£ ğ‘¥ one kind of symbol. - e.g. ğ‘¢ğ‘£ğ‘¤ğ‘¥ğ‘¦=ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ iii. Case 3: and do not have any symbols in common.ğ‘£ ğ‘¥ Computer Science / Software Engineering Notes Network - e.g. ğ‘¢ğ‘£ğ‘¤ğ‘¥ğ‘¦=ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ iv. It cannot be the case that contains all three letters because theğ‘£ğ‘¤ğ‘¥ length of is at most .ğ‘£ğ‘¤ğ‘¥ ğ‘˜ 4. We pick an such that the string If this is the case we have provenğ‘– â‰¥ 0 ğ‘¢ğ‘£ ğ‘– ğ‘¤ğ‘¥ ğ‘– ğ‘¦ âˆ‰ ğ¿. that the language is not context-free! - We can pick any we want as long as it is equal to or greater than 0.ğ‘– - Our goal is to choose an such that the resulting string is outside of theğ‘– language. - We have to do this for every case we defined in the previous step. - Here is how to do it for the example cases above: i. Let ğ‘– = 2 ii. Case 1: contains only one repeated letter:then is going toğ‘£ğ‘¥ ğ‘¢ğ‘£ 2 ğ‘¤ğ‘¥ 2 ğ‘¦ have either too many of , orğ‘'ğ‘  ğ‘'ğ‘  ğ‘'ğ‘  iii. Case 2:either or contains two different symbols:then isğ‘¥ ğ‘£ ğ‘¢ğ‘£ 2 ğ‘¤ğ‘¥ 2 ğ‘¦ going to have too many of two of , or .ğ‘'ğ‘  ğ‘'ğ‘  ğ‘'ğ‘  iv. Case 3: does not contain the same symbol as . then isğ‘£ ğ‘¥ ğ‘¢ğ‘£ 2 ğ‘¤ğ‘¥ 2 ğ‘¦ going to have too many of two of , or .ğ‘'ğ‘  ğ‘'ğ‘  ğ‘'ğ‘  5. You MUST say â€œTherefore L is not context-freeâ€, if you donâ€™t, you will lose marks. - If this still doesnâ€™t make any sense, look at a few examples below, and then read the general case above again. Examp le So lutio n ğ¿ = { ğ‘ ğ‘› ğ‘ ğ‘› ğ‘ ğ‘› } 1. The demon chooses a number such that .ğ‘˜ ğ‘˜ â‰¥ 0 2. We choose a string such that .ğ‘§ âˆˆ ğ¿ ğ‘§| |â‰¥ ğ‘˜ - Letâ€™s choose .ğ‘§ = ğ‘ ğ‘˜ ğ‘ ğ‘˜ ğ‘ ğ‘˜ - We can see that .ğ‘§| |â‰¥ ğ‘˜ 3. The demon splits into such that , i.e. ,ğ‘§ ğ‘¢ğ‘£ğ‘¤ğ‘¥ğ‘¦ ğ‘£ğ‘¥| | > 0 ğ‘£ğ‘¥ â‰  Îµ and |ğ‘£ğ‘¤ğ‘¥| â‰¤ ğ‘˜. - Letâ€™s consider all the different cases: - Case 1: contains only one repeated letter:Eitherğ‘£ğ‘¥ only â€™s, or only â€™s, or only â€™sğ‘ ğ‘ ğ‘ - Case 2:either or (but not both) is a word thatğ‘£ ğ‘¥ contains more than one kind of letter. - Case 3: and do not have any letters in common.ğ‘£ ğ‘¥ 4. We pick an such that the stringğ‘– â‰¥ 0 ğ‘¢ğ‘£ ğ‘– ğ‘¤ğ‘¥ ğ‘– ğ‘¦ âˆ‰ ğ¿. - pick , thenğ‘– = 2 ğ‘¢ğ‘£ 2 ğ‘¤ğ‘¥ 2 ğ‘¦ âˆ‰ ğ¿ - Case 1: Computer Science / Software Engineering Notes Network i. Our resulting word will have one letter repeated more often than the other two letters. - Case 2 i. Our resulting word is not going to be of the form a*b*c*. - Case 3: i. Our resulting word is going to have more of two of the letters but the number of occurrences of the third letter remains unchanged. 5. Therefore, L is not context-free ğ¿ = { ğ‘ 4 ğ‘› ğ‘ ğ‘› ğ‘ 4 ğ‘› } 1. The demon chooses a number such that .ğ‘˜ ğ‘˜ > 0 2. We choose a string such that .ğ‘§ âˆˆ ğ¿ ğ‘§| |â‰¥ ğ‘˜ - Letâ€™s choose .ğ‘§ = ğ‘ 4 ğ‘˜ ğ‘ ğ‘˜ ğ‘ 4 ğ‘˜ - We can see that .ğ‘§| |â‰¥ ğ‘˜ 3. The demon splits into such that , i.e. ,ğ‘§ ğ‘¢ğ‘£ğ‘¤ğ‘¥ğ‘¦ ğ‘£ğ‘¥| | > 0 ğ‘£ğ‘¥ â‰  Îµ and |ğ‘£ğ‘¤ğ‘¥| â‰¤ ğ‘˜. - Letâ€™s consider all the different cases: - Case 1: contains only one repeated letter:Eitherğ‘£ğ‘¥ only â€™s, or only â€™s.ğ‘ ğ‘ - Case 2:either or (but not both) is a word thatğ‘£ ğ‘¥ contains more than one kind of letter. - Case 3: and do not have any letters in common.ğ‘£ ğ‘¥ 4. We pick an such that the stringğ‘– â‰¥ 0 ğ‘¢ğ‘£ ğ‘– ğ‘¤ğ‘¥ ğ‘– ğ‘¦ âˆ‰ ğ¿. - Pick , thenğ‘– = 2 ğ‘¢ğ‘£ 2 ğ‘¤ğ‘¥ 2 ğ‘¦ âˆ‰ ğ¿ - Case 1: i. We are changing the number of either the â€™sğ‘ or the â€™s. Therefore, the number of â€™s wonâ€™tğ‘ ğ‘ be eight times the number of â€™s anymore.ğ‘ - Case 2 i. Our resulting word is not going to be of the form a*b*a*. - Case 3: i. We are changing the number of either the first â€™s and the â€™s or the â€™s and the second â€™s.ğ‘ ğ‘ ğ‘ ğ‘ Therefore, the number of the first â€™s wonâ€™tğ‘ match with the number of the second â€™sğ‘ anymore. 5. Therefore, L is not context-free ğ¿ = { ğ‘ 2 ğ‘› | ğ‘› â‰¥ 0 } 1. The demon chooses a number such that .ğ‘˜ ğ‘˜ > 0 2. We choose a string such that .ğ‘§ âˆˆ ğ¿ ğ‘§| |â‰¥ ğ‘˜ a. Letâ€™s choose .ğ‘§ = ğ‘ 2 ğ‘˜ b. We can see that .ğ‘§| |= 2 ğ‘˜ â‰¥ ğ‘˜ Computer Science / Software Engineering Notes Network 3. The demon splits into such that , i.e. ,ğ‘§ ğ‘¢ğ‘£ğ‘¤ğ‘¥ğ‘¦ ğ‘£ğ‘¥| | > 0 ğ‘£ğ‘¥ â‰  Îµ and |ğ‘£ğ‘¤ğ‘¥| â‰¤ ğ‘˜. a. This time we only have to consider one case as we only have one letter in our windowğ‘ ğ‘£ğ‘¤ğ‘¥. b. We know that we have at least 1 and at most â€™s inğ‘˜ ğ‘ our window, which we are going to pump in the next step. 4. We pick an such that the stringğ‘– â‰¥ 0 ğ‘¢ğ‘£ ğ‘– ğ‘¤ğ‘¥ ğ‘– ğ‘¦ âˆ‰ ğ¿. a. pick ğ‘– = 2 b. where we|ğ‘¢ğ‘£ 2 ğ‘¤ğ‘¥ 2 ğ‘¦| = |ğ‘¢ğ‘£ğ‘¤ğ‘¥ğ‘¦| + |ğ‘£ğ‘¥| = 2 ğ‘˜ + ğ‘™ define l to be |ğ‘£ğ‘¥| c. Define the bounds of to beğ‘™ 1 â‰¤ ğ‘™ â‰¤ ğ‘˜ i. This is because and when|ğ‘£ğ‘¥| > 0 |ğ‘£ğ‘¤ğ‘¥| â‰¤ ğ‘˜ ğ‘¤ = Îµ d. I know that because its length, ,ğ‘¢ğ‘£ 2 ğ‘¤ğ‘¥ 2 ğ‘¦ âˆ‰ ğ¿ 2 ğ‘˜ + ğ‘™ cannot be expressed as some number .2 ğ‘š e. This is because is going to be strictly between2 ğ‘˜ + ğ‘™ and :2 ğ‘˜ 2 ğ‘˜+ 1 2 ğ‘˜ < 2 ğ‘˜ + ğ‘™ < 2 ğ‘˜+ 1 f. If you have doubts, check the bounds of again andğ‘™ also try to plug in and (imagine you are the demon)ğ‘˜ ğ‘™ 5. Therefore, L is not context-free Computer Science / Software Engineering Notes Network Computability theory Turing machines - With DFAs and NFAs, we had states and transitions. - With PDAs, we had states, transitions and a stack. - Now, with Turing machines, we have states, transitions and a â€œtapeâ€, which is basically a linked list storing the input string at each node. - With this new data structure at our disposal, we can do even more things than PDAs. - In fact, according to the Church-Turing thesis, Turing machines (TMs, not to be confused with PokÃ©mon TMs) are just as powerful as algorithms. - However, TMs do not cover all languages. Theyâ€™re not that good. See Undecidable Problems for languages not covered by TMs. - So, what exactly are TMs? Iâ€™ll go through them informally and then formally. 1. Informally - Theyâ€™re basically like PDAs, but instead of a stack, you get a tape, where you can move left or right on each transition. - You can think of the tape as like a doubly linked list, where you can traverse left and right. - The input string is on the tape, and we start at the far left and usually work our way to the right. - Here is an example of a tape in the middle of a TM execution: âŠ¢ a âŠ” c âŠ£ - The âŠ¢symbol means the â€˜startâ€™, itâ€™s a left marker. - The âŠ”symbol means â€˜emptyâ€™, thereâ€™s nothing here. - The âŠ£symbol means the â€˜endâ€™, itâ€™s a right marker. - The part thatâ€™s shaded in red is the current position weâ€™re on, and the other blue parts are all the other positions. 2. Formally - Formally, a TM is a 9-tuple: - ğ‘€ = ( ğ‘„, Î£, Î“, âŠ¢, âŠ”, Î´, ğ‘ , ğ‘¡, ğ‘Ÿ) - where - is the finite set of statesğ‘„ - |Q| â‰¥ 3 :accept, reject and start states as well as other states - is the input alphabetÎ£ Computer Science / Software Engineering Notes Network - is the tape alphabet ( :the input alphabet is a proper subset of theÎ“ Î£ âŠ‚ Î“ tape alphabet) - is the left endmarker (left endmarkers are part of the tapeâŠ¢ âˆˆ Î“ âˆ’ Î£ alphabet, but not the input alphabet) - is the blank symbol (blanks are part of the tape alphabet, but notâŠ” âˆˆ Î“ âˆ’ Î£ the input alphabet) - is the transition functionÎ´: ( ğ‘„ âˆ’ { ğ‘¡, ğ‘Ÿ} ) Ã— Î“ â†’ ğ‘„ Ã— Î“ Ã— { ğ¿, ğ‘…} - In English, itâ€™s in the form whereÎ´( ğ‘, ğ‘) â†’( ğ‘, ğ‘‘, ğ‘’) - is a possible state that is n o t the accept / reject stateğ‘ - is a tape symbol that must be at our current position on theğ‘ tape - is a state to go toğ‘ - is a tape symbol to write to the tapeğ‘‘ - is either left or right , to traverse the tapeğ‘’ ğ¿ ğ‘… - is the start stateğ‘  - is the accept stateğ‘¡ - is the reject stateğ‘Ÿ - When performing transitions, we cannot overwrite and we cannot move left if weâ€™reâŠ¢ at the left endmarker. - We can write element in onto the tape (including âŠ¢and ).Î“ âŠ” Decidability Recursive and R.E languages - A to tal turin g machin e is a TM that halts on every input (does not loop infinitely) - A turing machine that isnâ€™t total can hang (like Microsoft Visual Studio) - A language is recursive if there exists a total Turing machine that accepts it. - A language is recursively en umerable (r.e) if there exists a Turing machine that accepts all of the strings in that language. - Remember that all recursive languages are recursively enumerable:R âŠ‚ R.E Proof:Recursive Sets Closed under Complement - Recursive sets are clo sed un der co mp lemen t (if L is recursive, ~L is also recursive) - Remember how we proved DFAs are closed under complement? Itâ€™s the same ordeal here. - Letâ€™s say we have a language â€˜Aâ€™that is accepted by a TM â€˜Mâ€™. If we can construct a TM for ~A, then we can prove this lemma. - Just swap the accept state and the reject state. This way, ~A will accept .Î£ * âˆ’ ğ´ - In other words, whenever A accepts something, ~A will reject it, and whenever A rejects something, ~A will accept it. Thatâ€™s literally the definition of a complement! Computer Science / Software Engineering Notes Network - Lemma:If L and ~L are r.e, then L is recursive - Letâ€™s say that the TMs â€˜M1â€™accepts â€˜Lâ€™and â€˜M2â€™accepts â€˜~Lâ€™. - If we can construct a total TM â€˜Nâ€™that simulates both M1 and M2, then we can show that this lemma is true. - Why the existence of N proves this lemma : - M1 accepts everything in L, so it never hangs for strings in L. - M2 accepts everything in ~L, so it never hangs for strings that are not in L. - When â€˜Nâ€™simulates M1 and M2, that means if M1 accepts, N accepts, and if M2 accepts, N rejects, so that the language of N is the same as M1. - But M1 never hangs for L, and M2 never hangs for anything not in L. If â€˜Nâ€™will halt when either M1 or M2 halts, that means â€˜Nâ€™will never hang for L an d never hang for anything not in L. But that just means â€˜Nâ€™will halt on any string! - Therefore â€˜Nâ€™wonâ€™t hang on an y string, making the language L recursive. - Constructing N: - We need to create a TM â€˜Nâ€™that simulates both M1 and M2. - Remember subset construction back in Automata theory? Well, this is similar to that. - Basically, we have two tapes, stuck to each other. The top tape is M1, and the bottom tape is M2. and ~Lğ‘ ğ‘– âˆˆ ğ¿ ğ‘ ğ‘– âˆˆ âŠ¢ ğ‘ 1 ğ‘ 2 ğ‘ 3 ğ‘ 4 âŠ¢ ğ‘ 1 ğ‘ 2 ğ‘ 3 ğ‘ 4 - But how do we know what position M1 and M2 are at? Currently, we can only select and together, where is the same number for both â€˜aâ€™and â€˜bâ€™, like or .ğ‘ ğ‘– ğ‘ ğ‘– ğ‘– ğ‘ 1 , ğ‘ 1 ğ‘ 4 , ğ‘ 4 - Thatâ€™s why we introduce a â€˜hatâ€™: âŠ¢ ğ‘ 1 ğ‘ 2 ğ‘ 3 ğ‘ 4 âŠ¢ ğ‘ 1 ğ‘ 2 ğ‘ 3 ğ‘ 4 - Now we know what position M1 and M2 are on! For example, if our simulation of M1 is on the tape element and our simulation for M2 is on the tape element , we canğ‘ 1 ğ‘ 4 represent that on our tape like so: âŠ¢ ğ‘ 1 ğ‘ 2 ğ‘ 3 ğ‘ 4 âŠ¢ ğ‘ 1 ğ‘ 2 ğ‘ 3 ğ‘ 4 Computer Science / Software Engineering Notes Network - Now that our tape is all set up, all we have to do is set the instructions for the TM to follow: 1. Scans the tape to find a symbol with a hat in the \"upper\" section of the tape. Then, according to the transitions of M1, it performs M1â€™s move. 2. If M1 accepts then N accepts; 3. Scans the tape to find a symbol with a hat in the \"lower\" section of the tape. Then, according to the transitions of M2 , it performs M2â€™s move. 4. If M2 accepts then N rejects; 5. Go back to step 1 - The states work just like subset construction;we have tuples as states, in the form: - ( , )ğ‘  ğ‘˜ - Where is a state in M1 and is a state in M2.ğ‘  ğ‘˜ - To complete this formal proof, all we need now is a short statement to show that â€˜Nâ€™is total: - â€œAny is either in or : So it is accepted by either M1 or M2. Soğ‘¥ ğ¿ Î£ * âˆ’ ğ¿ ğ‘¥ âˆˆ ğ¿ â‹ƒ Î£ * âˆ’ ğ¿ N will eventually accept or reject, thus N is total and so is recursive.â€ğ¿ - Just like that, the proof is done! - Lemma:If L is r.e and not recursive, ~L is not r.e - Letâ€™s say TM â€˜M1â€™accepts â€˜Lâ€™. If â€˜Lâ€™is r.e and not recursive, then that means â€˜M1â€™ loops on some strings that are not in L (which are instead in ~L) - Letâ€™s try to construct a TM â€˜M2â€™that accepts ~L. This Turing Machine would have to accept all strings that are not in L. - However, as stated before, â€˜Lâ€™is not recursive, so â€˜M1â€™loops on some strings that are not in L. Because ~L is every string that is not in L, M2 would have to loop on some strings that are in ~L, meaning that M2 can never fully accept ~L, and no Turing Machine can ever accept ~L, making it not recursively enumerable. (Semi) Decidable properties - First of all, letâ€™s define what a p ro p erty is. A property of a string is a predicate that tells you something about the string. It is either true or false. - A few examples are: - The string has length 2 :{w | #w = 2} - There is a letter â€˜gâ€™in the string :{w | â€˜gâ€™âˆˆ w} - There is an even number of letters in the string :{w | #w mod 2 = 0} - The string contains the substring â€œjojoâ€ :{w | â€œjojoâ€ âˆˆ w} - A property is decidable if all strings with that property form a language that is recursive. - For example:the property that the given string is equal to â€œduwangâ€ (because all finite languages are recursive) Computer Science / Software Engineering Notes Network - A property is semi-decidable if all strings with that property form a language that is recursively enumerable. - For example:the property that the given string is an encoding for a Turing Machine that halts (you can simulate the TM and accept if it halts, but if it loops, then your simulation will loop, making this recursively enumerable but not recursive). - Remember: - semi-decidable â‡” recursively enumerable - decidable â‡” recursive Universal Turing machines Multiple tapes - Are TMs with multiple tapes more powerful than TMs with only one tape? - No! Remember the section â€œRecursive and R.E languagesâ€ where we constructed a dual-tape TM out of a single-tape TM? - We can apply the same logic, but with any number of tapes. - If we can make a multi-tape TM out of a single-tape TM, that means multi-tape TMs are just as powerful as single-tape TMs. Simulating Turing machines - Turing machines are so powerful that they can simulate other Turing machines! Think of it like a virtual machine, like VMware or VirtualBox. - These Turing machines are called Universal Turing machines (UTM). Weird maths lan guage Plain En glish There exists a TM such thatğ‘ˆ ğ¿( ğ‘ˆ) = { ğ‘€#ğ‘¥ | ğ‘¥ âˆˆ ğ¿( ğ‘€) } Where is an encoding of the TM â€˜Mâ€™,followed byğ‘€#ğ‘¥ a â€˜#â€™,followed by an encoding of â€˜xâ€™in Mâ€™s input alphabet. Like all Turing machines, they have a string input. Universal Turing machines only accept strings that fit this pattern: ğ‘€#ğ‘¥ ... which is an encoding of the TM â€˜Mâ€™,a separating character (in this case #), and the encoding of the input string â€˜xâ€™. First of all, the UTM checks if M#x is a valid encoding. If it isnâ€™t,itâ€™llreject it straight away. If the TM â€˜Mâ€™accepts â€˜xâ€™,then the UTM will accept M#x If the TM â€˜Mâ€™rejects â€˜xâ€™,then the UTM will reject M#x The UTM does this by simulating M on â€˜xâ€™.If it finds that M accepts, then the UTM will accept. If it finds that M rejects, then the UTM will reject. Computer Science / Software Engineering Notes Network - We use UTMs without even thinking about it, for example interpreters (for Java, Python, Ruby etc.) and virtual machines. Encoding Turing machines - So how do you actually encode a TM and an input into M#x? - Well, the details arenâ€™t really important, but thereâ€™s a method from the Kozen book that converts all TM parameters into numbers, and then encodes them into one big number like this: - 0 ğ‘› 1 0 ğ‘š 1 0 ğ‘˜ 1 0 ğ‘  1 0 ğ‘¡ 1 0 ğ‘Ÿ 1 0 ğ‘¢ 1 0 ğ‘£ - where: - is the set of states{ 0 , 1 , 2 , 3 ,..., ğ‘› âˆ’ 1 } - is the tape alphabet where the first k numbers are the input{ 0 , 1 , 2 , 3 ,..., ğ‘š âˆ’ 1 } alphabet - Start, accept and reject states are , and respectivelyğ‘  ğ‘¡ ğ‘Ÿ - Blank symbol is and the endmarker isğ‘¢ ğ‘£ - So you use the number of zeroes to determine what state / alphabet character the encoding is referring to. - To encode the transitions, this encoding could be followed up by: - 0 ğ‘ 1 0 ğ‘ 1 0 ğ‘ 1 0 ğ‘ 1 0 - ... which is the encoded form of , orÎ´( ğ‘, ğ‘) = ( ğ‘, ğ‘, ğ¿) - 0 ğ‘ 1 0 ğ‘ 1 0 ğ‘ 1 0 ğ‘ 1 0 0 - ... which is the encoded form of Î´( ğ‘, ğ‘) = ( ğ‘, ğ‘, ğ‘…) Constructing a UTM - First of all, a UTM checks if the input string M#x is of the right encoding. - The rules for encoding could be anything;thereâ€™s lots of ways to do it. One of which is defined in the previous section. - Second, we use three tapes to store: - Description of M - Contents of Mâ€™s tape - Mâ€™s current state and position on the tape - Third, the UTM will loop through the following steps: 1. looks at Mâ€™s current state and head position (tape 3); 2. reads the tape contents at the correct position (tape 2); 3. reads the relevant transition (tape 1); 4. simulates transition, updating tape, state and head position; 5. accepts if M accepts, rejects if M rejects. Computer Science / Software Engineering Notes Network Halting problem - The Halting problem goes like this: - C an yo u co me up with a TM that takes in an en co din g M#x an d accep t if M halts o n x an d rejects if M lo o p s o n x? - Or, more formally... - Is the set recursive?ğ»ğ‘ƒ = { ğ‘€#ğ‘¥ | ğ‘€ â„ğ‘ğ‘™ğ‘¡ğ‘  ğ‘œğ‘› ğ‘¥ } - No. Proof by contradiction - Hereâ€™s an intuitive proof before we move onto diagonalisation. - Ever heard of the Pinocchio paradox? - What happens when Pinocchio says â€œMy nose will grow?â€ - If itâ€™s a lie, it wonâ€™t grow. But if it doesnâ€™t grow, Pinocchio will be lying, so it will grow. But then heâ€™s telling the truth, so it wonâ€™t grow, and weâ€™re just going around in circles. - This proof is just like that. - Letâ€™s say we have a TM called K that takes in an encoding M#x and accepts if it halts, and rejects if it loops. Basically, K solves the HP. - Letâ€™s create another TM called P that takes in an encoding of M, and runs K on M#M. It goes into an infinite loop if K accepts, and halts if K rejects. - What if we run P on P? Will it loop or halt? - If it loops, that means P halts. But if P halts, that means it has to loop. Weâ€™re going around in circles again;there is a contradiction! - If thatâ€™s a bit too wordy for you, hereâ€™s some pseudocode showing this: P o n M : c a l l K o n M # M i f K s a y s h a l t - - > g o i n t o i n f i n i t e l o o p i f K s a y s d o e s n ' t h a l t - - > h a l t P ( P ) = ? - Really good computerphile video explaining it via contradiction: https://www.youtube.com/watch?v=macM_MtS_w4 Proof by diagonalisation - We can also show how P is going to behave via diagonalisation - We can define the output of our TM K, which is supposed to decide the HP, by constructing a table - If K exists then we will be able to list the halting behaviour of all TMs in this table Computer Science / Software Engineering Notes Network Îµ 0 1 00 01 10 11 ... ğ‘€ Îµ H L L H L H L ğ‘€ 0 L L H H L H L ğ‘€ 1 H L L L L L L ğ‘€ 0 0 ... L H H L H L H - Where the left column is all the possible Turing machines and the top row is all the possible inputs. - We can create the TM P by taking a diagonal snippet of this table: Îµ 0 1 00 01 10 11 ... ğ‘€ Îµ H L L H L H L ğ‘€ 0 L L H H L H L ğ‘€ 1 H L L L L L L ğ‘€ 0 0 ... L H H L H L H - Then, we flip all of the cells. Our TM P behaves like this: Îµ 0 1 00 01 10 11 ... ğ‘ƒ L H H H H L H - This new TM P canâ€™t fit anywhere on our original table - The TM K cannot exist because the TM P wasnâ€™t anywhere on our table - Examples on how this table entry is equal to P: P on ( ):ğ‘€ Îµ Call K on #ğ‘€ Îµ Ïµ According to the table K returns H Therefore we will go into an infinite loop P on ( ):ğ‘€ 0 Computer Science / Software Engineering Notes Network Call K on #ğ‘€ 0 0 According to the table K returns L Therefore we will halt - So weâ€™ve proved that thereâ€™s no total Turing machine for this. However, the set HP is recursively enumerable. - Why? Because if the TM simulates M#x and it halts, the TM will accept this encoding. On all input strings that the TM accepts, the TM will accept it and not loop (because thatâ€™s the definition of an accepting string;it wonâ€™t loop). - So HP is recursively enumerable, but not recursive. That also means ~HP is not recursively enumerable (see proof in Recursive and R.E languages). - If ~HP is not recursively enumerable, there is no way of knowing if a Turing machine will loop on an input string or not. Decidable / Undecidable problems - A decidable problem is a decision problem for which there exists a total TM that decides it. - The total TM will accept for all yes/true instances and reject for all no/false instances of the problem. - Therefore, it will never loop for any input. - An un decidable problem is a decision problem for which there does not exist a total TM that decides it. - However, there might exist a TM that accepts yes/true instances and loops or rejects on no/false instances of the problem, making it semi-decidable. Computer Science / Software Engineering Notes Network - Ever heard of the membership problem? It goes like this: - ğ‘€ğ‘ƒ = { ğ‘€#ğ‘¥ | ğ‘¥ âˆˆ ğ¿( ğ‘€) } - Basically, can you make a TM that decides if a TM M will accept an input x? - Sounds simple, right? Well, itâ€™s actually impossible. Itâ€™s an undecidable problem. - Why is the membership problem undecidable? - Because if it was decidable, youâ€™d be able to solve the Halting problem, which we know cannot be solved because of our proof from before! If we had a TM K that solved the membership problem, we could create a TM N that would solve the Halting problem. - Letâ€™s construct a new TM N with input M#x: - Constructs a new TM Mâ€™which will change our existing machine M:All reject states become accept states, and all other states stay the same as before. Basically, Mâ€™will accept iff M halts on x. - Simulates K on Mâ€™#x. If K accepts, then make N accept. If K rejects, then make N reject. - Here, N solves the Halting problem because itâ€™ll accept if M halts on x and reject if M loops on x. - We know that the Halting problem is undecidable, so that means the membership problem must be undecidable. Computer Science / Software Engineering Notes Network - By doing this, weâ€™ve shown that the membership problem is just as hard as the Halting problem, because we can use the membership problem to solve the Halting problem. - This is called a reduction, at which we will take a closer look soon. Reductions - â€œReductionâ€ is an operation between two languages. - It is used to show the decidability of a language. - For example, in the previous section we â€œreducedâ€ the Halting problem to the membership problem, thus showing that the membership problem is undecidable (because we know the Halting problem is undecidable). - To represent this, we say that HP â‰¤ MP and, for our previous example, HP â‰¤ A. - Informally, a reduction is where you map one language to another language, so if you solve the second language with a TM, you can use that solution to solve the first language. - Like what we did with MP and HP;we reduced HP to MP, so if we solve MP, we can solve HP. - Formally, a function is computable when there exists a total TM â€˜Kâ€™thatğ‘“: Î£ * â†’ âˆ† * when started with on its tape, eventually halts with on its tape.ğ‘¥ âˆˆ Î£ * ğ‘“( ğ‘¥) âˆˆ âˆ† * - A reduction of to is a computable function s.t.ğ´ âŠ† Î£ * ğµ âŠ† âˆ† * ğ‘“: Î£ * â†’ âˆ† * ğ‘¥ âˆˆ ğ´ â‡” ğ‘“( ğ‘¥) âˆˆ ğµ - So a reduction function maps the inputs of one TM to another TM. - For example, remember the previous section when we showed how to solve the Halting problem if we had a TM K that could solve the membership problem by creating a TM N that could solve the Halting problem? - Hereâ€™s a diagram of what the TM N actually does: Computer Science / Software Engineering Notes Network - What N actually does is it takes in a Halting problem input, and uses the reduction function to turn it into a membership problem input. - Thatâ€™s all reduction is! Itâ€™s just a function converting input of one problem into an equivalent other. - Letâ€™s pluck out that reduction function and take a further look: - Letâ€™s say we have our TM for the Halting problem N and our TM for the membership problem K again. - If we run N on M#x, it should yield the same result as running K on Mâ€™#x. - In summary, just think this: - If you see A â‰¤ B, then you can convert the problem A into the problem B. - Letâ€™s look at some more examples Computer Science / Software Engineering Notes Network State Entry Problem (SEP) Decide whether a TM Mâ€™enters a given state q on input x Assume that we already have a TM K that decides the SEP. Create a TM N which decides the HP using a reduction from the HP to the SEP. N on inputs M and x (e.g. as an encoding M#x): 1. Construct a new TM Mâ€™from M a. Add a new state q which is not in M b. From all halting states add a new transition to q c. Make all halting states non-halting states 2. Simulate K on inputs M', q, x (e.g. as an encoding Mâ€™#q#x) 3. Accept if K accepts, reject if K rejects Since we know that the HP is undecidable, the SEP must also be undecidable Blank Tape Halting Problem (BTHP) Decide whether a TM Mâ€™halts on the blank tape (no input). Decide whether a TM Mâ€™halts on input epsilon. Assume that we already have a TM K that decides the BTHP. Create a TM N which decides the HP using a reduction from the HP to the BTHP. N on inputs M and x (e.g. as an encoding M#x): 1. Construct a new TM Mâ€™from M a. Ignore any input b. Write x on the blank tape and reset the tape head Computer Science / Software Engineering Notes Network c. Execute M with x on the tape and return the result 2. Simulate K on input Mâ€™ 3. Accept if K accepts, reject if K rejects If you are confused about Mâ€™: â— Mâ€™is a special version of M â— Mâ€™has the same instructions as M, however, it has some instructions prepended to the other instructions â—‹ We will ignore any input given to Mâ€™ â—‹ We need to write x on the tape and reset the tape head to the start â— So all in all we have a TM Mâ€™which has x hard coded in its instructions Since we know that the HP is undecidable, the BTHP must also be undecidable Emptiness Problem (EP) Semi-decide whether the language of a TM Mâ€™is the empty set Assume that we already have a TM K that semi-decides the EP. Create a TM N which semi-decides the LP (complement of HP) using a reduction from the LP to the EP. Computer Science / Software Engineering Notes Network N on inputs M and x (e.g. as an encoding M#x): 1. Construct a new TM Mâ€™from M a. Ignore any input b. Write x on the blank tape and reset the tape head c. Execute M with x on the tape d. Accept if the execution ends 2. Simulate K on input Mâ€™ 3. Accept if K accepts If you are confused about Mâ€™: â— Similarly to the last example Mâ€™will ignore any input and write x to the tape, so again our TM Mâ€™comes with the x hard-coded â— Now, if M loops on x, then Mâ€™will also loop and never accept. Therefore, L(Mâ€™) is the empty set. â— If M doesnâ€™t loop on x, then Mâ€™will accept and its language is clearly not equal to the empty set Since we know that the LP is not semi-decidable, the EP cannot be semi-decidable as well. Same Language Problem (SLP) Decide whether TMs M1 and M2 accept the same language. Assume that we already have a TM K that decides the SLP. Create a TM N which decides the HP using a reduction from HP to SLP. N on inputs M and x (e.g. as an encoding M#x): Computer Science / Software Engineering Notes Network 1. Construct a new TM M1: a. Simulate M on x b. If simulation halts accept (no matter what the input is) 2. Construct a new TM M2: a. Accept (no matter what the input is) 3. Simulate K on inputs M1 and M2 4. Accept if K accepts, reject if K rejects This works because â— M2 always accepts everything, so its language is Î£ * â— M1 either accepts nothing or everything â—‹ If the simulation halts, i.e. if M halts on x, it will accept everything, so its language is Î£ * â—‹ If the simulation doesnâ€™t halt, then it will loop and run forever. Therefore its language is the empty set. â— We can see that the language of M1 and M2 is the same if and only if M halts on x â— So when we ask K if M1 and M2 have the same language it will accept if and only if M halts on x and reject otherwise â— We can use this answer to solve the HP, which is a contradiction because we know that the HP is undecidable Since we know that the HP is not decidable, the SLP must be undecidable as well. Properties of reductions - If A â‰¤ B and B is r.e. then so is A. Equivalently, if A is not r.e. then B is not r.e. - An example of this reduction rule is MP â‰¤ HP. - If A â‰¤ B, then thereâ€™s a reduction function from A to B:ğ‘“: ğ´ â†’ ğµ - If B is r.e, then there exists a TM â€˜Mâ€™that accepts B. - To prove A is r.e, we just need to define a TM that accepts A. - This is that TM â€˜Nâ€™: - On an input â€˜xâ€™, compute f(x) - Run â€˜Mâ€™on f(x) - If that accepts, make N accept - If that rejects, make N reject - If A is not r.e, then there is no TM that accepts it. - Letâ€™s just say a TM exists for B, called â€˜Mâ€™. - Using the same TM we defined before (N), we can now define a TM to accept A, if the TM â€˜Mâ€™actually exists. - This is a contradiction, so a TM for B cannot exist if A is not r.e., and therefore B is not r.e. Computer Science / Software Engineering Notes Network - If A â‰¤ B and B is recursive then so is A. Equivalently, if A isnâ€™t recursive then neither is B - Itâ€™s the same proof as before, except now, the TM â€˜Mâ€™halts on all inputs. - If we follow through the same steps as before, our TM â€˜Nâ€™will not halt on any inputs either, because it uses â€˜Mâ€™. This means that A is recursive when B is. - The same goes for B not being recursive if A isnâ€™t. - If A is not recursive, then itâ€™s either r.e or not r.e. Weâ€™ve already proved the case for when A is not r.e, so letâ€™s prove the case for when A is r.e. - Letâ€™s say that B is recursive and has a TM â€˜Mâ€™that halts on all inputs. - If we have â€˜Mâ€™, we can create a total TM â€˜Nâ€™that halts on all inputs and determines A. - Therefore, B cannot be recursive if A is not recursive. Riceâ€™s theorem - Does Theory of Computing depress you? - Well, this theorem is about to make it worse. - Riceâ€™s theorem states that every non-trivial property of r.e sets is undecidable. - So, what does this actually mean? - Every language with a non-trivial property is constructed by a Turing Machine which loops. - A r.e set is actually the same as a TM, but weâ€™re just referring to a TM by its language. By saying r.e set instead of TM, we ignore things like the TMâ€™s states, tape etc. and we only focus on the language it recognises. - A property of an r.e set is a property of the TMâ€™s language. Itâ€™s a predicate that tells you about what the TM recognises. - A non-trivial property is a property that isnâ€™t always true or always false. - So what Riceâ€™s theorem means is that if you partition the set of all r.e sets into two using some condition, both partitions will be undecidable. - Letâ€™s visualise this. We have the set of all r.e sets: Computer Science / Software Engineering Notes Network - What if I were to split this set into two, using some property? - Letâ€™s say the property is this:â€œthe r.e set must contain the empty stringâ€. - Now we know our sets arenâ€™t recursive anymore! This is due to Riceâ€™s theorem. - Why are they not recursive? - Remember the â€œDecidable / Undecidable problemsâ€ section where we proved that itâ€™s impossible to have a total TM that tells if M accepts the empty string? - It doesnâ€™t stop at accepting the empty string. Any predicate you can think of that splits the set of all r.e sets are undecidable: - Accepts any string at all? - Accepts every string? - Accepts a given finite language? - Accepts a given regular language? - Accepts a context-free language? - Accepts a recursive language? - Accepts a language with the word â€œdavidtyoemberâ€ (ğŸ˜) in it? - You may be thinking â€œWhy keep using the term â€˜r.e setâ€™? Why not just say any non-trivial property of a Turing machine is undecidable?â€ - Thereâ€™s a reason why itâ€™s only a property of a TMâ€™s language and not a property of the TM itself. Computer Science / Software Engineering Notes Network - The following are properties of TMs, but not r.e sets: - M has less than 400 states (this isnâ€™t a property of an r.e set because 1. it queries nothing about the language and 2. you could find two TMs that recognise the same set, but one having less than 400 states and one having more than or equal to 400 states) - M halts on all inputs (this isnâ€™t a property of an r.e set because 1. it, again, queries nothing about the language and 2. you could have two TMs that recognise the same set, one halting on all inputs and one which doesnâ€™t) - So if the concept of r.e sets is a little weird to you, then donâ€™t worry;just think about it in terms of TMs and their languages. Instead of a property of a r.e set, think of a property of a TMâ€™s language. - Sure, because of Riceâ€™s theorem, there are lots of properties that are undecidable, like: - membership problem for TMs:does a given TM accept a given string? - emptiness problem for TMs:does a given TM accept any strings at all? - equivalence problem for TMs:given two TMs, do they accept the same language? - ... but there are properties that are decidable: - membership problem for DFAs/NFAs:does a given DFA/NFA accept a given string? - emptiness problem for DFAs/NFAs: does a given DFA/NFA accept any strings at all? - equivalence problem for DFAs:given two DFAs, do they accept the same language? - membership problem for CFGs - emptiness problem for CFGs - Theyâ€™re all decidable because simulations of NFAs, DFAs and CFGs are all decidable;you canâ€™t loop with any of those because with each transition, a bit of the string is being spent. - If Riceâ€™s theorem depressed you, donâ€™t worry. Youâ€™ve come this far, and thereâ€™s only one topic left to go. You can do it! I believe in you! Computer Science / Software Engineering Notes Network Complexity theory - We know that Turing machines and algorithms are equivalent. However, how do we measure and compare the complexity of algorithms? - Complexity theory is concerned with measuring how the time/space required by an algorithm/problem increases as the input gets larger - You should remember Big-O notation from Algorithmics (I hope). - In this module, we use Big-O and Big-Ï´, and we use the classes P and NP to categorise problems. Big-O and Big-Ï´ - To define complexity in an algorithm or a problem, we use Big-O and Big-Ï´ notation. - The complexity of a problem is the complexity of the best algorithm that currently exists for this problem. Big-Ï´ - In fo rmally ( En glish) : - If an algorithm is for some equation , that means that theğ‘“( ğ‘›) Î˜( ğ‘”( ğ‘›) ) ğ‘”( ğ‘›) algorithmâ€™s complexity scales with and can only scale by , it can doğ‘”( ğ‘›) ğ‘”( ğ‘›) no better than that. - For example, the average-case complexity of quick sort is .Î˜( ğ‘› ğ‘™ğ‘œğ‘”( ğ‘›) ) - If a problem is for some equation , that means there existsğ‘“( ğ‘›) Î˜( ğ‘”( ğ‘›) ) ğ‘”( ğ‘›) no algorithm that can solve the problem at a complexity better than .ğ‘“( ğ‘›) ğ‘”( ğ‘›) - In other words, it means is the complexity of the best knownÎ˜( ğ‘”( ğ‘›) ) algorithm for .ğ‘“( ğ‘›) - For example, the sorting problem has the complexity because noÎ˜( ğ‘› ğ‘™ğ‘œğ‘” ğ‘›) sorting algorithm exists that does better than (except sleepsort, butğ‘› ğ‘™ğ‘œğ‘” ğ‘› that doesnâ€™t count). - Fo rmally ( weird maths lan guage) : - We say that is for some if there exist reals:ğ‘“( ğ‘›) Î˜( ğ‘”( ğ‘›) ) ğ‘”( ğ‘›) - c > 0 - d > 0 - integer M > 0 - with - for all .ğ‘‘ğ‘”( ğ‘›) â‰¤ ğ‘“( ğ‘›) â‰¤ ğ‘ğ‘”( ğ‘›) ğ‘› â‰¥ ğ‘€ - We say that and have the same rate of growth.ğ‘“( ğ‘›) ğ‘”( ğ‘›) Big-O - In fo rmally ( En glish) : Computer Science / Software Engineering Notes Network - If an algorithm is for some equation , that means that theğ‘“( ğ‘›) ğ‘‚( ğ‘”( ğ‘›) ) ğ‘”( ğ‘›) algorithmâ€™s complexity scales, at worst, with , but it could do better inğ‘”( ğ‘›) certain cases. - For example, the worst-case complexity of bubble sort is .ğ‘‚( ğ‘› 2 ) - If a problem is for some equation , that means our bestğ‘“( ğ‘›) ğ‘‚( ğ‘”( ğ‘›) ) ğ‘”( ğ‘›) algorithm can solve this problem with complexity . There might exist anğ‘”( ğ‘›) algorithm that does better, but we havenâ€™t discovered it yet. - In other words, it means is the complexity of the best knownğ‘‚( ğ‘”( ğ‘›) ) algorithm for .ğ‘“( ğ‘›) - For example, if we had an algorithm that had a worst-case of , thenğ‘‚( ğ‘› ğ‘™ğ‘œğ‘” ğ‘›) that means the algorithm will, at worst, perform , but may performğ‘› ğ‘™ğ‘œğ‘” ğ‘› better on average-case or best-case. - Fo rmally ( weird maths lan guage) : - We say that is for another function if there exist reals:ğ‘“( ğ‘›) ğ‘‚( ğ‘”( ğ‘›) ) ğ‘”( ğ‘›) - c > 0 - integer M > 0 - with - for all .ğ‘“( ğ‘›) â‰¤ ğ‘ğ‘”( ğ‘›) ğ‘› > ğ‘€ - We say that g(n) is an asymptotic upper bound for f(n) The class P â— The class P is the set of all decision problems that can be solved by a deterministic Turing machine in polynomial time. â—‹ Decision problem â†’ For all inputs we receive a â€œyesâ€ or â€œnoâ€ answer â—‹ Deterministic Turing machine â†’ A Turing machine that cannot make any choices in terms of the next move â–  This is the model of a Turing machine that we have seen so far â–  We will see a non-deterministic Turing machine later â—‹ Solved in polynomial time â†’ The problem is feasible â— Some examples that are in P are â—‹ Searching an unordered list â–  Use sequential search, which is ğ‘‚( ğ‘›) â—‹ Searching an ordered list â–  Use binary search, which is ğ‘‚( ğ‘™ğ‘œğ‘”( ğ‘›) ) â—‹ Testing whether a list is sorted â–  Go through the list sequentially and compare each element with the element before, which is Î˜( ğ‘›) â— An example that is not in P is:Given a first-order statement about non-negative integer variables (with only symbols 0, 1, +, = and logical operators allowed), is it true? Computer Science / Software Engineering Notes Network â—‹ We are going to look at some equation with non-negative integer variables, i.e. variables that can be assigned natural numbers â—‹ On the left and right hand side of the equation we can only â–  use the variables â–  use the â€œ+â€ operation â–  use the numbers â€œ0â€, â€œ1â€ â—‹ We will use quantifiers to form the first-order logic statement, which is going to be either true or false â–  We can use the quantifiers â€œfor allâ€ and/or â€œthere existsâ€ â–  We must define one quantifier for each variable â—‹ Problem instances are: â–  âˆ€ğ‘¥âˆƒğ‘¦( ğ‘¥ + ğ‘¦ = ğ‘¥ + 1 ) â— For all x there exists y such that the equation holds â–  âˆƒğ‘¥âˆ€ğ‘¦âˆƒğ‘§( ğ‘¥ + ğ‘§ = ğ‘¥ + ğ‘¦ + ğ‘§) â— There exists x then for all y there exists z such that the equation holds â—‹ This problem is known to be decidable, but infeasible â–  This means that we can always say whether this equation holds or not â–  However, this cannot be done in polynomial time with a deterministic machine Feasible and infeasible problems â— A problem is said to be feasible if it has an algorithm with time complexity someâ‰¤ polynomial f(n). â—‹ Examples: , , ,Î˜( ğ‘›) Î˜( ğ‘› ğ‘™ğ‘œğ‘”( ğ‘›) ) Î˜( ğ‘›) Î˜( ğ‘› 6 ) â—‹ These are problems with polynomial time complexity â— Otherwise, a problem that can be solved in finite time but has no polynomial time algorithm is said to be infeasible â—‹ Examples: , ,Î˜( 2 ğ‘› ) Î˜( 1 . 3 ğ‘› ) Î˜( ğ‘›!) â—‹ These are problems with complexity greater than polynomial time (exponential and factorial time complexity) Decision problems â— A computational problem is called a decision problem if the output for any problem instance is either â€œyesâ€ or â€œnoâ€. â—‹ A problem instance is a specific input for a problem â—‹ For example, the numbers â€œ1â€, â€œ4â€, â€œ5â€, â€œ8â€ are problem instances for an algorithm that determines whether a number is an even number or not â—‹ This algorithm is a decision problem because given a number this algorithm can say â€œyes this number is evenâ€ or â€œno this number is not evenâ€ â— We can classify the problem instances into positive/â€yesâ€ instances and negative/â€noâ€ instances Computer Science / Software Engineering Notes Network â—‹ For example, â€œ4â€ and â€œ8â€ are positive instances and â€œ1â€ and â€œ5â€ are negative instances of the â€œis this number evenâ€ problem. â— The â€œyesâ€ instances are forming a language. Therefore, solving the decision problem is the same as deciding this language â—‹ For example, the positive instances of the â€œis this number evenâ€ problem form the language of all even numbers. â—‹ ğ¿ ğ‘’ğ‘£ğ‘’ğ‘› ğ‘›ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿğ‘  = { ..., âˆ’ 4 , âˆ’ 2 , 0 , 2 , 4 , ...} The PATH problem â— Let PATH be the following decision problem:Given a directed graph, does there exist a directed path connecting two given nodes? â— For example, given the following graph: â— Does there exist a path from 1 to 6? â—‹ Yes, 1 â†’ 2 â†’ 4 â†’ 6 â— Does there exist a path from 3 to 4? â—‹ Yes, 3 â†’ 5 â†’ 4 â— Does there exist a path from 5 to 1? â—‹ No, from 5 we can only reach 4 and 6 â— Does there exist a path from 1 to 3? â—‹ No, from 1 we can reach all nodes but 3 â— A polynomial time algorithm for PATH is the following: â—‹ On input (G, s, t), where G is the graph, s is the start node and t is the goal node â—‹ Place a mark on node s â—‹ Repeat the following until no additional nodes are marked â–  For each edge from node a to b of G, if a is marked then also mark b Computer Science / Software Engineering Notes Network â—‹ If t is marked then accept, otherwise reject â— This algorithm runs in polynomial time â—‹ The graph has n nodes and m edges â—‹ For each node n we have to mark and check at most m other nodes which are directly connected (via an edge) to n â—‹ Therefore, this algorithm runs in timeğ‘‚( ğ‘› * ğ‘š) The HAMPATH problem â— Let HAMPATH be the following decision problem:Given a directed graph, does there exist a directed path connecting two given nodes that goes through each node exactly once? â— This is an extension of PATH:We do not only have to find a path from one node to another node - the path also needs to go through each node exactly once. â— The best known algorithm for this problem is exponential, however, we do not know if there exists a polynomial time algorithm. â— Given a candidate for a HAMPATH, we can verify it in polynomial time. Regular and context-free languages â— Every regular language is in P â—‹ If a language is regular then there exists a DFA that accepts the language â—‹ A Turing machine can simulate a DFA â—‹ It will have the input string and a symbol that marks the end of the string (end marker) on the tape â—‹ It will always move right after consuming a symbol and change state in the same way as the DFA would change state â—‹ When it reaches the end marker and it is in a state that corresponds to the accept state of the DFA it will accept, otherwise it will reject â—‹ Therefore, the Turing machine will execute exactly n steps (where n is the length of the input string) so itâ€™s time complexity is Î˜( ğ‘›) â— Every context-free language is in P â—‹ For every context-free language there exists a corresponding context-free grammar. â—‹ For every context-free grammar, there exists another grammar which accepts the same language in Chomsky normal form. â—‹ Grammars in Chomsky can be parsed using the CYK (Cocke-Younger-Kasami) algorithm (citation), which parses in cubic time, which is polynomial. â—‹ One could create a Turing machine which applies the CYK algorithm to a given context-free grammar, and that Turing machine would accept said context-free language in cubic time. Computer Science / Software Engineering Notes Network The class NP - The class NP is the set of all decision problems that can be solved by a non-deterministic Turing machine in polynomial time - NP stands for non-deterministic polynomial - Anything in P is also in NP. If a problem can be solved in polynomial time by a deterministic machine, then also by a non-deterministic one. - Letâ€™s look at some NP problems which are believed not to be in P Non-deterministic Turing machine - A non-deterministic TM is of the same form as a deterministic TM: - ğ‘€ = ( ğ‘„, Î£, Î“, âŠ¢, âŠ”, Î´, ğ‘ , ğ‘¡, ğ‘Ÿ) - However, the transition function is defined differently - is the transition functionÎ´: ( ğ‘„ âˆ’ { ğ‘¡, ğ‘Ÿ} ) Ã— Î“ â†’ğ‘ƒ( ğ‘„ Ã— Î“ Ã— { ğ¿, ğ‘…} ) - Note that the output of the function is now a power set of configurations - This means that given a configuration, there are many possible other configurations in which the TM can be after making the transition - Therefore, the Turing machine becomes non-deterministic. - We can think of the non-deterministic TM as a TM that makes all possible transitions from a given configuration in parallel - Therefore, the computation of a non-deterministic TM is a tree, whose branches are all traversed in parallel - In contrast, the computation of a deterministic TM is a linear path, as there is exactly one configuration after making a transition. - Non-deterministic TMs have the same expressibility as deterministic TMs. We can simulate a non-deterministic TM with a multi-tape deterministic TM. - The deterministic TM has four tapes: - One to remember the input. - One to simulate the current state of the branch. - One to remember the branch being simulated on. - One to remember the branches simulated. - The deterministic TM accepts an input when one of the branches accepts, and rejects otherwise. - A non-deterministic TM is a decider when all its branches halt on all inputs, similar to a total TM. Computer Science / Software Engineering Notes Network - Since we now have a tree of configurations, we need to re-think the condition when the non-deterministic TM accepts/rejects. - Reminder:A deterministic TM - accepts/rejects as soon as it reaches a accept/reject configuration - loops if it never reaches such a configuration - A non-deterministic TM - accepts if so me branch of the computation leads to the accept state - rejects if all branches of the computation lead to the reject state - loops if none of those two conditions are ever met - For example, the tree can be infinite and without any accept state - If all branches halt on all inputs, i.e. if the computation tree is finite, the non-deterministic TM is called a decider - This is similar to a deterministic total TM, which always halts on any input - The decider accepts an input if there exists a sequence of choices, where at least one ends in the accepting state. - Otherwise all choices will end in the reject state and the decider will reject the input - Non-deterministic TMs are n o t mo re p o werful than deterministic TMs as we are going to see shortly - For any non-deterministic TM there exists a deterministic TM accepting the same language - A non-deterministic TM N can be simulated by a 3-tape deterministic TM D - D will try all branches of Nâ€™s computation using breadth first search - If we use depth first search our simulation can get stuck in an infinite loop in case of an infinite tree - There might exist an accept state on another branch which we are unable to reach because of the infinite loop - In order to avoid this we have to use breadth first search - The 3 tapes are used as follows Computer Science / Software Engineering Notes Network - One tape stores the input - One tape used to simulate a branch up to a given depth - One tape used to remember the branch being simulated - If D ever finds the accept state in the tree it will accept. Otherwise D will loop, or reject if all branches evaluate to a reject state. - For any non-deterministic TM that halts on all branches (= decider) there exists a total TM deciding the same language - We can modify the proof from above such that if N halts on all branches then D halts - Therefore, we will introduce a fourth tape where we remember the branches that halt. We are not going to explore these branches again - If there is no branch left to explore, reject - Therefore, we can conclude that any non-deterministic TM has an equivalent deterministic TM Time complexity of Turing machines - Letâ€™s think about the time complexity of Turing machines - First, we will define the following: - The size of a problem instance = the number of symbols on the input tape - The algorithm cost (measure of time taken) = number of steps the Turing machine takes - The time complexity of a decider is a function f(n), where f(n) is the maximum number of steps the machine takes on any branch of its computation, on any input of length n. - In other words, to determine the time complexity of a decider, we are going to take a look at the computation tree for some input of length n Computer Science / Software Engineering Notes Network - The time complexity is equal to the depth of this tree - Every time multi-tape deterministic TM has an equivalent timeğ‘¡( ğ‘›) ğ‘‚( ğ‘¡ 2 ( ğ‘›) ) single-tape deterministic TM - If a multi-tape TM runs in time, it can only use tape cells on eachğ‘¡( ğ‘›) ğ‘¡( ğ‘›) tape - We can construct a single-tape TM that simulates the multi-tape TM - Before simulating a single step of the multi-tape TM we need to find the position of the tape heads. These positions will be marked using special symbols on the tape. - Therefore, we are going to scan the tape from left to right, which takes an extra steps. The tape heads might be anywhere on the tape butğ‘‚( ğ‘¡( ğ‘›) ) cannot be beyond the tape cells, which is why we use big O notationğ‘¡( ğ‘›) here. - All in all, we have steps to simulate, and for each step we can find theğ‘¡( ğ‘›) tape heads in time, so all in all we require time for theğ‘‚( ğ‘¡( ğ‘›) ) ğ‘‚( ğ‘¡ 2 ( ğ‘›) ) whole simulation. - The following is an example of a single-tape TM simulating a 3-tape TM. The position of the heads is marked with a â€œ^â€ symbol: âŠ¢ âŠ¢ a bÌ‚ c d e âŠ¢ h i j kÌ‚ l âŠ¢ vÌ‚ w x y z - Every time non-deterministic Turing machine has an equivalent timeğ‘¡( ğ‘›) 2 ğ‘‚( ğ‘¡( ğ‘›) ) deterministic Turing machine - Each branch of a time non-deterministic TM N has length of at most .ğ‘¡( ğ‘›) ğ‘¡( ğ‘›) Computer Science / Software Engineering Notes Network - Remember:the time complexity of a non-deterministic TM is defined as the depth of the computation tree - Therefore, the length of the longest branch is equal to the time complexity - Each node in the computation tree of N can have up to children.ğ‘ - This is also known as the branching factor of the tree. - Therefore, there are at most leaves, and nodes in theğ‘ ğ‘¡( ğ‘›) ğ‘‚( ğ‘ ğ‘¡( ğ‘›) ) computation tree of the non-deterministic TM N - A tree with branching factor and depth cannot have more thanğ‘ ğ‘‘ ğ‘ ğ‘‘ nodes - A tree with branching factor and depth cannot have more thanğ‘ ğ‘‘ leaves. Furthermore, it also cannot have more than leaves,ğ‘ ğ‘‘âˆ’ 1 ğ‘ ğ‘‘ which is a less restrictive statement. - We can construct a multi tape deterministic TM to simulate N. This will take time.ğ‘‚( ğ‘¡( ğ‘›) *ğ‘ ğ‘¡( ğ‘›) ) - We need to simulate the path from the root to each of the leaves. Since we have at most leaves we need to simulate at mostğ‘ ğ‘¡( ğ‘›) paths.ğ‘ ğ‘¡( ğ‘›) - Each of the paths we are going to simulate is no longer than ğ‘¡( ğ‘›) - Therefore the simulation will take no longer than timeğ‘¡( ğ‘›) *ğ‘ ğ‘¡( ğ‘›) - is (see tutorial 8 question 2)ğ‘¡( ğ‘›) * ğ‘ ğ‘¡( ğ‘›) 2 ğ‘‚( ğ‘¡( ğ‘›) ) - The big O notation is an upper bound and hides a constant ,ğ‘ therefore we have to show that there exists some andğ‘ > 0 ğ‘€ âˆˆ â„• such that for allğ‘¡( ğ‘›) * ğ‘ ğ‘¡( ğ‘›) â‰¤ 2 ğ‘*( ğ‘¡( ğ‘›) ) ğ‘› â‰¥ ğ‘€ - The proof for this is just below: Pro o f fro m the tuto rial that I do n â€™t un derstan d ğ‘¡( ğ‘›) â‰¤ 2 ğ‘¡( ğ‘›) ğ‘¡( ğ‘›) * ğ‘ ğ‘¡( ğ‘›) â‰¤ 2 ğ‘¡( ğ‘›) * ğ‘ ğ‘¡( ğ‘›) = ( 2 ğ‘) ğ‘¡( ğ‘›) â‰¤ ( 2 ğ‘ ) ğ‘¡( ğ‘›) = 2 ğ‘*ğ‘¡( ğ‘›) For all , therefore andğ‘› â‰¥ 1 ğ‘ = ğ‘ ğ‘€ = 1 My p ro o f that I fully un derstan d Computer Science / Software Engineering Notes Network ğ‘¡( ğ‘›) â‰¤ 2 ğ‘¡( ğ‘›) ğ‘¡( ğ‘›) * ğ‘ ğ‘¡( ğ‘›) â‰¤ 2 ğ‘¡( ğ‘›) * ğ‘ ğ‘¡( ğ‘›) ğ‘¡( ğ‘›) * ğ‘ ğ‘¡( ğ‘›) â‰¤ 2 ğ‘¡( ğ‘›) * ( 2 ğ‘™ğ‘œğ‘” 2 ( ğ‘) ) ğ‘¡( ğ‘›) ğ‘¡( ğ‘›) * ğ‘ ğ‘¡( ğ‘›) â‰¤ 2 ğ‘¡( ğ‘›) * 2 ğ‘™ğ‘œğ‘” 2 ( ğ‘) Ã—ğ‘¡( ğ‘›) ğ‘¡( ğ‘›) * ğ‘ ğ‘¡( ğ‘›) â‰¤ 2 ğ‘™ğ‘œğ‘” 2 ( ğ‘) Ã—ğ‘¡( ğ‘›) + ğ‘¡( ğ‘›) ğ‘¡( ğ‘›) * ğ‘ ğ‘¡( ğ‘›) â‰¤ 2 ( ğ‘™ğ‘œğ‘” 2 ( ğ‘) + 1 ) Ã— ğ‘¡( ğ‘›) ğ‘¡( ğ‘›) * ğ‘ ğ‘¡( ğ‘›) = 2 ğ‘‚( ğ‘¡( ğ‘›) ) For all , therefore andğ‘› â‰¥ 1 ğ‘ = ğ‘™ğ‘œğ‘” 2 ( ğ‘) + 1 ğ‘€ = 1 The SAT problem - SAT:Boolean satisfiability - Given a boolean expression, does there exist an assignment of true and false (or 0s and 1s) to all variables such that the formula is satisfied? - Example:( ğ‘¥ âˆ¨ ğ‘¦ âˆ¨ Â¬ğ‘§) âˆ§ ( ğ‘¤ âˆ¨ Â¬ğ‘§) âˆ§ ( Â¬ğ‘¤ âˆ¨ ğ‘¥) - Does there exist an assignment for the variables such that theğ‘¤, ğ‘¥, ğ‘¦, ğ‘§ formula is satisfied? - SAT is in NP:We can non-deterministically generate all possible assignments to the variables and then check if the formula is satisfied. - For each variable, we have two options:It can be either true or false - If we want to solve this problem in a deterministic way, we have to try out either true or false for each of the variables - Therefore, it will take time where is the number of variables2 ğ‘› ğ‘› - However, a non-deterministic machine has the power to always guess the right assignment for each of the variable - For instance, if we have three variables there are 8 differentğ‘¥, ğ‘¦, ğ‘§ assignments for these variables - The non-deterministic machine will always pick the right assignment for each of the variables before moving on to the next variable Computer Science / Software Engineering Notes Network - We can visualise this in a computation tree. The non-deterministic machine will instantly pick the right path from the root to the leaf which makes the formula true (if such an assignment exists) - Therefore, it can solve the problem in linear time (linear in the number of variables) - - We donâ€™t know if SAT is in P because we currently do not have any polynomial time algorithm for it. However, no one has been able to prove that there isnâ€™t one. The HAMPATH problem - HAMPATH:Given a directed graph, does there exist a directed path connecting two given nodes that goes through each node exactly once? - We can non-deterministically generate all sequences of nodes of length equal to the size of the graph, and then check the following: - No repetitions are found in the sequence - The start and end of the sequence coincide with the required nodes - The sequences defines a directed path through the graph - We donâ€™t know if HAMPATH is in P The TSP(D) problem - TSP(D) refers to the Travelling Salesperson Problem. Computer Science / Software Engineering Notes Network - For this problem, you have a graph with weighted edges and an input D. - Is there a route leading all around the graph and back to the start with a total distance at most D? - This problem is in NP because the TM would have to â€˜guessâ€™the order of cities to check in, then add up the distances to see if itâ€™s at most D. - We donâ€™t know if TSP(D) is in P. The 3COL problem - 3COL:3-colourability - Given a graph G, is it possible to colour all the vertices with one of three available colours such that no two adjacent vertices are the same colour? - Here is an example of a solution: - This problem is in NP because we can non-deterministically guess the colour of each vertex;our computation splits into 3 branches of â€œis this node red?â€, â€œis this node blue?â€, or â€œis this node green?â€. - We donâ€™t know if 3COL is in P. NP = P? - This is one of the biggest problems in computer science. Is NP equal for P? What if every problem in NP has a P algorithm, but we just havenâ€™t discovered them all yet? - I donâ€™t know. - But if P does equal NP, that means: - P = NP = NP-complete - To prove that P = NP-complete, we need to show that all problems in NP can reduce to all problems in P in polynomial time. - So weâ€™ll have some arbitrary problem X in P and some arbitrary problem Y in NP. - We will then reduce Y to X. When we do that, weâ€™ll have proved that all NP problems reduce to all P problems and that P = NP-complete, hence P = NP = NP-complete. - If Y is in NP, that means itâ€™s in P also (because P = NP). Computer Science / Software Engineering Notes Network - This proof only works if the language of X is non-trivial, meaning itâ€™s not the empty set or sigma star! - If X is not trivial, that means there exists an input such that X will accept it,ğ‘– 1 and an input such that X will reject it.ğ‘– 2 - Our reduction formula will remember this, and simulate an input y on Y. If Y accepts, then the formula returns . If Y rejects, then the formula returns .ğ‘– 1 ğ‘– 2 - This is computable in polynomial time and maps yes/no instances of Y to yes/no instances of X, hence proving that if P = NP, then P = NP = NP-complete. - P âŠ‚ NP-hard - Following from the P = NP = NP-complete rule we proved earlier... - Some NP-hard problems are NP-complete. - If P = NP-complete, that means some NP-hard problems are also in P. - Therefore, P is a strict subset of NP-hard. - Here is what the problem sets will look like if P != NP and P = NP (just remember that trivial problems are in P and NP, just not NP-complete!): Presburger arithmetic - Hereâ€™s a problem thatâ€™s so hard that itâ€™s not even in NP. However, it is decidable (possible to solve). - It goes like this: - You have a set of variables, each with either a â€˜for allâ€™for â€˜there existsâ€™. - There is also a formula that links up all the variables together. - Is the formula true? - If that explanation didnâ€™t make much sense, the problems look like this: Computer Science / Software Engineering Notes Network - The question is:do these formulae hold? - This is so hard that this is at least doubly exponential, which is !ğ‘( ğ‘ ğ‘¥) NP-Completeness Polynomial time reduction - Remember reduction with Turing machines? - We can do the same here;we can reduce a problem to another problem. - If we can reduce problem A to problem B, then any polynomial algorithm for B also applies for A, right? - Almost! The reduction needs to be in polynomial time as well. This is called a polynomial time reduction. - So to solve problem A, we need to reduce it to B in polynomial time, then solve B in polynomial time. Polynomial + polynomial = polynomial, so solving A would also be in polynomial time. - If youâ€™re a visual learner, maybe this diagram will help (it goes from left to right): - Polynomial time reduction is written like this: - ğ´ â‰¤ ğ‘ƒ ğµ - More formally, itâ€™s defined like this: - A function is polynomial time computable if there exists a polynomial timeğ‘“: Î£ * â†’ âˆ† * deterministic Turing machine that halts on each input with just on itsğ‘¤ âˆˆ Î£ * ğ‘“( ğ‘¤) tape. - From this, we can conclude that if A reduces to B in polynomial time, and B is in P, then A is in P. - Additionally, if A reduces to B in polynomial time, and A is not in P, then B is not in P. 3COL to SAT - We can reduce 3COL (3-colourability) to SAT (boolean satisfiability). Computer Science / Software Engineering Notes Network - We can do this by: - for each node â€˜xâ€™in 3COL... - ... create 3 variables in SAT, rx (is â€˜xâ€™red?), gx (is â€˜xâ€™green?), and bx (is â€˜xâ€™ blue?). - After weâ€™ve created our variables, we need to define three expressions: 1. For each vertex â€˜xâ€™, the expression: ( r x O R g x O R b x ) must be true (each vertex must be assigned a colour) 2. For each vertex â€˜xâ€™, the expression: ( ! ( r x A N D g x ) A N D ! ( r x A N D b x ) A N D ! ( b x A N D g x ) ) must be true (each vertex may only have ONE colour) 3. For each edge â€˜x yâ€™, the expression:â†’ ! ( r x A N D r y ) A N D ! ( g x A N D g y ) A N D ! ( b x A N D b y ) must be true (no two adjacent vertices should have the same colour) - All these expressions are â€˜ANDâ€™ed together, and that forms the final expression for SAT. - Hereâ€™s a basic example: - So our 3COL problem is just two nodes with one edge joining them. - The first block in the SAT expression makes sure that each node has a colour. - The second block in the SAT expression makes sure each node has only ONE colour. - The third block in the SAT expression makes sure that nodes 1 and 2 donâ€™t share the same colour. - Great, but is it in polynomial time? - The number of characters in the output SAT problem is: - 7 ğ‘š + 2 0 ğ‘š + 2 0 ğ‘™ + ( 2 ğ‘š + ğ‘™ âˆ’ 1 ) - Where and . I donâ€™t know about you, but that looks likeğ‘š = #ğ‘£ğ‘’ğ‘Ÿğ‘¡ğ‘–ğ‘ğ‘’ğ‘  ğ‘™ = #ğ‘’ğ‘‘ğ‘”ğ‘’ğ‘  a polynomial to me. - By applying this method, we can convert any 3COL problem to SAT. - That means if we solve SAT in polynomial time, we can solve 3COL in polynomial time. - Conversely, if we find that 3COL is not in P, then SAT cannot be in P. Computer Science / Software Engineering Notes Network NP-hard - Whatâ€™s NP-hard? - NP-hard is a set of problems where any NP problem can reduce to any NP-hard problem in polynomial time. - This shows that NP-hard problems are, in a sense, hard, because every NP problem can reduce to it. The Cook-Levin theorem - The Cook-Levin theorem states that any NP problem can reduce to SAT in polynomial time. - That means that SAT is an NP-hard problem, because every NP problem can reduce to it. - This also means that if we can solve SAT in polynomial time, then every NP problem will be solvable in polynomial time, and NP will be equal to P. - To convert an NP problem X into SAT, you need to â€˜encodeâ€™the parameters of X into boolean variables and construct an expression for SAT. - Thereâ€™s a proof for it, but itâ€™s not examinable. Basically, itâ€™s about converting a Turing machine into a boolean expression. What is NP-completeness - An NP-complete problem is a problem in NP and NP-hard. - SAT is an example of an NP-complete problem, because it can be solved by a non-deterministic Turing machine and every other NP problem can be reduced to it in polynomial time. - To find another NP-complete problem, you just need to have a problem X that is in NP, then find a reduction function from SAT to X. - Just remember:if you solve an NP-complete problem in polynomial time, youâ€™ve solved all NP problems in polynomial time, too, proving P = NP. Computer Science / Software Engineering Notes Network Space complexity Space complexity - First of all, what is space complexity? - The space complexity of a decider is the function where is theğ‘“: ğ‘ â†’ ğ‘ ğ‘“( ğ‘›) maximum number of tape cells the machine scans on any branch of its computation, on any input of length n. - Basically, whatâ€™s the maximum number of tape cells we need to solve this problem? - Hereâ€™s a theorem for you: - Assume . If a decider runs in space, then it runs in time.ğ‘“( ğ‘›) â‰¥ ğ‘› ğ‘“( ğ‘›) 2 ğ‘‚( ğ‘“( ğ‘›) ) - Why? - Well, think of all the different possible combinations the Turing tape could be: 1 5 8 3 6 ... 8 3 2 9 5 ... 2 7 3 8 0 ... Computer Science / Software Engineering Notes Network - Thereâ€™s lots of possibilities the tape could be! - What are all the possible combinations of the tape? - Well, first of all, we need to know how long the tape is. We already know that! Itâ€™s the space complexity of the algorithm, which is f(n). Thatâ€™s how many tape cells we need to solve the problem. - Letâ€™s just say that our decider has to run through every possible tape configuration to solve the problem. - We need a bit of combinatorics from Foundations here;what are all the possible combinations of this tape? - For each position on the tape, there are â€˜mâ€™possibilities, where â€˜mâ€™is the number of symbols available to put on the tape. - So, we multiply for each tape cell, m * m * m * m ... f(n) times. This yields us: - ğ‘šğ‘“( ğ‘›) - We still have a ways to go! - We have our base â€˜mâ€™. However, with a little mathsy magic, we can generalise this further and make our base â€˜2â€™: - Whatâ€™s the opposite of exponential? Thatâ€™s right;itâ€™s logarithms! - We can simply take the logarithm of â€˜mâ€™and convert the base to a â€˜2â€™! - ( 2 ğ‘™ğ‘œğ‘” 2 ( ğ‘š) ) ğ‘“( ğ‘›) - Still remember your GCSE maths? When you have a power to the power, you multiply the powers. - 2 ğ‘™ğ‘œğ‘” 2 ( ğ‘š) Ã— ğ‘“( ğ‘›) - Wait a minute... is just a constant. It could be anything, depending on whatğ‘™ğ‘œğ‘” 2 ( ğ‘š) â€˜mâ€™is! Look familiar? Thatâ€™s the constant â€˜câ€™found in Big-O notation! Therefore, we can introduce Big-O notation to generalise that constant. - 2 ğ‘‚( ğ‘“( ğ‘›) ) - As you can see, we have resulted in , thereby proving the link between time2 ğ‘‚( ğ‘“( ğ‘›) ) and space complexity. - What does this mean? - It means the time complexity is 2 to the power of space complexity .ğ‘‚( ) - Remember our assumption:the decider checks all possible combinations of tape. Therefore, this is simply an â€œupper boundâ€. In other words, a decider of space complexity linear or above will have at worst exponential time complexity. PSPACE - PSPACE is the set of all decision problems that can be solved by a deterministic Turing machine in polynomial space. Computer Science / Software Engineering Notes Network NPSPACE - NPSPACE is the set of all decision problems that can be solved by a non-deterministic Turing machine in polynomial space. - Anything in PSPACE is in NPSPACE, and anything in NPSPACE is in PSPACE (see Savitchâ€™s Theorem, which is literally just below) Savitchâ€™s Theorem - Hereâ€™s another theorem, called Savitchâ€™s theorem: - For , every space non-deterministic Turing machine has an equivalentğ‘“( ğ‘›) â‰¥ ğ‘› ğ‘“( ğ‘›) space deterministic Turing machine.ğ‘“( ğ‘›) 2 - This means that PSPA C E = NPSPA C E. - Thereâ€™s a proof for this, but itâ€™s not examinable. EXPTIME - The class EXPTIME is the set of all decision problems that can be solved by a deterministic Turing machine in time for some .ğ‘‚( 2 ğ‘› ğ‘˜) ğ‘˜ âˆˆ ğ‘ Relationships between complexity classes - P âŠ† PSPACE:a machine that runs in polynomial time can only use polynomial space - NP âŠ† NPSPACE:same reason - Hence, using Savitchâ€™s theorem, NP âŠ† PSPACE - PSPACE âŠ† EXPTIME: - If a decider runs in f(n) space, then it runs in time.2 ğ‘‚( ğ‘“( ğ‘›) ) - We donâ€™t know which inclusion is strict. - All we know is P EXPTIME.âŠ‚ - No te:One can also define EXPSPACE. We know that - EXPTIME âŠ† EXPSPACE - PSPACE EXPSPACEâŠ‚ PSPACE-hard - A problem X is PSPACE-hard if every problem A in PSPACE is polynomial-time reducible to X. - Examples of PSPACE-hard problems are Chess and Go. - Why not space-reducible? - We defined it like that because we want reductions to be easy compared to problems in NP! Computer Science / Software Engineering Notes Network - If we used polynomial space reduction from A to B, then found an easy solution for B, it could potentially be factorial time complexity for A! - However, because we use time-reducible, it has to be both polynomial time an d polynomial space (because P âŠ† PSPACE). PSPACE-completeness - PSPACE-complete simply means that a problem is both PSPACE and PSPACE-hard. - An example of a PSPACE-complete problem is TQBF. - Let TQBF be the problem of deciding whether a fully quantified boolean formula is true. - Examples of fully quantified boolean formulas: - âˆ€x âˆ€y ( x âˆ¨ y ) - âˆ€x âˆƒy ( ( x âˆ¨ y ) âˆ§ ( Â¬ x âˆ¨ Â¬ y ) ) - Are there formulas true for all cases? Yes or no? That is the TQBF problem. TL;DR - Canâ€™t be bothered to read all these notes? - Need a bite-sized form of these notes? - The TL;DR section has your back! Automata theory:Regular languages - A lp habet:a set of symbols - Lan guage:any string that can be made with an alphabet - DFAs start at the initial state, then goes through transitions (each character in the string) until it reaches an accept state. - DFAs cannot guess;they must discretely be in only one state at a time, and each state must have all possible types of transitions from it - DFAs either accept a string or reject a string - DFAs are deterministic, NFAs are non-deterministic - NFAs can make guesses Computer Science / Software Engineering Notes Network - NFAs and DFAs have the same power - The set of all strings that a DFA / NFA can accept is called itâ€™s language - ÎµNFAs have epsilon-moves, which are free moves that do not cost any symbols in the string - A language accepted by some DFA or NFA is called â€˜regularâ€™ - Regular expressions have the same power as DFAs and NFAs - â€œa*â€ means 0 or more repetitions of a - â€œa + bâ€ means a or b - â€œabâ€ means a followed by b - You can always convert an NFA/DFA to regex or vice versa - You can prove a language is regular by constructing a DFA / NFA / regex - You can prove a language is not regular by using the pumping lemma Automata theory:Context free languages - A language is context free if it can be accepted by a PDA or CFG - Pushdown automata (PDA) are like DFAs and NFAs, but you get a stack. Computer Science / Software Engineering Notes Network - Each transition, an element is popped or pushed onto the stack - PDAs accept by final state or by empty stack - Context free grammars are just as powerful as PDAs - There are two forms of CFGs: - Chomsky normal form - - Greibach normal form - - You can always convert a CFG to either Chomsky or Greibach - You can always convert a CFG to PDA or vice versa - You can prove a language isnâ€™t context-free using the pumping lemma Computability theory - A Turing machine is like a PDA, but instead of a stack you get tape. You can move left or right on the tape, write to the tape and read from the tape. Computer Science / Software Engineering Notes Network - They are the closest mathematical abstraction of an actual computer. - A language is recursively enumerable (r.e) if it can be accepted by a Turing machine. - A language is recursive if a Turing machine can accept and reject strings from that language without looping. - Multi-tape TMs are just as powerful as single-tape TMs - A Universal Turing machine can simulate a Turing machine with a given input - The Halting problem:Is there a Turing machine that can accept if an input halts on a TM and reject if an input loops on a TM? - Itâ€™s impossible. There is a diagonalisation proof for this. - The Halting problem is â€˜undecidableâ€™. - The membership problem is also â€˜undecidableâ€™, because if we had a TM to solve the membership problem, we could use that to solve the Halting problem. - Reductio n :a computable function that maps inputs of one problem to another. - Riceâ€™s theorem states that any property about a Turing machineâ€™s language is undecidable: - You canâ€™t tell if a TM accepts the empty string - You canâ€™t tell if a TM accepts any string - You canâ€™t tell if a TM accepts all the strings - etc. Computer Science / Software Engineering Notes Network Complexity theory - Big-O represents the best algorithm we currently have;we could do better but this is the best we have - Big-Î˜ represents that an algorithm can scale no better than this - Time complexity is the number of steps it takes for a Turing machine to solve a problem. - The class P is the set of all decision problems that can be solved by a deterministic Turing machine in polynomial time - The class NP is the set of all decision problems that can be solved by a non-deterministic Turing machine in polynomial time. - The class NP-hard is the set of all problems such that all the NP problems can reduce into any NP-hard problem in polynomial time. - The class NP-complete is the set of all problems such that they are in both NP and NP-hard. - If you find a (deterministic) polynomial algorithm for an NP-complete problem, then P = NP. - If P = NP, then: - P = NP = NP-complete - P âŠ‚ NP-hard - Space complexity is the minimum number of tape cells required for a Turing machine to solve a problem. - PSPACE is the set of all decision problems that can be solved by a deterministic Turing machine in polynomial space. - NPSPACE is the set of all decision problems that can be solved by a non-deterministic Turing machine in polynomial space. - Savitchâ€™s Theorem states that for , every space non-deterministicğ‘“( ğ‘›) â‰¥ ğ‘› ğ‘“( ğ‘›) Turing machine has an equivalent space deterministic Turing machine.ğ‘“( ğ‘›) 2 - Therefore, PSPACE = NPSPACE. - EXPTIME is the set of all decision problems that can be solved by a deterministic Turing machine in time for some .ğ‘‚( 2 ğ‘› ğ‘˜) ğ‘˜ âˆˆ ğ‘ Computer Science / Software Engineering Notes Network - PSPACE = NPSPACE - NP âŠ† PSPACE - PSPACE âŠ† EXPTIME - P âŠ‚ EXPTIME - PSPACE-hard is the set of all problems such that all the PSPACE problems can reduce into any PSPACE-hard problems in polynomial time. - PSPACE-complete is the set of all problems that are in PSPACE and PSPACE-hard.","libVersion":"0.3.2","langs":""}